{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import RAW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 1162749: expected 6 fields, saw 7\n",
      "\n",
      "Skipping line 1725934: expected 6 fields, saw 7\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FORMA</th>\n",
       "      <th>LEMA</th>\n",
       "      <th>CATEGORIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>el</td>\n",
       "      <td>el</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la</td>\n",
       "      <td>el</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FORMA LEMA CATEGORIA\n",
       "0    de   de         P\n",
       "1     ,    ,         Y\n",
       "2     .    .         Y\n",
       "3    el   el         T\n",
       "4    la   el         T"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"./data/diccionario/frecuencia_elementos_corpes_1_0.txt\"\n",
    "\n",
    "columns = [\"Forma\", \"Lema\", \"Categoria\", \"Frecuencia\", \"Frec. norm. con signos ort.\", \"Frec. norm. sin signos ort.\"]\n",
    "df = pd.read_csv(filename, delimiter='\\t', header=0, on_bad_lines=\"warn\",encoding='utf-8', names=columns, skiprows=[0])\n",
    "\n",
    "# Get only the first 3 columns\n",
    "df = df.iloc[:,0:3]\n",
    "# Cast columns names to unicode and uppercase\n",
    "df.columns = [x.upper() for x in df.columns]\n",
    "# Remove rows with NaN values\n",
    "df = df.dropna()\n",
    "# Remove rows with empty values\n",
    "df = df[df[\"LEMA\"] != \" \"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize some tags see [etiquetario](./docs/etiquetario_RAE_sustantivos_adjetivos.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             FORMA            LEMA CATEGORIA\n",
      "0        En base a       en base a         P\n",
      "1       en pos del       en pos de         P\n",
      "2          5.3.3.4         5.3.3.4         Y\n",
      "3          6.3.3.3         6.3.3.3         Y\n",
      "4              los              el         T\n",
      "5             Unos              un         T\n",
      "6       a poco que      a poco que         C\n",
      "7         dado que        dado que         C\n",
      "8              que             que         H\n",
      "9             cuyo            cuyo         H\n",
      "10              LO              lo         L\n",
      "11              mí              mí         L\n",
      "12      Vocalmente      vocalmente         R\n",
      "13     cuerdamente     cuerdamente         R\n",
      "14           suyos            suyo         X\n",
      "15            Suya            suyo         X\n",
      "16    sorprendamos      sorprender         V\n",
      "17      acaríciala       acariciar         V\n",
      "18            ESTO            este         D\n",
      "19             TAL             tal         D\n",
      "20            Unos             uno         Q\n",
      "21          aLguna          alguno         Q\n",
      "22   Thiago Moroso   Thiago Moroso         N\n",
      "23     Álex Chaban     Álex Chaban         N\n",
      "24            6369            6369         M\n",
      "25          69.280          69.280         M\n",
      "26         QUIÉNES           quién         W\n",
      "27     cuantísimos          cuánto         W\n",
      "28         curales           cural         A\n",
      "29      Narrativas       narrativo         A\n",
      "30          pseudo         pseudo-         J\n",
      "31          acetil         acetil-         J\n",
      "32  Psittacosaurus  Psittacosaurus         F\n",
      "33     programació     programació         F\n",
      "34           órale           órale         I\n",
      "35           piiii           piiii         I\n",
      "36          jevito              ??         U\n",
      "37       guasquear              ??         U\n",
      "38             Der             del         E\n",
      "39             del             del         E\n",
      "40      Vade retro      vade retro         i\n",
      "41      vade retro      vade retro         i\n"
     ]
    }
   ],
   "source": [
    "# Get the unique values of the column \"CATEGORIA\"\n",
    "categories = df[\"CATEGORIA\"].unique()\n",
    "# Create an empty DataFrame to store the sampled rows\n",
    "sample_df = pd.DataFrame(columns=df.columns)\n",
    "# Loop through each category and sample two rows without replacement\n",
    "for category in categories:\n",
    "    category_df = df[df[\"CATEGORIA\"] == category]\n",
    "    if len(category_df) >= 2:\n",
    "        sampled_rows = category_df.sample(2, replace=False)\n",
    "        sample_df = pd.concat([sample_df, sampled_rows])\n",
    "# Reset the index of the resulting DataFrame\n",
    "sample_df.reset_index(drop=True, inplace=True)\n",
    "# Show the result\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get only the sustantives and adjectives see [etiquetado](./docs/etiquetario_RAE_sustantivos_adjetivos.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  2754080\n",
      "After:  1772146\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FORMA</th>\n",
       "      <th>LEMA</th>\n",
       "      <th>CATEGORIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>años</td>\n",
       "      <td>año</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>parte</td>\n",
       "      <td>parte</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>vida</td>\n",
       "      <td>vida</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tiempo</td>\n",
       "      <td>tiempo</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>vez</td>\n",
       "      <td>vez</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FORMA    LEMA CATEGORIA\n",
       "51    años     año         N\n",
       "82   parte   parte         N\n",
       "85    vida    vida         N\n",
       "90  tiempo  tiempo         N\n",
       "94     vez     vez         N"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract only the column \"CATEGORIA\" which have the values of adjectives and sustantives\n",
    "# Mirar la documentación en donde se define el tag de los sustantivos y adjetivos\n",
    "sustantive_tag = \"N\"\n",
    "adjective_tag = \"A\"\n",
    "# Extract from the raw df DataFrame the rows with the tag \"N\" or \"A\"\n",
    "print(\"Before: \", len(df))\n",
    "df = df[df[\"CATEGORIA\"].isin([sustantive_tag, adjective_tag])]\n",
    "print(\"After: \", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split from sustantivo and adjetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LEMA   FORMA\n",
      "51     año    años\n",
      "82   parte   parte\n",
      "85    vida    vida\n",
      "90  tiempo  tiempo\n",
      "94     vez     vez\n",
      "           LEMA       FORMA\n",
      "143      grande        gran\n",
      "145       mayor       mayor\n",
      "172       nuevo       nuevo\n",
      "204       mejor       mejor\n",
      "209  importante  importante\n"
     ]
    }
   ],
   "source": [
    "# Split the dataframe in sustantives and adjectives and sort by alphabetical order in FORMA and reset the index\n",
    "sustantives_df = df[df[\"CATEGORIA\"] == sustantive_tag][[\"LEMA\", \"FORMA\"]]\n",
    "adjectives_df = df[df[\"CATEGORIA\"] == adjective_tag][[\"LEMA\", \"FORMA\"]]\n",
    "# Show the result\n",
    "print(sustantives_df.head())\n",
    "print(adjectives_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter, clean and delete data from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  1631668\n",
      "After:  1305938\n",
      "Before:  140478\n",
      "After:  100412\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "def clean_word(word):\n",
    "    # Delete all numbers\n",
    "    word = re.sub(r\"\\d+\", \"\", word)\n",
    "    # Delete all accents\n",
    "    word = unidecode(word.lower())\n",
    "    # Remove simbols\n",
    "    word = re.sub(r\"[^a-z0-9ñ]\", \"\", word)\n",
    "    return word\n",
    "\n",
    "def clean_and_process_df(df):\n",
    "    # Remove registers with nan or empty values in the column \"FORMA\"\n",
    "    df = df.dropna(subset=[\"FORMA\"])\n",
    "    # Apply the cleaning function to the \"FORMA\" and \"LEMA\" columns\n",
    "    df[\"FORMA\"] = df[\"FORMA\"].apply(clean_word)\n",
    "    df[\"LEMA\"] = df[\"LEMA\"].apply(clean_word)\n",
    "    # Get all the registers with spaces in the column \"FORMA\" and delete them\n",
    "    df = df[~df[\"FORMA\"].str.contains(\" \")]\n",
    "    # Get all the registers with spaces in the column \"LEMA\" and delete them\n",
    "    df = df[~df[\"LEMA\"].str.contains(\" \")]\n",
    "    # Remove registers with nan or empty values in the column \"LEMA\"\n",
    "    df = df.dropna(subset=[\"LEMA\"])\n",
    "    # Remove duplicates in the column \"FORMA\"\n",
    "    df = df.drop_duplicates(subset=[\"FORMA\"])\n",
    "    # Remove rows where \"LEMA\" or \"FORMA\" are empty strings\n",
    "    df = df[(df[\"LEMA\"] != \"\") & (df[\"FORMA\"] != \"\")]\n",
    "    return df\n",
    "# Clean the sustantives and adjectives DataFrames\n",
    "print(\"Before: \", len(sustantives_df))\n",
    "sustantives_df = clean_and_process_df(sustantives_df)\n",
    "print(\"After: \", len(sustantives_df))\n",
    "print(\"Before: \", len(adjectives_df))\n",
    "adjectives_df = clean_and_process_df(adjectives_df)\n",
    "print(\"After: \", len(adjectives_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Delete stopwords in unstructrured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LEMA   FORMA\n",
      "51     ano    anos\n",
      "82   parte   parte\n",
      "85    vida    vida\n",
      "90  tiempo  tiempo\n",
      "94     vez     vez\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/fulp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download stopwords in spanish and english from nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# Import stopwords from nltk\n",
    "from nltk.corpus import stopwords\n",
    "# Get the stopwords in spanish\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "# Get the stopwords in english\n",
    "english_stopwords = stopwords.words('english')\n",
    "# Extend into stopwords\n",
    "stopwords = spanish_stopwords + english_stopwords\n",
    "# Unidecode the stopwords\n",
    "stopwords = [unidecode(word) for word in stopwords]\n",
    "# Delete all aparitions of stopwords in the sustantives and adjectives DataFrames\n",
    "sustantives_df = sustantives_df[~sustantives_df[\"FORMA\"].isin(stopwords)]\n",
    "adjectives_df = adjectives_df[~adjectives_df[\"FORMA\"].isin(stopwords)]\n",
    "# Show the result\n",
    "print(sustantives_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order alphabetical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order alphabetically by \"LEMA\" and \"FORMA\" and reset the index\n",
    "sustantives_df = sustantives_df.sort_values(by=[\"LEMA\", \"FORMA\"]).reset_index(drop=True)\n",
    "adjectives_df = adjectives_df.sort_values(by=[\"LEMA\", \"FORMA\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get structure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "sustantives_df.head(5)\n",
    "# Save the DataFrames to CSV files in the folder \"data/diccionario\" as df_structured_sustantivos.csv and df_structured_adjetivos.csv\n",
    "sustantives_df.to_csv(\"./data/diccionario/df_structured_sustantivos.csv\", index=False)\n",
    "adjectives_df.to_csv(\"./data/diccionario/df_structured_adjetivos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get unstructured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12\n",
      "1 12d\n",
      "2 2\n",
      "3 2ddtt2\n",
      "4 3\n",
      "5 3mm3\n",
      "6 a2b2\n",
      "7 aa\n",
      "8 aaa\n",
      "9 aaaa\n",
      "0 12\n",
      "1 12d\n",
      "2 2\n",
      "3 2ddtt2\n",
      "4 3\n"
     ]
    }
   ],
   "source": [
    "# Get a list with all LEMAS of the sustantives and sort by alphabetical order\n",
    "sustantives_lemas = list(sustantives_df[\"LEMA\"])\n",
    "# Get a list with all LEMAS of the adjetives and sort by alphabetical order\n",
    "adjectives_lemas = list(adjectives_df[\"LEMA\"])\n",
    "# Show a sample of the sustantives with the format \"index - lemma\"\n",
    "for i, lemma in enumerate(sustantives_lemas[:10]):\n",
    "    print(i, lemma)\n",
    "# Get a list with all FORMS of the sustantives and sort by alphabetical order\n",
    "sustantives_forms = list(sustantives_df[\"FORMA\"])\n",
    "# Get a list with all FORMS of the adjetives and sort by alphabetical order\n",
    "adjectives_forms = list(adjectives_df[\"FORMA\"])\n",
    "# Show a sample of the sustantives with the format \"index - form\"\n",
    "for i, form in enumerate(sustantives_forms[:5]):\n",
    "    print(i, form)\n",
    "# Save in txt file as list_unstructured_sustantivos.txt and list_unstructured_adjetivos.txt\n",
    "with open(\"./data/diccionario/list_unstructured_sustantivos.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(sustantives_lemas))\n",
    "with open(\"./data/diccionario/list_unstructured_adjetivos.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(adjectives_lemas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syntax(words, df_nouns, unstructured_forms_nouns, df_adj, unstructured_forms_adj, estricto=False):\n",
    "    # Object palabras_dict\n",
    "    palabras_dict = {}\n",
    "    # Object palabras_list\n",
    "    palabras_list = []\n",
    "    # Initialize nouns array\n",
    "    nouns = []\n",
    "    adjectives = []\n",
    "    # Split by \" \"\n",
    "    for word in words.split(\" \"):\n",
    "        word = clean_word(word)\n",
    "        # Verify if is a noun\n",
    "        noun = get_lemma_df(word, df_nouns, unstructured_forms_nouns)\n",
    "        adjective = get_lemma_df(word, df_adj, unstructured_forms_adj)\n",
    "        palabras_list, adjectives, nouns = inference(adjective, noun, estricto, palabras_list, adjectives, nouns)\n",
    "    palabras_dict[\"Sustantivos\"] = nouns\n",
    "    palabras_dict[\"Adjetivos\"] = adjectives\n",
    "    return palabras_dict, palabras_list\n",
    "\n",
    "def clasify_estric_mode(adjective, noun, adjective_list, noun_list):\n",
    "    if adjective is not None:\n",
    "        adjective_list.append(adjective)\n",
    "    elif noun is not None:\n",
    "        noun_list.append(noun)\n",
    "    return adjective_list, noun_list\n",
    "\n",
    "def clasify_non_estric_mode(adjective, noun, adjective_list, noun_list):\n",
    "    if noun is not None:\n",
    "        noun_list.append(noun)\n",
    "    if adjective is not None:\n",
    "        adjective_list.append(adjective)\n",
    "    return adjective_list, noun_list\n",
    "\n",
    "def inference(adjective, noun, estricto, palabras_list, adjective_list, noun_list):\n",
    "    if adjective is not None and noun is not None:\n",
    "        # Da igual que sea adjetivo o sustantivo, ya pasó por el filtro\n",
    "        palabras_list.append(adjective)\n",
    "    if estricto:\n",
    "        adjective_list, noun_list = clasify_estric_mode(adjective, noun, adjective_list, noun_list)\n",
    "    else:\n",
    "        adjective_list, noun_list = clasify_non_estric_mode(adjective, noun, adjective_list, noun_list)\n",
    "    return palabras_list, adjective_list, noun_list\n",
    "\n",
    "def get_lemma_df(word, df, unstructured_forms):\n",
    "    try:\n",
    "        word_index = unstructured_forms.index(word)\n",
    "        return df.iloc[word_index][\"LEMA\"]\n",
    "    except ValueError:\n",
    "        return None  # Handle the case when the word is not found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  11.38090205192566\n",
      "['presente', 'agente', 'asociado', 'asesor', 'inmobiliario', 'propio', 'menor', 'canario', 'mejor', 'profesional', 'inmobiliario', 'alto', 'agente', 'asociado', 'nuevo', 'nuevo', 'inmueble', 'inmueble', 'concreto', 'inmueble', 'inmueble']\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso:\n",
    "word_to_find = \"\"\"\n",
    "En España está presente desde hace más de 25 años, con más de 130 oficinas y más de 1.800 Agentes asociados. Seleccionamos asesores inmobiliarios para nuestra oficina en calle Carvajal, con o sin experiencia.\n",
    "Te ofrecemos tener tu negocio propio con la menor inversión del mercado trabajando en la empresa líder de Canarias es la mejor elección para profesionales como tu para la industria inmobiliaria y sus clientes, a través de la creación de un entorno de trabajo Sinérgico, transformando y profesionalizando esta industria.\n",
    "Con RE/MAX puedes llegar a lo más alto de la profesión Inmobiliaria.\n",
    "¿Qué hace un agente asociado RE/MAX?\n",
    "\n",
    "- Calificar nuevos clientes.\n",
    "- Estudia el mercado donde trabaja.\n",
    "- Capta nuevos inmuebles para la venta.\n",
    "- Elabora planes de marketing para los inmuebles en cartera.\n",
    "- Atiende y da el seguimiento a las necesidades de sus clientes\n",
    "- Aconseja financieramente a sus clientes.\n",
    "- Concreta la venta de los inmuebles en cartera.\n",
    "- Realiza valoraciones de valor de mercado de los inmuebles.\n",
    "\"\"\"\n",
    "# Measure the time with time package\n",
    "import time\n",
    "start_time = time.time()\n",
    "palabras_dict, palabras_list = get_syntax(word_to_find, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms, estricto=True)\n",
    "print(\"Time: \", time.time() - start_time)\n",
    "print(palabras_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
