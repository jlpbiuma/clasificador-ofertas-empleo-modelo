{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import RAW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 1162749: expected 6 fields, saw 7\n",
      "\n",
      "Skipping line 1725934: expected 6 fields, saw 7\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FORMA</th>\n",
       "      <th>LEMA</th>\n",
       "      <th>CATEGORIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>el</td>\n",
       "      <td>el</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la</td>\n",
       "      <td>el</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FORMA LEMA CATEGORIA\n",
       "0    de   de         P\n",
       "1     ,    ,         Y\n",
       "2     .    .         Y\n",
       "3    el   el         T\n",
       "4    la   el         T"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"./data/diccionario/frecuencia_elementos_corpes_1_0.txt\"\n",
    "\n",
    "columns = [\"Forma\", \"Lema\", \"Categoria\", \"Frecuencia\", \"Frec. norm. con signos ort.\", \"Frec. norm. sin signos ort.\"]\n",
    "df = pd.read_csv(filename, delimiter='\\t', header=0, on_bad_lines=\"warn\",encoding='utf-8', names=columns, skiprows=[0])\n",
    "\n",
    "# Get only the first 3 columns\n",
    "df = df.iloc[:,0:3]\n",
    "# Cast columns names to unicode and uppercase\n",
    "df.columns = [x.upper() for x in df.columns]\n",
    "# Remove rows with NaN values\n",
    "df = df.dropna()\n",
    "# Remove rows with empty values\n",
    "df = df[df[\"LEMA\"] != \" \"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize some tags see [etiquetario](./docs/etiquetario_RAE_sustantivos_adjetivos.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            FORMA           LEMA CATEGORIA\n",
      "0    en lugar del   en lugar del         P\n",
      "1       JUNTO CON      junto con         P\n",
      "2          7.20.5         7.20.5         Y\n",
      "3         3.4.2.1        3.4.2.1         Y\n",
      "4              un             un         T\n",
      "5             UNA             un         T\n",
      "6     una vez que    una vez que         C\n",
      "7               O              o         C\n",
      "8           cuyos           cuyo         H\n",
      "9         QUIENES          quien         H\n",
      "10             Te             te         L\n",
      "11             YO             yo         L\n",
      "12     vacuamente     vacuamente         R\n",
      "13  Separadamente  separadamente         R\n",
      "14            suS           suyo         X\n",
      "15       NUESTROS        nuestro         X\n",
      "16   iluminábamos       iluminar         V\n",
      "17   importunarla     importunar         V\n",
      "18      aquellita          aquel         D\n",
      "19           Ésos            ese         D\n",
      "20          Mucha          mucho         Q\n",
      "21    Toditititos           todo         Q\n",
      "22     Eric Gagné     Eric Gagné         N\n",
      "23           LETS           LETS         N\n",
      "24        0,7-2,5        0,7-2,5         M\n",
      "25       213.4630       213.4630         M\n",
      "26     cuantísima         cuánto         W\n",
      "27         CUÁNTO         cuánto         W\n",
      "28    Epistémicas     epistémico         A\n",
      "29       Mercante       mercante         A\n",
      "30             Co            co-         J\n",
      "31        cérvico       cérvico-         J\n",
      "32   Rumpelstikin   Rumpelstikin         F\n",
      "33  endosimbionte  endosimbionte         F\n",
      "34             UY             uy         I\n",
      "35           plas           plas         I\n",
      "36            89c             ??         U\n",
      "37    suicidófila             ??         U\n",
      "38            der            del         E\n",
      "39            Der            del         E\n",
      "40     vade retro     vade retro         i\n",
      "41     Vade retro     vade retro         i\n"
     ]
    }
   ],
   "source": [
    "# Get the unique values of the column \"CATEGORIA\"\n",
    "categories = df[\"CATEGORIA\"].unique()\n",
    "# Create an empty DataFrame to store the sampled rows\n",
    "sample_df = pd.DataFrame(columns=df.columns)\n",
    "# Loop through each category and sample two rows without replacement\n",
    "for category in categories:\n",
    "    category_df = df[df[\"CATEGORIA\"] == category]\n",
    "    if len(category_df) >= 2:\n",
    "        sampled_rows = category_df.sample(2, replace=False)\n",
    "        sample_df = pd.concat([sample_df, sampled_rows])\n",
    "# Reset the index of the resulting DataFrame\n",
    "sample_df.reset_index(drop=True, inplace=True)\n",
    "# Show the result\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get only the sustantives and adjectives see [etiquetado](./docs/etiquetario_RAE_sustantivos_adjetivos.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  2754080\n",
      "After:  1772146\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FORMA</th>\n",
       "      <th>LEMA</th>\n",
       "      <th>CATEGORIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>años</td>\n",
       "      <td>año</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>parte</td>\n",
       "      <td>parte</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>vida</td>\n",
       "      <td>vida</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tiempo</td>\n",
       "      <td>tiempo</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>vez</td>\n",
       "      <td>vez</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FORMA    LEMA CATEGORIA\n",
       "51    años     año         N\n",
       "82   parte   parte         N\n",
       "85    vida    vida         N\n",
       "90  tiempo  tiempo         N\n",
       "94     vez     vez         N"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract only the column \"CATEGORIA\" which have the values of adjectives and sustantives\n",
    "# Mirar la documentación en donde se define el tag de los sustantivos y adjetivos\n",
    "sustantive_tag = \"N\"\n",
    "adjective_tag = \"A\"\n",
    "# Extract from the raw df DataFrame the rows with the tag \"N\" or \"A\"\n",
    "print(\"Before: \", len(df))\n",
    "df = df[df[\"CATEGORIA\"].isin([sustantive_tag, adjective_tag])]\n",
    "print(\"After: \", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split from sustantivo and adjetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LEMA   FORMA\n",
      "51     año    años\n",
      "82   parte   parte\n",
      "85    vida    vida\n",
      "90  tiempo  tiempo\n",
      "94     vez     vez\n",
      "           LEMA       FORMA\n",
      "143      grande        gran\n",
      "145       mayor       mayor\n",
      "172       nuevo       nuevo\n",
      "204       mejor       mejor\n",
      "209  importante  importante\n"
     ]
    }
   ],
   "source": [
    "# Split the dataframe in sustantives and adjectives and sort by alphabetical order in FORMA and reset the index\n",
    "sustantives_df = df[df[\"CATEGORIA\"] == sustantive_tag][[\"LEMA\", \"FORMA\"]]\n",
    "adjectives_df = df[df[\"CATEGORIA\"] == adjective_tag][[\"LEMA\", \"FORMA\"]]\n",
    "# Show the result\n",
    "print(sustantives_df.head())\n",
    "print(adjectives_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter, clean and delete data from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  1631668\n",
      "After:  1305938\n",
      "Before:  140478\n",
      "After:  100412\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "def clean_word(word):\n",
    "    # Delete all numbers\n",
    "    word = re.sub(r\"\\d+\", \"\", word)\n",
    "    # Delete all accents\n",
    "    word = unidecode(word.lower())\n",
    "    # Remove simbols\n",
    "    word = re.sub(r\"[^a-z0-9ñ]\", \"\", word)\n",
    "    return word\n",
    "\n",
    "def clean_and_process_df(df):\n",
    "    # Remove registers with nan or empty values in the column \"FORMA\"\n",
    "    df = df.dropna(subset=[\"FORMA\"])\n",
    "    # Apply the cleaning function to the \"FORMA\" and \"LEMA\" columns\n",
    "    df[\"FORMA\"] = df[\"FORMA\"].apply(clean_word)\n",
    "    df[\"LEMA\"] = df[\"LEMA\"].apply(clean_word)\n",
    "    # Get all the registers with spaces in the column \"FORMA\" and delete them\n",
    "    df = df[~df[\"FORMA\"].str.contains(\" \")]\n",
    "    # Get all the registers with spaces in the column \"LEMA\" and delete them\n",
    "    df = df[~df[\"LEMA\"].str.contains(\" \")]\n",
    "    # Remove registers with nan or empty values in the column \"LEMA\"\n",
    "    df = df.dropna(subset=[\"LEMA\"])\n",
    "    # Remove duplicates in the column \"FORMA\"\n",
    "    df = df.drop_duplicates(subset=[\"FORMA\"])\n",
    "    # Remove rows where \"LEMA\" or \"FORMA\" are empty strings\n",
    "    df = df[(df[\"LEMA\"] != \"\") & (df[\"FORMA\"] != \"\")]\n",
    "    return df\n",
    "# Clean the sustantives and adjectives DataFrames\n",
    "print(\"Before: \", len(sustantives_df))\n",
    "sustantives_df = clean_and_process_df(sustantives_df)\n",
    "print(\"After: \", len(sustantives_df))\n",
    "print(\"Before: \", len(adjectives_df))\n",
    "adjectives_df = clean_and_process_df(adjectives_df)\n",
    "print(\"After: \", len(adjectives_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Delete stopwords in unstructrured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LEMA   FORMA\n",
      "51     ano    anos\n",
      "82   parte   parte\n",
      "85    vida    vida\n",
      "90  tiempo  tiempo\n",
      "94     vez     vez\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/fulp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download stopwords in spanish and english from nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# Import stopwords from nltk\n",
    "from nltk.corpus import stopwords\n",
    "# Get the stopwords in spanish\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "# Get the stopwords in english\n",
    "english_stopwords = stopwords.words('english')\n",
    "# Extend into stopwords\n",
    "stopwords = spanish_stopwords + english_stopwords\n",
    "# Unidecode the stopwords\n",
    "stopwords = [unidecode(word) for word in stopwords]\n",
    "# Delete all aparitions of stopwords in the sustantives and adjectives DataFrames\n",
    "sustantives_df = sustantives_df[~sustantives_df[\"FORMA\"].isin(stopwords)]\n",
    "adjectives_df = adjectives_df[~adjectives_df[\"FORMA\"].isin(stopwords)]\n",
    "# Show the result\n",
    "print(sustantives_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order alphabetical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order alphabetically by \"LEMA\" and \"FORMA\" and reset the index\n",
    "sustantives_df = sustantives_df.sort_values(by=[\"LEMA\", \"FORMA\"]).reset_index(drop=True)\n",
    "adjectives_df = adjectives_df.sort_values(by=[\"LEMA\", \"FORMA\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get structure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "sustantives_df.head(5)\n",
    "# Save the DataFrames to CSV files in the folder \"data/diccionario\" as df_structured_sustantivos.csv and df_structured_adjetivos.csv\n",
    "sustantives_df.to_csv(\"./data/diccionario/df_structured_sustantivos.csv\", index=False)\n",
    "adjectives_df.to_csv(\"./data/diccionario/df_structured_adjetivos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get unstructured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12\n",
      "1 12d\n",
      "2 2\n",
      "3 2ddtt2\n",
      "4 3\n",
      "5 3mm3\n",
      "6 a2b2\n",
      "7 aa\n",
      "8 aaa\n",
      "9 aaaa\n",
      "0 12\n",
      "1 12d\n",
      "2 2\n",
      "3 2ddtt2\n",
      "4 3\n"
     ]
    }
   ],
   "source": [
    "# Get a list with all LEMAS of the sustantives and sort by alphabetical order\n",
    "sustantives_lemas = list(sustantives_df[\"LEMA\"])\n",
    "# Get a list with all LEMAS of the adjetives and sort by alphabetical order\n",
    "adjectives_lemas = list(adjectives_df[\"LEMA\"])\n",
    "# Show a sample of the sustantives with the format \"index - lemma\"\n",
    "for i, lemma in enumerate(sustantives_lemas[:10]):\n",
    "    print(i, lemma)\n",
    "# Get a list with all FORMS of the sustantives and sort by alphabetical order\n",
    "sustantives_forms = list(sustantives_df[\"FORMA\"])\n",
    "# Get a list with all FORMS of the adjetives and sort by alphabetical order\n",
    "adjectives_forms = list(adjectives_df[\"FORMA\"])\n",
    "# Show a sample of the sustantives with the format \"index - form\"\n",
    "for i, form in enumerate(sustantives_forms[:5]):\n",
    "    print(i, form)\n",
    "# Save in txt file as list_unstructured_sustantivos.txt and list_unstructured_adjetivos.txt\n",
    "with open(\"./data/diccionario/list_unstructured_sustantivos.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(sustantives_lemas))\n",
    "with open(\"./data/diccionario/list_unstructured_adjetivos.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(adjectives_lemas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syntax(words, df_nouns, unstructured_forms_nouns, df_adj, unstructured_forms_adj, estricto=False):\n",
    "    # Object palabras_dict\n",
    "    palabras_dict = {}\n",
    "    # Object palabras_list\n",
    "    palabras_list = []\n",
    "    # Initialize nouns array\n",
    "    nouns = []\n",
    "    adjectives = []\n",
    "    # Split by \" \"\n",
    "    for word in words.split(\" \"):\n",
    "        word = clean_word(word)\n",
    "        # Verify if is a noun\n",
    "        noun = get_lemma_df(word, df_nouns, unstructured_forms_nouns)\n",
    "        adjective = get_lemma_df(word, df_adj, unstructured_forms_adj)\n",
    "        adjectives, nouns = inference(adjective, noun, estricto, adjectives, nouns)\n",
    "    palabras_dict[\"Sustantivos\"] = nouns\n",
    "    palabras_dict[\"Adjetivos\"] = adjectives\n",
    "    palabras_list = nouns + adjectives\n",
    "    return palabras_dict, palabras_list\n",
    "\n",
    "def clasify_estric_mode(adjective, noun, adjective_list, noun_list):\n",
    "    if adjective is not None:\n",
    "        adjective_list.append(adjective)\n",
    "    elif noun is not None:\n",
    "        noun_list.append(noun)\n",
    "    return adjective_list, noun_list\n",
    "\n",
    "def clasify_non_estric_mode(adjective, noun, adjective_list, noun_list):\n",
    "    if noun is not None:\n",
    "        noun_list.append(noun)\n",
    "    if adjective is not None:\n",
    "        adjective_list.append(adjective)\n",
    "    return adjective_list, noun_list\n",
    "\n",
    "def inference(adjective, noun, estricto, adjective_list, noun_list):\n",
    "    if estricto:\n",
    "        adjective_list, noun_list = clasify_estric_mode(adjective, noun, adjective_list, noun_list)\n",
    "    else:\n",
    "        adjective_list, noun_list = clasify_non_estric_mode(adjective, noun, adjective_list, noun_list)\n",
    "    return adjective_list, noun_list\n",
    "\n",
    "def get_lemma_df(word, df, unstructured_forms):\n",
    "    try:\n",
    "        word_index = unstructured_forms.index(word)\n",
    "        return df.iloc[word_index][\"LEMA\"]\n",
    "    except ValueError:\n",
    "        return None  # Handle the case when the word is not found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and clean test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11123, 5)\n"
     ]
    }
   ],
   "source": [
    "from notebooks.functions.tools import load_json\n",
    "data = load_json('./data/test/test_palabras.json')\n",
    "# Now cast data to a DataFrame\n",
    "test_df = pd.DataFrame(data)\n",
    "print(test_df.shape)\n",
    "test_df.head()\n",
    "# from functions.descripcion import clean_descripcion\n",
    "import re\n",
    "\n",
    "list_remove = [\"www\", \"com\",\"http\", \"https\"]\n",
    "\n",
    "def tokenize_descripcion(text):\n",
    "    # Remove links (URLs) from the text using regular expressions\n",
    "    text = re.sub(r'http(s)?:\\s+\\S+', '', text, flags=re.IGNORECASE)\n",
    "    # Remove all occurrences of \".es\" (case-insensitive)\n",
    "    text = re.sub(r'\\.es', '', text, flags=re.IGNORECASE)\n",
    "    # Remove all non alpha characters from the text using regular expressions\n",
    "    text = re.sub(r'[^a-zA-Z ]+', ' ', text, flags=re.IGNORECASE)\n",
    "    # Remove unnecessary spaces from the text using regular expressions\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.IGNORECASE)\n",
    "    # Cast all words to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def create_palabras_column(text):\n",
    "    # Split the text into a list of words and filter simultaneously\n",
    "    palabras = [palabra for palabra in text.split(\" \") if len(palabra) > 1 and palabra not in list_remove]\n",
    "    return palabras\n",
    "\n",
    "def clean_descripcion(df):\n",
    "    # tokenize the descripcion\n",
    "    df['descripcion_oferta'] = df['descripcion_oferta'].apply(tokenize_descripcion)\n",
    "    # Split the text into a list of words\n",
    "    df['palabras_descripcion_oferta'] = df['descripcion_oferta'].apply(create_palabras_column)\n",
    "    return df\n",
    "\n",
    "def list_words(palabras_empleo_texto):\n",
    "    # print(palabras_empleo_texto)\n",
    "    return palabras_empleo_texto.lower().split(\" \")[:-1]\n",
    "test_df = clean_descripcion(test_df)\n",
    "test_df['palabras_empleo_texto'] = test_df['palabras_empleo_texto'].apply(lambda x: list_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  29.969093084335327\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_puesto_esco_ull</th>\n",
       "      <th>categoria</th>\n",
       "      <th>subcategoria</th>\n",
       "      <th>palabras_empleo_texto</th>\n",
       "      <th>descripcion_oferta</th>\n",
       "      <th>palabras_descripcion_oferta</th>\n",
       "      <th>palabras_list_all</th>\n",
       "      <th>palabras_legacy_minus_nuevas</th>\n",
       "      <th>palabras_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1634</td>\n",
       "      <td>Atencion a clientes</td>\n",
       "      <td>Atencion al cliente</td>\n",
       "      <td>[administrativo, persona, reservas, buceo, ges...</td>\n",
       "      <td>buscamos una persona encargada de gestionar la...</td>\n",
       "      <td>[buscamos, una, persona, encargada, de, gestio...</td>\n",
       "      <td>[persona, encargado, reserva, actividad, buceo...</td>\n",
       "      <td>[alojamientos, electronica, data, recepciones,...</td>\n",
       "      <td>{'Sustantivos': ['persona', 'encargado', 'rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984</td>\n",
       "      <td>Ventas al detalle</td>\n",
       "      <td>Venta al detalle</td>\n",
       "      <td>[dependiente, tiendas, centro, comercial, expe...</td>\n",
       "      <td>se busca dependiente para la tienda tezenis en...</td>\n",
       "      <td>[se, busca, dependiente, para, la, tienda, tez...</td>\n",
       "      <td>[busca, dependiente, tienda, centro, comercial...</td>\n",
       "      <td>[tiendas, idiomas]</td>\n",
       "      <td>{'Sustantivos': ['busca', 'dependiente', 'tien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>719</td>\n",
       "      <td>Recursos humanos</td>\n",
       "      <td>Prevencion de riesgos</td>\n",
       "      <td>[puentes, grua, normas, sector, metales, homol...</td>\n",
       "      <td>grupo loxamhune empresa lider en el alquiler d...</td>\n",
       "      <td>[grupo, loxamhune, empresa, lider, en, el, alq...</td>\n",
       "      <td>[grupo, empresa, lider, alquiler, maquinaria, ...</td>\n",
       "      <td>[normas, elevadores, certificaciones, metales,...</td>\n",
       "      <td>{'Sustantivos': ['grupo', 'empresa', 'lider', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1508</td>\n",
       "      <td>Comercial y ventas</td>\n",
       "      <td>Comercial</td>\n",
       "      <td>[asesores, comercial, prevencion, riesgos, lab...</td>\n",
       "      <td>antea prevencion es una compania dedicada a la...</td>\n",
       "      <td>[antea, prevencion, es, una, compania, dedicad...</td>\n",
       "      <td>[antea, prevencion, compania, prevencion, ries...</td>\n",
       "      <td>[servicios, empresas, experiencia, seguros, eq...</td>\n",
       "      <td>{'Sustantivos': ['antea', 'prevencion', 'compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2280</td>\n",
       "      <td>Ingenieros y tecnicos</td>\n",
       "      <td>Electronica y automatica industrial</td>\n",
       "      <td>[oficial, mantenimiento, electromecanico, agua...</td>\n",
       "      <td>mantenimiento preventivo y correctivo de sist...</td>\n",
       "      <td>[mantenimiento, preventivo, correctivo, de, si...</td>\n",
       "      <td>[mantenimiento, preventivo, correctivo, sistem...</td>\n",
       "      <td>[mecanica, correctivos, gmao, electrica, ofici...</td>\n",
       "      <td>{'Sustantivos': ['mantenimiento', 'preventivo'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_puesto_esco_ull              categoria  \\\n",
       "0                1634    Atencion a clientes   \n",
       "1                1984      Ventas al detalle   \n",
       "2                 719       Recursos humanos   \n",
       "3                1508     Comercial y ventas   \n",
       "4                2280  Ingenieros y tecnicos   \n",
       "\n",
       "                          subcategoria  \\\n",
       "0                  Atencion al cliente   \n",
       "1                     Venta al detalle   \n",
       "2                Prevencion de riesgos   \n",
       "3                            Comercial   \n",
       "4  Electronica y automatica industrial   \n",
       "\n",
       "                               palabras_empleo_texto  \\\n",
       "0  [administrativo, persona, reservas, buceo, ges...   \n",
       "1  [dependiente, tiendas, centro, comercial, expe...   \n",
       "2  [puentes, grua, normas, sector, metales, homol...   \n",
       "3  [asesores, comercial, prevencion, riesgos, lab...   \n",
       "4  [oficial, mantenimiento, electromecanico, agua...   \n",
       "\n",
       "                                  descripcion_oferta  \\\n",
       "0  buscamos una persona encargada de gestionar la...   \n",
       "1  se busca dependiente para la tienda tezenis en...   \n",
       "2  grupo loxamhune empresa lider en el alquiler d...   \n",
       "3  antea prevencion es una compania dedicada a la...   \n",
       "4   mantenimiento preventivo y correctivo de sist...   \n",
       "\n",
       "                         palabras_descripcion_oferta  \\\n",
       "0  [buscamos, una, persona, encargada, de, gestio...   \n",
       "1  [se, busca, dependiente, para, la, tienda, tez...   \n",
       "2  [grupo, loxamhune, empresa, lider, en, el, alq...   \n",
       "3  [antea, prevencion, es, una, compania, dedicad...   \n",
       "4  [mantenimiento, preventivo, correctivo, de, si...   \n",
       "\n",
       "                                   palabras_list_all  \\\n",
       "0  [persona, encargado, reserva, actividad, buceo...   \n",
       "1  [busca, dependiente, tienda, centro, comercial...   \n",
       "2  [grupo, empresa, lider, alquiler, maquinaria, ...   \n",
       "3  [antea, prevencion, compania, prevencion, ries...   \n",
       "4  [mantenimiento, preventivo, correctivo, sistem...   \n",
       "\n",
       "                        palabras_legacy_minus_nuevas  \\\n",
       "0  [alojamientos, electronica, data, recepciones,...   \n",
       "1                                 [tiendas, idiomas]   \n",
       "2  [normas, elevadores, certificaciones, metales,...   \n",
       "3  [servicios, empresas, experiencia, seguros, eq...   \n",
       "4  [mecanica, correctivos, gmao, electrica, ofici...   \n",
       "\n",
       "                                       palabras_dict  \n",
       "0  {'Sustantivos': ['persona', 'encargado', 'rese...  \n",
       "1  {'Sustantivos': ['busca', 'dependiente', 'tien...  \n",
       "2  {'Sustantivos': ['grupo', 'empresa', 'lider', ...  \n",
       "3  {'Sustantivos': ['antea', 'prevencion', 'compa...  \n",
       "4  {'Sustantivos': ['mantenimiento', 'preventivo'...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def process_and_update_df(df, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms):\n",
    "    # Create a new column in the DataFrame to store the result\n",
    "    df[\"palabras_list_all\"] = \"\"\n",
    "    df[\"palabras_dict\"] = \"\"\n",
    "    # Iterate over the DataFrame and apply the word extraction function\n",
    "    for index, description in df[\"descripcion_oferta\"].items():\n",
    "        palabras_dict, palabras_list = get_syntax(description, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms)\n",
    "        # Save palabras_list in a new column in the DataFrame, insert the full list\n",
    "        df.at[index, \"palabras_list_all\"] = palabras_list\n",
    "        # Save palabras_dict in a new column in the DataFrame\n",
    "        df.at[index, \"palabras_dict\"] = palabras_dict\n",
    "    # Calculate and add the column with words that appear in palabras legacy but not in palabras nuevas\n",
    "    df[\"palabras_legacy_minus_nuevas\"] = df.apply(lambda row: list(set(row[\"palabras_empleo_texto\"]) - set(row[\"palabras_list_all\"])), axis=1)\n",
    "    return df\n",
    "\n",
    "# Function to measure time and apply the processing function\n",
    "def process_and_measure_time(df, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms):\n",
    "    start_time = time.time()\n",
    "    df = process_and_update_df(df, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms)\n",
    "    print(\"Time: \", time.time() - start_time)\n",
    "    return df\n",
    "# Get the first 5 rows of the DataFrame and save into a new DataFrame\n",
    "test_df = test_df.iloc[0:5].copy()\n",
    "# Call the processing function with your DataFrame\n",
    "test_df = process_and_measure_time(test_df, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms)\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descripcion oferta:  buscamos una persona encargada de gestionar las reservas de nuestras actividades de buceo horario de las mismas gestion de alojamientos venta de actividades y demas acciones administrativas tambien se hara cargo de reservas telefonicas y presenciales asi como de supervisar que el centro fisico este en buenas condiciones \n",
      "Total de palabras en descripción:  49\n",
      "Accuracy - palabras nuevas:  13\n",
      "Error - palabras nuevas:  36\n",
      "Palabras nuevas:  ['persona', 'encargado', 'reserva', 'actividad', 'buceo', 'horario', 'mismas', 'gestion', 'alojamiento', 'venta', 'actividad', 'demas', 'accion', 'administrativo', 'hara', 'cargo', 'reserva', 'asi', 'centro', 'fisico', 'buenas', 'condicion', 'encargado', 'horario', 'administrativo', 'telefonico', 'presencial', 'fisico', 'bueno'] 29\n",
      "Accuracy - palabras legacy:  10\n",
      "Error - palabras legacy:  39\n",
      "Palabras legacy:  ['administrativo', 'persona', 'reservas', 'buceo', 'gestion', 'alojamientos', 'ventas', 'telefonicas', 'supervisar', 'centro', 'fisica', 'condiciones', 'archivo', 'facturaciones', 'correspondencia', 'recepciones', 'atenciones', 'tramitaciones', 'facturas', 'data', 'electronica'] 21\n",
      "Palabras legacy no encontradas en descripción:  ['electronica', 'data', 'recepciones', 'atenciones', 'archivo', 'administrativo', 'ventas', 'facturas', 'tramitaciones', 'correspondencia', 'facturaciones', 'fisica']\n"
     ]
    }
   ],
   "source": [
    "def get_reference(descripcion_oferta, df, index, column):\n",
    "    # Get the accuracy of the words in palabras_empleo_texto that are in descripcion_oferta\n",
    "    error = 0\n",
    "    accuracy = 0\n",
    "    for word in descripcion_oferta:\n",
    "        if unidecode(word) not in df[column].iloc[index]:\n",
    "            error += 1\n",
    "        else:\n",
    "            accuracy += 1\n",
    "    return error, accuracy\n",
    "\n",
    "def show_results(index, test_df):\n",
    "    # Get list of words in descripcion_oferta\n",
    "    descripcion_oferta = test_df[\"descripcion_oferta\"].iloc[index].split(\" \")\n",
    "    error, accuracy = get_reference(descripcion_oferta, test_df, index, \"palabras_list_all\")\n",
    "    # Show descripcion_oferta\n",
    "    print(\"Descripcion oferta: \", test_df[\"descripcion_oferta\"].iloc[index])\n",
    "    print(\"Total de palabras en descripción: \", len(descripcion_oferta))\n",
    "    print(\"Accuracy - palabras nuevas: \", accuracy)\n",
    "    print(\"Error - palabras nuevas: \", error)\n",
    "    # Show palabras list all\n",
    "    print(\"Palabras nuevas: \", test_df[\"palabras_list_all\"].iloc[index], len(test_df[\"palabras_list_all\"].iloc[index]))\n",
    "    # Show palabras_empleo_texto\n",
    "    error, accuracy = get_reference(descripcion_oferta, test_df, index, \"palabras_empleo_texto\")\n",
    "    print(\"Accuracy - palabras legacy: \", accuracy)\n",
    "    print(\"Error - palabras legacy: \", error)\n",
    "    print(\"Palabras legacy: \", test_df[\"palabras_empleo_texto\"].iloc[index], len(test_df[\"palabras_empleo_texto\"].iloc[index]))\n",
    "    # Show the words in palabras_empleo_texto that are not in descripcion_oferta\n",
    "    print(\"Palabras legacy no encontradas en descripción: \", list(set(test_df[\"palabras_empleo_texto\"].iloc[index]) - set(descripcion_oferta)))\n",
    "# Define the Markdown output file\n",
    "output_file = \"results.md\"\n",
    "show_results(0, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_results_to_markdown(index, test_df, output_file):\n",
    "    # Get list of words in descripcion_oferta\n",
    "    descripcion_oferta = test_df[\"descripcion_oferta\"].iloc[index].split(\" \")\n",
    "    error, accuracy = get_reference(descripcion_oferta, test_df, index, \"palabras_list_all\")\n",
    "    \n",
    "    with open(output_file, \"w\") as md_file:\n",
    "        # Write header for the section\n",
    "        md_file.write(f\"**Descripcion oferta:** {test_df['descripcion_oferta'].iloc[index]}\\n\")\n",
    "        md_file.write(f\"**Total de palabras en descripción:** {len(descripcion_oferta)}\\n\")\n",
    "        md_file.write(f\"**Accuracy - palabras nuevas:** {accuracy}\\n\")\n",
    "        md_file.write(f\"**Error - palabras nuevas:** {error}\\n\")\n",
    "        md_file.write(f\"**Palabras nuevas:** {', '.join(test_df['palabras_list_all'].iloc[index])}\\n\")\n",
    "        palabras_not_found = list(set(test_df['palabras_list_all'].iloc[index]) - set(descripcion_oferta))\n",
    "        md_file.write(f\"**Palabras nuevas no encontradas en descripción:** {', '.join(palabras_not_found)}\\n\")\n",
    "        \n",
    "        error, accuracy = get_reference(descripcion_oferta, test_df, index, \"palabras_empleo_texto\")\n",
    "        md_file.write(f\"**Accuracy - palabras legacy:** {accuracy}\\n\")\n",
    "        md_file.write(f\"**Error - palabras legacy:** {error}\\n\")\n",
    "        md_file.write(f\"**Palabras legacy:** {', '.join(test_df['palabras_empleo_texto'].iloc[index])}\\n\")\n",
    "        \n",
    "        palabras_not_found = list(set(test_df['palabras_empleo_texto'].iloc[index]) - set(descripcion_oferta))\n",
    "        md_file.write(f\"**Palabras legacy no encontradas en descripción:** {', '.join(palabras_not_found)}\\n\")\n",
    "\n",
    "# Define the Markdown output file\n",
    "output_file = \"results.md\"\n",
    "\n",
    "# Call the function to export the results to Markdown\n",
    "export_results_to_markdown(1, test_df, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show palabras_legacy_minus_nuevas\n",
    "# print(\"Palabras no encontradas: \", test_df[\"palabras_legacy_minus_nuevas\"].iloc[index], len(test_df[\"palabras_legacy_minus_nuevas\"].iloc[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46157\n"
     ]
    }
   ],
   "source": [
    "# Get the index of \"alojamientos\" in sustantives_forms\n",
    "index = sustantives_forms.index(\"alojamientos\")\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descripcion oferta: buscamos una persona encargada de gestionar las reservas de nuestras actividades de buceo horario de las mismas gestion de alojamientos venta de actividades y demas acciones administrativas tambien se hara cargo de reservas telefonicas y presenciales asi como de supervisar que el centro fisico este en buenas condiciones \n",
      "\n",
      "Palabras legacy: administrativo persona reservas buceo gestion alojamientos ventas telefonicas supervisar centro fisica condiciones archivo facturaciones correspondencia recepciones atenciones tramitaciones facturas data electronica\n",
      "\n",
      "Palabras nuevas: encargado horario administrativo fisico bueno\n",
      "\n",
      "Palabras legacy - Palabras nuevas: recepciones supervisar condiciones facturaciones alojamientos data atenciones buceo ventas persona telefonicas tramitaciones archivo reservas correspondencia centro electronica gestion facturas fisica\n"
     ]
    }
   ],
   "source": [
    "print(\"Descripcion oferta: \" + descriptions[0])\n",
    "print()\n",
    "print(\"Palabras legacy: \" + ' '.join(palabras_empleo_texto[0]))\n",
    "print()\n",
    "print(\"Palabras nuevas: \" + ' '.join(palabras_list_all[0]))\n",
    "# Print the words that from palabras legacy that not appear in palabras nuevas\n",
    "print()\n",
    "print(\"Palabras legacy - Palabras nuevas: \" + ' '.join(list(set(palabras_empleo_texto[0]) - set(palabras_list_all[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso:\n",
    "offer = \"\"\"\n",
    "En España está presente desde hace más de 25 años, con más de 130 oficinas y más de 1.800 Agentes asociados. Seleccionamos asesores inmobiliarios para nuestra oficina en calle Carvajal, con o sin experiencia.\n",
    "Te ofrecemos tener tu negocio propio con la menor inversión del mercado trabajando en la empresa líder de Canarias es la mejor elección para profesionales como tu para la industria inmobiliaria y sus clientes, a través de la creación de un entorno de trabajo Sinérgico, transformando y profesionalizando esta industria.\n",
    "Con RE/MAX puedes llegar a lo más alto de la profesión Inmobiliaria.\n",
    "¿Qué hace un agente asociado RE/MAX?\n",
    "\n",
    "- Calificar nuevos clientes.\n",
    "- Estudia el mercado donde trabaja.\n",
    "- Capta nuevos inmuebles para la venta.\n",
    "- Elabora planes de marketing para los inmuebles en cartera.\n",
    "- Atiende y da el seguimiento a las necesidades de sus clientes\n",
    "- Aconseja financieramente a sus clientes.\n",
    "- Concreta la venta de los inmuebles en cartera.\n",
    "- Realiza valoraciones de valor de mercado de los inmuebles.\n",
    "\"\"\"\n",
    "\n",
    "def test_unitary(offer):\n",
    "    start_time = time.time()\n",
    "    palabras_dict, palabras_list = get_syntax(offer, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms, estricto=True)\n",
    "    print(\"Time: \", time.time() - start_time)\n",
    "    return palabras_dict, palabras_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
