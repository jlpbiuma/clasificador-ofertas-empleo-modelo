{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import collocations dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLLOCATION</th>\n",
       "      <th>COLLOCATION_VISUAL</th>\n",
       "      <th>RAIZ_COLLOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOSTRAR INICIATIVA</td>\n",
       "      <td>MOSTRAR INICIATIVA</td>\n",
       "      <td>MOSTR INICI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRABAJAR SOLISTAS</td>\n",
       "      <td>TRABAJAR CON SOLISTAS</td>\n",
       "      <td>TRABAJ SOLIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FABRICAR INGREDIENTES</td>\n",
       "      <td>FABRICAR INGREDIENTES</td>\n",
       "      <td>FABRIC INGREDIENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TECNICAS ASERRADO</td>\n",
       "      <td>TECNICAS DE ASERRADO</td>\n",
       "      <td>TECNIC ASERR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VULCANIZADO FRIO</td>\n",
       "      <td>VULCANIZADO EN FRIO</td>\n",
       "      <td>VULCANIZ FRI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             COLLOCATION     COLLOCATION_VISUAL   RAIZ_COLLOCATION\n",
       "0     MOSTRAR INICIATIVA     MOSTRAR INICIATIVA        MOSTR INICI\n",
       "1      TRABAJAR SOLISTAS  TRABAJAR CON SOLISTAS      TRABAJ SOLIST\n",
       "2  FABRICAR INGREDIENTES  FABRICAR INGREDIENTES  FABRIC INGREDIENT\n",
       "3      TECNICAS ASERRADO   TECNICAS DE ASERRADO       TECNIC ASERR\n",
       "4       VULCANIZADO FRIO    VULCANIZADO EN FRIO       VULCANIZ FRI"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_path = './static/'\n",
    "# Read collacations dictionary as list of dicts is a json file\n",
    "with open(dictionary_path + 'diccionario_collocation.json', 'r') as f:\n",
    "    collocations = json.load(f)\n",
    "# Cast to dataframe and get only the columns\n",
    "columns = ['COLLOCATION', 'COLLOCATION_VISUAL', 'RAIZ_COLLOCATION']\n",
    "df_collocations = pd.DataFrame(collocations)[columns]\n",
    "df_collocations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy function find collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('spanish')\n",
    "\n",
    "def f_vector_collocation_json(texto):\n",
    "    # importamos las librerías necesarias\n",
    "\n",
    "    # Obtenemos las stopwords del idioma del módulo nltk\n",
    "    \n",
    "\n",
    "    # adverbios\n",
    "    adverbios = ['ahora', 'antes', 'despues', 'tarde', 'luego', 'ayer', 'temprano', 'ya',\n",
    "                 'todavia', 'anteayer', 'aun', 'pronto', 'hoy', 'aqui', 'ahi', 'alli',\n",
    "                 'cerca', 'lejos', 'fuera', 'dentro', 'alrededor', 'aparte', 'encima',\n",
    "                 'debajo', 'delante', 'detras', 'asi', 'bien', 'mal', 'despacio',\n",
    "                 'deprisa', 'como', 'mucho', 'poco', 'muy', 'casi', 'todo', 'nada', 'algo',\n",
    "                 'medio', 'demasiado', 'bastante', 'mas', 'menos', 'ademas', 'incluso',\n",
    "                 'tambien', 'si', 'asimismo', 'no', 'tampoco', 'jamas', 'nunca', 'acaso',\n",
    "                 'quiza', 'quizas', 'tal', 'vez', 'mejor']\n",
    "    stopwords.extend(adverbios)\n",
    "\n",
    "    # obtengo en un dataframe el diccionario de collocation\n",
    "    with open(dictionary_path + 'diccionario_collocation.json',\n",
    "              encoding=\"latin-1\") as f:\n",
    "        aux_collocations = f.read()\n",
    "    diccionario_collocations = json.loads(aux_collocations)\n",
    "\n",
    "    # obtengo en un dataframe el diccionario de equivalencias de collocation\n",
    "    with open(dictionary_path + 'diccionario_equivalencias_collocation.json',\n",
    "              encoding=\"latin-1\") as f:\n",
    "        aux_equiv = f.read()\n",
    "    dic_equiv_collocations = json.loads(aux_equiv)\n",
    "\n",
    "    vector_collocation = list()\n",
    "    collocations_dic = list()\n",
    "    collocations_equiv = list()\n",
    "\n",
    "    for i in range(len(diccionario_collocations)):\n",
    "        collocations_dic.append(diccionario_collocations[i]['RAIZ_COLLOCATION'])\n",
    "\n",
    "    for i in range(len(dic_equiv_collocations)):\n",
    "        collocations_equiv.append(dic_equiv_collocations[i]['RAIZ_COLLOCATION'])\n",
    "\n",
    "    stemmer = SnowballStemmer(\"spanish\")\n",
    "\n",
    "    lista_palabras = str(texto).lower()\n",
    "    palabras = lista_palabras.split()\n",
    "    filtered_words = [word for word in palabras if word not in stopwords]\n",
    "\n",
    "    table = {33: 32, 35: 32, 36: 32, 37: 32, 94: 32, 38: 32, 42: 32, 40: 32, 41: 32, 91: 32, 93: 32,\n",
    "             123: 32, 125: 32, 58: 32, 59: 32, 44: 32, 47: 32, 60: 32, 62: 32, 92: 32, 124: 32, 96: 32,\n",
    "             126: 32, 45: 32, 34: 32, 39: 32, 61: 32, 95: 32, 43: 32}\n",
    "\n",
    "    palabras_encontradas = []\n",
    "\n",
    "    for j in range(len(filtered_words)):\n",
    "        sin_simbolo = filtered_words[j].replace(\"¡\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"»\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"«\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"¿\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"°\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"º\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ª\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"_x000d_\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"@\", \"o\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"á\", \"a\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"à\", \"a\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"À\", \"a\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Á\", \"a\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"é\", \"e\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"è\", \"e\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"È\", \"e\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"É\", \"e\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"í\", \"i\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ì\", \"i\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Ì\", \"i\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Í\", \"i\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ó\", \"o\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ò\", \"o\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Ò\", \"o\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Ó\", \"o\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ú\", \"u\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ù\", \"u\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Ù\", \"u\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Ú\", \"u\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ñ\", \"ñ\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"?\", \"\")\n",
    "        tratar = sin_simbolo.strip(r\"!#$%^&*()[]{};:,./<>?\\|`~-'=_·\")\n",
    "        tratar2 = tratar.translate(table)\n",
    "        palabras = tratar2.split()\n",
    "        tokens = []\n",
    "        for palabra in palabras:\n",
    "            if palabra not in stopwords:\n",
    "                tokens.append(palabra.upper())\n",
    "        for w in tokens:\n",
    "            es_numero = w.isdigit()\n",
    "            if len(w) > 2 and not es_numero:\n",
    "                palabras_encontradas.append(w)\n",
    "    collocations = []\n",
    "    for n in [2, 3]:\n",
    "        collocations.extend(nltk.ngrams(palabras_encontradas, n))\n",
    "\n",
    "    for coll in collocations:\n",
    "        if len(coll) == 2:\n",
    "            coll_final = coll[0] + \" \" + coll[1]\n",
    "        if len(coll) == 3:\n",
    "            coll_final = coll[0] + \" \" + coll[1] + \" \" + coll[2]\n",
    "        coll_sep = coll_final.split(sep=' ')\n",
    "        coll_def = \"\"\n",
    "        for k in range(len(coll_sep)):\n",
    "            coll_def = coll_def + stemmer.stem(coll_sep[k]).upper() + \" \"\n",
    "        coll_def = coll_def[:-1]\n",
    "        if coll_def in collocations_dic and coll_final not in vector_collocation:\n",
    "            vector_collocation.append(coll_final)\n",
    "        elif coll_def in collocations_equiv and coll_final not in vector_collocation:\n",
    "            vector_collocation.append(coll_final)\n",
    "\n",
    "    value = {\n",
    "        \"vector_collocation\": vector_collocation\n",
    "    }\n",
    "\n",
    "    return json.dumps(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"vector_collocation\": [\"OFERTA EMPLEO\"]}\n"
     ]
    }
   ],
   "source": [
    "texto = '''\n",
    "Oferta de empleo de ingeniero de software con experiencia en desarrollo de aplicaciones web y móviles. Voz sobre protocolo de internet Necesaria experiencia en Python, Java y C++.\n",
    "'''\n",
    "lista_palabras = f_vector_collocation_json(texto)\n",
    "print(lista_palabras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OFERTA', 'EMPLEO', 'INGENIERO', 'SOFTWARE', 'EXPERIENCIA', 'DESARROLLO', 'APLICACIONES', 'WEB', 'MOVILES', 'VOZ', 'PROTOCOLO', 'INTERNET', 'NECESARIA', 'EXPERIENCIA', 'PYTHON', 'JAVA', 'C']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "expections = [\"@\", r\"\\.\"]\n",
    "\n",
    "def clean_text(text):\n",
    "    # ! EXCEPCIONES MANUALES!!!\n",
    "    # Cast exceptions to \"a\"\n",
    "    text = re.sub(r'@', 'a', text)\n",
    "    # Cast from \".\" to \"\"\n",
    "    text = re.sub(r'\\.', '', text)\n",
    "    \n",
    "    # Trim the text\n",
    "    text = text.strip()\n",
    "    # Remove accents using unidecode, excluding 'ñ' and 'Ñ'\n",
    "    text = ''.join(char if char in ('ñ', 'Ñ') else unidecode(char) for char in text)\n",
    "    # Delete non-alphanumeric characters\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # Delete additional spaces with regex\n",
    "    text = re.sub(r'\\s+', ' ', text).upper()\n",
    "    return text\n",
    "texto = '''\n",
    "Oferta de empleo de ingeniero de software con experiencia en desarrollo de aplicaciones web y móviles. Voz sobre protocolo de internet Necesaria experiencia en Python, Java y C++.\n",
    "'''\n",
    "texto = clean_text(texto)\n",
    "# Split the text by \" \"\n",
    "list_words = texto.split(\" \")\n",
    "# Delete empty strings\n",
    "list_words = list(filter(None, list_words))\n",
    "# Change all stopwords to uppercase\n",
    "stopwords = [word.upper() for word in stopwords]\n",
    "# Delete stopwords\n",
    "list_words = [word for word in list_words if word not in stopwords]\n",
    "print(list_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get list of stems for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "def filter_words(text):\n",
    "    # Split the text by \" \"\n",
    "    list_words = text.split(\" \")\n",
    "    # Delete empty strings\n",
    "    list_words = list(filter(None, list_words))\n",
    "    # Filter all stopwords\n",
    "    return [word for word in list_words if word not in stopwords]\n",
    "\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "\n",
    "def get_list_stems(list_words):\n",
    "    # Get stems\n",
    "    return [stemmer.stem(word).upper() for word in list_words]\n",
    "\n",
    "def get_n_gramas(list_stems, min_n_gramas, max_n_gramas):\n",
    "    list_n_gramas = [\" \".join(n_grama) for n in range(min_n_gramas, max_n_gramas + 1)\n",
    "                     for n_grama in nltk.ngrams(list_stems, n)]\n",
    "    return list_n_gramas\n",
    "\n",
    "def calculate_forms(text, min_n_gramas=2, max_n_gramas=4):\n",
    "    # First clean text\n",
    "    text = clean_text(text)\n",
    "    # Filter words\n",
    "    list_words = filter_words(text)\n",
    "    # Get list of stems\n",
    "    list_stems = get_list_stems(list_words)\n",
    "    # Get the n gramas\n",
    "    list_n_gramas = get_n_gramas(list_stems, min_n_gramas, max_n_gramas)\n",
    "    if list_n_gramas != []:\n",
    "        return list_n_gramas\n",
    "    else:\n",
    "        return None\n",
    "texto = '''\n",
    "SENTIDO DE RESPONSABILIDAD\n",
    "'''\n",
    "list_n_gramas = calculate_forms(texto)\n",
    "print(list_n_gramas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo de FORMAS a partir de COLLOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_GRAMAS</th>\n",
       "      <th>RAIZ_COLLOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[CLASIF PESC]</td>\n",
       "      <td>CLASIFICACION PESC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[TRASTORN ALIMENT]</td>\n",
       "      <td>TRASTORN ALIMENTACION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>[TECNIC COMPACT]</td>\n",
       "      <td>TECNIC COMPACTACION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>[CLASIF DEUD]</td>\n",
       "      <td>CLASIFICACION DEUD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>[MODELIZ RIESG]</td>\n",
       "      <td>MODELIZACION RIESG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               N_GRAMAS       RAIZ_COLLOCATION\n",
       "39        [CLASIF PESC]     CLASIFICACION PESC\n",
       "46   [TRASTORN ALIMENT]  TRASTORN ALIMENTACION\n",
       "459    [TECNIC COMPACT]    TECNIC COMPACTACION\n",
       "469       [CLASIF DEUD]     CLASIFICACION DEUD\n",
       "483     [MODELIZ RIESG]     MODELIZACION RIESG"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate all n_gramas for the column COLLOCATION_VISUAL in a new column\n",
    "df_collocations['N_GRAMAS'] = df_collocations['COLLOCATION'].apply(calculate_forms)\n",
    "# Compare the column N_GRAMAS with the column RAIZ_COLLOCATION\n",
    "def compare_n_gramas(n_gramas, raiz_collocation):\n",
    "    if n_gramas is not None and raiz_collocation in n_gramas:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "# Create a new column with the result of the comparison\n",
    "df_collocations['RESULT'] = df_collocations.apply(lambda row: compare_n_gramas(row['N_GRAMAS'], row['RAIZ_COLLOCATION']), axis=1)\n",
    "# Show all non True values in the column RESULT\n",
    "df_differences = df_collocations[df_collocations['RESULT'] != True][['N_GRAMAS', 'RAIZ_COLLOCATION']]\n",
    "df_differences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the max total forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLLOCATION</th>\n",
       "      <th>COLLOCATION_VISUAL</th>\n",
       "      <th>RAIZ_COLLOCATION</th>\n",
       "      <th>N_GRAMAS</th>\n",
       "      <th>RESULT</th>\n",
       "      <th>N_FORMAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8576</th>\n",
       "      <td>SABER MANEJAR COSTES EXPLOTACION</td>\n",
       "      <td>SABER MANEJAR COSTES DE EXPLOTACIÓN</td>\n",
       "      <td>SAB MANEJ COST EXPLOTACION</td>\n",
       "      <td>[SAB MANEJ, MANEJ COST, COST EXPLOT, SAB MANEJ...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8546</th>\n",
       "      <td>LONG SHORT TERM MEMORY</td>\n",
       "      <td>LONG-SHORT TERM MEMORY</td>\n",
       "      <td>LONG SHORT TERM MEMORY</td>\n",
       "      <td>[LONG SHORT, SHORT TERM, TERM MEMORY, LONG SHO...</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8584</th>\n",
       "      <td>INTERES DESARROLLAR CARRERA PROFESIONAL</td>\n",
       "      <td>INTERÉS POR DESARROLLAR UNA CARRERA PROFESIONAL</td>\n",
       "      <td>INTER DESARROLL CARRER PROFESIONAL</td>\n",
       "      <td>[INTER DESARROLL, DESARROLL CARRER, CARRER PRO...</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8583</th>\n",
       "      <td>GESTION GRANDES GRUPOS EQUIPOS</td>\n",
       "      <td>GESTIÓN DE GRANDES GRUPOS O EQUIPOS</td>\n",
       "      <td>GESTION GRAND GRUP EQUIP</td>\n",
       "      <td>[GESTION GRAND, GRAND GRUP, GRUP EQUIP, GESTIO...</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581</th>\n",
       "      <td>CREADOR BUEN AMBIENTE TRABAJO</td>\n",
       "      <td>CREADOR DE BUEN AMBIENTE DE TRABAJO</td>\n",
       "      <td>CREADOR BUEN AMBIENT TRABAJ</td>\n",
       "      <td>[CREADOR BUEN, BUEN AMBIENT, AMBIENT TRABAJ, C...</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  COLLOCATION  \\\n",
       "8576         SABER MANEJAR COSTES EXPLOTACION   \n",
       "8546                   LONG SHORT TERM MEMORY   \n",
       "8584  INTERES DESARROLLAR CARRERA PROFESIONAL   \n",
       "8583           GESTION GRANDES GRUPOS EQUIPOS   \n",
       "8581            CREADOR BUEN AMBIENTE TRABAJO   \n",
       "\n",
       "                                   COLLOCATION_VISUAL  \\\n",
       "8576              SABER MANEJAR COSTES DE EXPLOTACIÓN   \n",
       "8546                           LONG-SHORT TERM MEMORY   \n",
       "8584  INTERÉS POR DESARROLLAR UNA CARRERA PROFESIONAL   \n",
       "8583              GESTIÓN DE GRANDES GRUPOS O EQUIPOS   \n",
       "8581              CREADOR DE BUEN AMBIENTE DE TRABAJO   \n",
       "\n",
       "                        RAIZ_COLLOCATION  \\\n",
       "8576          SAB MANEJ COST EXPLOTACION   \n",
       "8546              LONG SHORT TERM MEMORY   \n",
       "8584  INTER DESARROLL CARRER PROFESIONAL   \n",
       "8583            GESTION GRAND GRUP EQUIP   \n",
       "8581         CREADOR BUEN AMBIENT TRABAJ   \n",
       "\n",
       "                                               N_GRAMAS  RESULT  N_FORMAS  \n",
       "8576  [SAB MANEJ, MANEJ COST, COST EXPLOT, SAB MANEJ...   False         4  \n",
       "8546  [LONG SHORT, SHORT TERM, TERM MEMORY, LONG SHO...    True         4  \n",
       "8584  [INTER DESARROLL, DESARROLL CARRER, CARRER PRO...    True         4  \n",
       "8583  [GESTION GRAND, GRAND GRUP, GRUP EQUIP, GESTIO...    True         4  \n",
       "8581  [CREADOR BUEN, BUEN AMBIENT, AMBIENT TRABAJ, C...    True         4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_clean_text(text):\n",
    "    # Clean text\n",
    "    text = clean_text(text)\n",
    "    # Filter words\n",
    "    list_words = filter_words(text)\n",
    "    return list_words\n",
    "\n",
    "def get_all_forms(text):\n",
    "    list_words = get_clean_text(text)\n",
    "    return len(list_words)\n",
    "\n",
    "\n",
    "texto = '''\n",
    "Oferta de empleo de ingeniero de software con experiencia en desarrollo de aplicaciones web y móviles. Voz sobre protocolo de internet Necesaria experiencia en Python, Java y C++.\n",
    "'''\n",
    "df_collocations['N_FORMAS'] = df_collocations['COLLOCATION_VISUAL'].apply(get_all_forms)\n",
    "# Order by N_FORMAS\n",
    "df_collocations.sort_values(by=['N_FORMAS'], ascending=False, inplace=True)\n",
    "df_collocations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export new COLLOCATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['COLLOCATION', 'COLLOCATION_VISUAL', 'RAIZ_COLLOCATION', 'N_GRAMAS',\n",
      "       'RESULT', 'N_FORMAS'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_collocations.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19278, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LEMA</th>\n",
       "      <th>COLLOCATION</th>\n",
       "      <th>FORMAS</th>\n",
       "      <th>N_WORDS_FORMAS</th>\n",
       "      <th>N_WORDS_LEMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7385</th>\n",
       "      <td>ABBYY FINEREADER</td>\n",
       "      <td>ABBYY FINEREADER</td>\n",
       "      <td>ABBYY FINEREAD</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>ABOGAR PERSONAS</td>\n",
       "      <td>ABOGAR POR OTRAS PERSONAS</td>\n",
       "      <td>ABOG PERSON</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>ASESORAR ABONOS PLANTAS</td>\n",
       "      <td>ASESORAR SOBRE ABONOS PARA PLANTAS</td>\n",
       "      <td>ABON PLANT</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>ABRASIVOS CHORRO</td>\n",
       "      <td>ABRASIVOS DE CHORRO</td>\n",
       "      <td>ABRAS CHORR</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>ABRIR CUENTAS BANCO</td>\n",
       "      <td>ABRIR CUENTAS DE BANCO</td>\n",
       "      <td>ABRIR CUENT</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>ABRIR CUENTAS BANCO</td>\n",
       "      <td>ABRIR CUENTAS DE BANCO</td>\n",
       "      <td>ABRIR CUENT BANC</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8207</th>\n",
       "      <td>ABRIR GALERIAS CONDUCCIONES</td>\n",
       "      <td>ABRIR GALERIAS DE CONDUCCIONES</td>\n",
       "      <td>ABRIR GALERI</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8207</th>\n",
       "      <td>ABRIR GALERIAS CONDUCCIONES</td>\n",
       "      <td>ABRIR GALERIAS DE CONDUCCIONES</td>\n",
       "      <td>ABRIR GALERI CONDUCCION</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>ABROCHAR DISPOSITIVOS SEGURIDAD</td>\n",
       "      <td>ABROCHAR LOS DISPOSITIVOS DE SEGURIDAD</td>\n",
       "      <td>ABROCH DISPOSIT</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>ABROCHAR DISPOSITIVOS SEGURIDAD</td>\n",
       "      <td>ABROCHAR LOS DISPOSITIVOS DE SEGURIDAD</td>\n",
       "      <td>ABROCH DISPOSIT SEGUR</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 LEMA                             COLLOCATION  \\\n",
       "7385                 ABBYY FINEREADER                        ABBYY FINEREADER   \n",
       "2298                  ABOGAR PERSONAS               ABOGAR POR OTRAS PERSONAS   \n",
       "3680          ASESORAR ABONOS PLANTAS      ASESORAR SOBRE ABONOS PARA PLANTAS   \n",
       "2047                 ABRASIVOS CHORRO                     ABRASIVOS DE CHORRO   \n",
       "4050              ABRIR CUENTAS BANCO                  ABRIR CUENTAS DE BANCO   \n",
       "4050              ABRIR CUENTAS BANCO                  ABRIR CUENTAS DE BANCO   \n",
       "8207      ABRIR GALERIAS CONDUCCIONES          ABRIR GALERIAS DE CONDUCCIONES   \n",
       "8207      ABRIR GALERIAS CONDUCCIONES          ABRIR GALERIAS DE CONDUCCIONES   \n",
       "4594  ABROCHAR DISPOSITIVOS SEGURIDAD  ABROCHAR LOS DISPOSITIVOS DE SEGURIDAD   \n",
       "4594  ABROCHAR DISPOSITIVOS SEGURIDAD  ABROCHAR LOS DISPOSITIVOS DE SEGURIDAD   \n",
       "\n",
       "                       FORMAS  N_WORDS_FORMAS  N_WORDS_LEMA  \n",
       "7385           ABBYY FINEREAD               2             2  \n",
       "2298              ABOG PERSON               2             2  \n",
       "3680               ABON PLANT               2             3  \n",
       "2047              ABRAS CHORR               2             2  \n",
       "4050              ABRIR CUENT               2             3  \n",
       "4050         ABRIR CUENT BANC               3             3  \n",
       "8207             ABRIR GALERI               2             3  \n",
       "8207  ABRIR GALERI CONDUCCION               3             3  \n",
       "4594          ABROCH DISPOSIT               2             3  \n",
       "4594    ABROCH DISPOSIT SEGUR               3             3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get only the columns COLLOCATION, COLLOCATION_VISUAL and N_GRAMAS\n",
    "df_new_collocations = df_collocations[['COLLOCATION', 'COLLOCATION_VISUAL', 'N_GRAMAS']]\n",
    "# Rename columns as LEMA, COLLOCATION and FORMAS\n",
    "df_new_collocations.columns = ['LEMA', 'COLLOCATION', 'FORMAS']\n",
    "# # Explode the dataframe by the column FORMAS\n",
    "df_new_collocations = df_new_collocations.explode('FORMAS')\n",
    "# # Drop duplicates\n",
    "df_new_collocations.drop_duplicates(inplace=True)\n",
    "# Drop empty strings\n",
    "df_new_collocations = df_new_collocations[(df_new_collocations['FORMAS'] != '') & (~df_new_collocations['FORMAS'].isnull())]\n",
    "print(df_new_collocations.shape)\n",
    "# Get the number of words for each FORMAS\n",
    "df_new_collocations['N_WORDS_FORMAS'] = df_new_collocations['FORMAS'].apply(lambda x: len(x.split(\" \")))\n",
    "# Get the number of words for each LEMA\n",
    "df_new_collocations['N_WORDS_LEMA'] = df_new_collocations['LEMA'].apply(lambda x: len(x.split(\" \")))\n",
    "# Get all the registers with same number of N_WORDS_LEMA and N_WORDS_FORMAS\n",
    "# df_new_collocations = df_new_collocations[df_new_collocations['N_WORDS_LEMA'] == df_new_collocations['N_WORDS_FORMAS']]\n",
    "# Order alphabetically by FORMAS\n",
    "df_new_collocations.sort_values(by=['FORMAS', 'N_WORDS_FORMAS'], ascending=True, inplace=True)\n",
    "# Save the dataframe as csv\n",
    "df_new_collocations.to_csv(dictionary_path + 'diccionario_collocation.csv', index=False)\n",
    "# Show the dataframe\n",
    "df_new_collocations.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find by forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5687         GESTIONAR DOCUMENTOS DIGITALES\n",
      "6062    GESTIONAR DOCUMENTACION FABRICACION\n",
      "2372                     GESTION DOCUMENTOS\n",
      "Name: LEMA, dtype: object\n"
     ]
    }
   ],
   "source": [
    "forma = \"GESTION DOCUMENT\"\n",
    "# Find the df_new_collocations with the FORMAS == forma\n",
    "print(df_new_collocations[df_new_collocations['FORMAS'] == forma][\"LEMA\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
