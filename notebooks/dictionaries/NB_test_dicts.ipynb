{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.tools import load_json\n",
    "import pandas as pd\n",
    "import time\n",
    "from unidecode import unidecode\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ofertas = 50099\n",
    "index_chars = 2\n",
    "filename = \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50099, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_oferta</th>\n",
       "      <th>id_puesto_esco_ull</th>\n",
       "      <th>categoria</th>\n",
       "      <th>subcategoria</th>\n",
       "      <th>asunto</th>\n",
       "      <th>requisitos_minimos</th>\n",
       "      <th>descripcion_oferta</th>\n",
       "      <th>skills</th>\n",
       "      <th>palabras_empleo_texto</th>\n",
       "      <th>requisitos_deseados</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ef5a8ae0a743018628df9bd53893bb</td>\n",
       "      <td>1634</td>\n",
       "      <td>Administración de empresas</td>\n",
       "      <td>Administración</td>\n",
       "      <td>Administrativo con inglés y Navision Turno tarde</td>\n",
       "      <td>-Conocimientos de inglés avanzado (hablado y e...</td>\n",
       "      <td>Empresa de carácter internacional solicita adm...</td>\n",
       "      <td>Microsoft Dynamics NAV (Navision) INGLES Logí...</td>\n",
       "      <td>ADMINISTRATIVO INGLES NAVISION EMPRESAS CARACT...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47137c06a640348ca4cb7dcbf938b1</td>\n",
       "      <td>611</td>\n",
       "      <td>Sanidad y salud</td>\n",
       "      <td>Medicina general</td>\n",
       "      <td>Médico/a</td>\n",
       "      <td>-Ser Licenciado/a o tener el Grado en Medicina...</td>\n",
       "      <td>Las funciones a desempeñar son las propias del...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEDICO MEDICINA DIAGNOSTICO TRATAMIENTO LICENC...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cdfb72672340819a6721db72eee187</td>\n",
       "      <td>2825</td>\n",
       "      <td>Comercial y ventas</td>\n",
       "      <td>Comercial</td>\n",
       "      <td>REPARTIDOR-AUTOVENTAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buscamos persona para puesto de Chófer -Repart...</td>\n",
       "      <td>ventas-reparto-almacen</td>\n",
       "      <td>REPARTIDOR PERSONA CHOFER VENTAS CLIENTES SEGU...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5746210e854264aaca9452f4d377a4</td>\n",
       "      <td>1984</td>\n",
       "      <td>Ventas al detalle</td>\n",
       "      <td>Venta al detalle</td>\n",
       "      <td>Dependiente/a</td>\n",
       "      <td>No se requiere experiencia previa.</td>\n",
       "      <td>Abrimos proceso de selección para dependiente ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEPENDIENTE PROCESOS SELECCION COMERCIAL TIEND...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8a1bda0c91438bb4133f32e392a1ce</td>\n",
       "      <td>1984</td>\n",
       "      <td>Ventas al detalle</td>\n",
       "      <td>Venta al detalle</td>\n",
       "      <td>DEPENDIENTE/A STRADIVARIUS CC. PALMERAS (FUERT...</td>\n",
       "      <td>Queremos incorporar personas con pasión por la...</td>\n",
       "      <td>Tus funciones principales serán:\\n\\n- Atención...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEPENDIENTE PALMERAS SEMANALES ATENCIONES VENT...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id_oferta  id_puesto_esco_ull  \\\n",
       "0  ef5a8ae0a743018628df9bd53893bb                1634   \n",
       "1  47137c06a640348ca4cb7dcbf938b1                 611   \n",
       "2  cdfb72672340819a6721db72eee187                2825   \n",
       "3  5746210e854264aaca9452f4d377a4                1984   \n",
       "4  8a1bda0c91438bb4133f32e392a1ce                1984   \n",
       "\n",
       "                    categoria      subcategoria  \\\n",
       "0  Administración de empresas    Administración   \n",
       "1             Sanidad y salud  Medicina general   \n",
       "2          Comercial y ventas         Comercial   \n",
       "3           Ventas al detalle  Venta al detalle   \n",
       "4           Ventas al detalle  Venta al detalle   \n",
       "\n",
       "                                              asunto  \\\n",
       "0   Administrativo con inglés y Navision Turno tarde   \n",
       "1                                           Médico/a   \n",
       "2                              REPARTIDOR-AUTOVENTAS   \n",
       "3                                      Dependiente/a   \n",
       "4  DEPENDIENTE/A STRADIVARIUS CC. PALMERAS (FUERT...   \n",
       "\n",
       "                                  requisitos_minimos  \\\n",
       "0  -Conocimientos de inglés avanzado (hablado y e...   \n",
       "1  -Ser Licenciado/a o tener el Grado en Medicina...   \n",
       "2                                                NaN   \n",
       "3                 No se requiere experiencia previa.   \n",
       "4  Queremos incorporar personas con pasión por la...   \n",
       "\n",
       "                                  descripcion_oferta  \\\n",
       "0  Empresa de carácter internacional solicita adm...   \n",
       "1  Las funciones a desempeñar son las propias del...   \n",
       "2  Buscamos persona para puesto de Chófer -Repart...   \n",
       "3  Abrimos proceso de selección para dependiente ...   \n",
       "4  Tus funciones principales serán:\\n\\n- Atención...   \n",
       "\n",
       "                                              skills  \\\n",
       "0   Microsoft Dynamics NAV (Navision) INGLES Logí...   \n",
       "1                                                NaN   \n",
       "2                             ventas-reparto-almacen   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                               palabras_empleo_texto requisitos_deseados  \n",
       "0  ADMINISTRATIVO INGLES NAVISION EMPRESAS CARACT...                 NaN  \n",
       "1  MEDICO MEDICINA DIAGNOSTICO TRATAMIENTO LICENC...                 NaN  \n",
       "2  REPARTIDOR PERSONA CHOFER VENTAS CLIENTES SEGU...                 NaN  \n",
       "3  DEPENDIENTE PROCESOS SELECCION COMERCIAL TIEND...                 NaN  \n",
       "4  DEPENDIENTE PALMERAS SEMANALES ATENCIONES VENT...                 NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_json(\"../../data/RAW/TRAIN_TEST_full_attributes.json\")\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sustantives_df = pd.read_csv('../../data/diccionario/df_structured_sustantivos.csv')\n",
    "adjectives_df = pd.read_csv('../../data/diccionario/df_structured_adjetivos.csv')\n",
    "adverbs_df = pd.read_csv('../../data/diccionario/df_structured_adverbios.csv')\n",
    "verbs_df = pd.read_csv('../../data/diccionario/df_structured_verbos.csv')\n",
    "# Read the txt files sustantives and adjectives\n",
    "with open('../../data/diccionario/list_unstructured_sustantivos.txt', 'r') as f:\n",
    "    sustantives_forms = f.read().splitlines()\n",
    "with open('../../data/diccionario/list_unstructured_adjetivos.txt', 'r') as f:\n",
    "    adjectives_forms = f.read().splitlines()\n",
    "# with open('../../data/diccionario/list_unstructured_verbs.txt', 'r') as f:\n",
    "#     verbs_forms = f.read().splitlines()\n",
    "with open('../../data/diccionario/list_unstructured_adverbios.txt', 'r') as f:\n",
    "    adverbs_forms = f.read().splitlines()\n",
    "# Get the spanish stopwords with nltk\n",
    "stop_words = stopwords.words('spanish')\n",
    "# Cast all word to unicode\n",
    "sustantives_forms = [unidecode(word) for word in sustantives_forms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix TRAIN_TEST_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_oferta</th>\n",
       "      <th>id_puesto_esco_ull</th>\n",
       "      <th>categoria</th>\n",
       "      <th>subcategoria</th>\n",
       "      <th>asunto</th>\n",
       "      <th>requisitos_minimos</th>\n",
       "      <th>descripcion_oferta</th>\n",
       "      <th>skills</th>\n",
       "      <th>palabras_empleo_texto</th>\n",
       "      <th>requisitos_deseados</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ef5a8ae0a743018628df9bd53893bb</td>\n",
       "      <td>1634</td>\n",
       "      <td>Administracion de empresas</td>\n",
       "      <td>Administracion</td>\n",
       "      <td>Administrativo con inglés y Navision Turno tarde</td>\n",
       "      <td>-Conocimientos de inglés avanzado (hablado y e...</td>\n",
       "      <td>Empresa de carácter internacional solicita adm...</td>\n",
       "      <td>Microsoft Dynamics NAV (Navision) INGLES Logí...</td>\n",
       "      <td>ADMINISTRATIVO INGLES NAVISION EMPRESAS CARACT...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47137c06a640348ca4cb7dcbf938b1</td>\n",
       "      <td>611</td>\n",
       "      <td>Sanidad y salud</td>\n",
       "      <td>Medicina general</td>\n",
       "      <td>Médico/a</td>\n",
       "      <td>-Ser Licenciado/a o tener el Grado en Medicina...</td>\n",
       "      <td>Las funciones a desempeñar son las propias del...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEDICO MEDICINA DIAGNOSTICO TRATAMIENTO LICENC...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cdfb72672340819a6721db72eee187</td>\n",
       "      <td>2825</td>\n",
       "      <td>Comercial y ventas</td>\n",
       "      <td>Comercial</td>\n",
       "      <td>REPARTIDOR-AUTOVENTAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buscamos persona para puesto de Chófer -Repart...</td>\n",
       "      <td>ventas-reparto-almacen</td>\n",
       "      <td>REPARTIDOR PERSONA CHOFER VENTAS CLIENTES SEGU...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5746210e854264aaca9452f4d377a4</td>\n",
       "      <td>1984</td>\n",
       "      <td>Ventas al detalle</td>\n",
       "      <td>Venta al detalle</td>\n",
       "      <td>Dependiente/a</td>\n",
       "      <td>No se requiere experiencia previa.</td>\n",
       "      <td>Abrimos proceso de selección para dependiente ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEPENDIENTE PROCESOS SELECCION COMERCIAL TIEND...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8a1bda0c91438bb4133f32e392a1ce</td>\n",
       "      <td>1984</td>\n",
       "      <td>Ventas al detalle</td>\n",
       "      <td>Venta al detalle</td>\n",
       "      <td>DEPENDIENTE/A STRADIVARIUS CC. PALMERAS (FUERT...</td>\n",
       "      <td>Queremos incorporar personas con pasión por la...</td>\n",
       "      <td>Tus funciones principales serán:\\n\\n- Atención...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEPENDIENTE PALMERAS SEMANALES ATENCIONES VENT...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id_oferta  id_puesto_esco_ull  \\\n",
       "0  ef5a8ae0a743018628df9bd53893bb                1634   \n",
       "1  47137c06a640348ca4cb7dcbf938b1                 611   \n",
       "2  cdfb72672340819a6721db72eee187                2825   \n",
       "3  5746210e854264aaca9452f4d377a4                1984   \n",
       "4  8a1bda0c91438bb4133f32e392a1ce                1984   \n",
       "\n",
       "                    categoria      subcategoria  \\\n",
       "0  Administracion de empresas    Administracion   \n",
       "1             Sanidad y salud  Medicina general   \n",
       "2          Comercial y ventas         Comercial   \n",
       "3           Ventas al detalle  Venta al detalle   \n",
       "4           Ventas al detalle  Venta al detalle   \n",
       "\n",
       "                                              asunto  \\\n",
       "0   Administrativo con inglés y Navision Turno tarde   \n",
       "1                                           Médico/a   \n",
       "2                              REPARTIDOR-AUTOVENTAS   \n",
       "3                                      Dependiente/a   \n",
       "4  DEPENDIENTE/A STRADIVARIUS CC. PALMERAS (FUERT...   \n",
       "\n",
       "                                  requisitos_minimos  \\\n",
       "0  -Conocimientos de inglés avanzado (hablado y e...   \n",
       "1  -Ser Licenciado/a o tener el Grado en Medicina...   \n",
       "2                                                NaN   \n",
       "3                 No se requiere experiencia previa.   \n",
       "4  Queremos incorporar personas con pasión por la...   \n",
       "\n",
       "                                  descripcion_oferta  \\\n",
       "0  Empresa de carácter internacional solicita adm...   \n",
       "1  Las funciones a desempeñar son las propias del...   \n",
       "2  Buscamos persona para puesto de Chófer -Repart...   \n",
       "3  Abrimos proceso de selección para dependiente ...   \n",
       "4  Tus funciones principales serán:\\n\\n- Atención...   \n",
       "\n",
       "                                              skills  \\\n",
       "0   Microsoft Dynamics NAV (Navision) INGLES Logí...   \n",
       "1                                                NaN   \n",
       "2                             ventas-reparto-almacen   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                               palabras_empleo_texto requisitos_deseados  \n",
       "0  ADMINISTRATIVO INGLES NAVISION EMPRESAS CARACT...                 NaN  \n",
       "1  MEDICO MEDICINA DIAGNOSTICO TRATAMIENTO LICENC...                 NaN  \n",
       "2  REPARTIDOR PERSONA CHOFER VENTAS CLIENTES SEGU...                 NaN  \n",
       "3  DEPENDIENTE PROCESOS SELECCION COMERCIAL TIEND...                 NaN  \n",
       "4  DEPENDIENTE PALMERAS SEMANALES ATENCIONES VENT...                 NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now delete all accents in the columns categoria and subcategoria\n",
    "test_df['categoria'] = test_df['categoria'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "test_df['subcategoria'] = test_df['subcategoria'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "# Present it\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix verbs df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  (1021406, 2)\n",
      "After:  (554143, 2)\n"
     ]
    }
   ],
   "source": [
    "# Delete all samples that a one of the columns is null in verbs_df\n",
    "print(\"Before: \", verbs_df.shape)\n",
    "verbs_df = verbs_df.dropna()\n",
    "# Find all the verbs that have a space in the column \"FORMA\" and delete them\n",
    "verbs_df = verbs_df[verbs_df['FORMA'].str.contains(' ') == False]\n",
    "print(\"After: \", verbs_df.shape)\n",
    "verbs_df = verbs_df.sort_values(by=['FORMA']).reset_index(drop=True)\n",
    "# Get the list of verbs in the column \"FORMA\"\n",
    "verbs_forms = verbs_df['FORMA'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hacer\n"
     ]
    }
   ],
   "source": [
    "# Get the index of the verbs that are in the list of verbs_forms\n",
    "verb = \"hara\"\n",
    "index = verbs_forms.index(verb)\n",
    "# Get the INF value of the verb\n",
    "inf = verbs_df.iloc[index]['INF']\n",
    "print(inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "list_remove = [\"www\", \"com\",\"http\", \"https\"]\n",
    "\n",
    "def tokenize_descripcion(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Normalize the text using NFKD normalization\n",
    "    text = unicodedata.normalize('NFKD', text) if isinstance(text, str) else text\n",
    "    # Remove non-ASCII characters\n",
    "    text = text.encode('ascii', errors='ignore').decode('utf-8')\n",
    "    # Replace newline, carriage return, and tab characters with spaces\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "    # Replace '/', '\\\\', double quotes, and single quotes\n",
    "    text = text.replace('/', ' ').replace('\\\\', ' ').replace('\"', '').replace(\"'\", '')\n",
    "    # Remove links (URLs) from the text using regular expressions\n",
    "    text = re.sub(r'http(s)?:\\s+\\S+', '', text, flags=re.IGNORECASE)\n",
    "    # Remove all occurrences of \".es\" (case-insensitive)\n",
    "    text = re.sub(r'\\.es', '', text, flags=re.IGNORECASE)\n",
    "    # Remove all non alpha characters from the text using regular expressions\n",
    "    text = re.sub(r'[^a-zA-Z ]+', ' ', text, flags=re.IGNORECASE)\n",
    "    # Remove unnecessary spaces from the text using regular expressions\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.IGNORECASE)\n",
    "    # Cast all words to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def create_palabras_column(text):\n",
    "    # Split the text into a list of words and filter simultaneously\n",
    "    palabras = [palabra for palabra in text.split(\" \") if len(palabra) > 1 and palabra not in list_remove]\n",
    "    return palabras\n",
    "\n",
    "def list_words(palabras_empleo_texto):\n",
    "    # print(palabras_empleo_texto)\n",
    "    try:\n",
    "        return palabras_empleo_texto.lower().split(\" \")[:-1]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def clean_descripcion(df):\n",
    "    # tokenize asunto\n",
    "    df['asunto'] = df['asunto'].apply(tokenize_descripcion)\n",
    "    # tokenize the descripcion\n",
    "    df['descripcion_oferta'] = df['descripcion_oferta'].apply(tokenize_descripcion)\n",
    "    # tokenize requisitos_minimos\n",
    "    df['requisitos_minimos'] = df['requisitos_minimos'].apply(tokenize_descripcion)\n",
    "    # tokenize requisitos_deseados\n",
    "    df['requisitos_deseados'] = df['requisitos_deseados'].apply(tokenize_descripcion)\n",
    "    # tokenize skills\n",
    "    df['skills'] = df['skills'].apply(tokenize_descripcion)\n",
    "    # Join all the columns into 'descripcion_oferta'\n",
    "    df['descripcion_oferta'] = df['asunto'] + \" \" + df['descripcion_oferta'] + \" \" + df['requisitos_minimos'] + \" \" + df['requisitos_deseados'] + \" \" + df['skills']\n",
    "    # Split the text into a list of words\n",
    "    df['palabras_descripcion_oferta'] = df['descripcion_oferta'].apply(create_palabras_column)\n",
    "    # Convert the string into a list\n",
    "    df['palabras_empleo_texto'] = df['palabras_empleo_texto'].apply(lambda x: list_words(x))\n",
    "    return df\n",
    "\n",
    "test_df = clean_descripcion(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexialice unstructured lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zu', 'zz', 'zu']\n"
     ]
    }
   ],
   "source": [
    "def create_index_list(unstructured_forms):\n",
    "    if index_chars == 0:\n",
    "        return {}\n",
    "    index_list = {}\n",
    "    for index, string in enumerate(unstructured_forms):\n",
    "        first_letter = string[0:index_chars]\n",
    "        if first_letter not in index_list:\n",
    "            index_list[first_letter] = index\n",
    "    return index_list\n",
    "\n",
    "def find_indices(string, index_list, unstructured_forms):\n",
    "    if index_chars == 0:\n",
    "        return {}\n",
    "    if not string:  # Check if the string is empty\n",
    "        return 0, len(unstructured_forms)\n",
    "    first_letter = string[0:index_chars]\n",
    "    start_index = index_list.get(first_letter, 0)\n",
    "    if first_letter in limit_letters:\n",
    "        end_index = len(unstructured_forms)\n",
    "    else:\n",
    "        next_letter = get_next_letter(first_letter, index_list)\n",
    "        end_index = index_list.get(next_letter, len(unstructured_forms))\n",
    "    return start_index, end_index\n",
    "\n",
    "def get_next_letter(first_letter, index_list):\n",
    "    keys_list = list(index_list.keys())\n",
    "    if first_letter in keys_list:\n",
    "        next_letter_index_key = keys_list.index(first_letter) + 1\n",
    "        return keys_list[next_letter_index_key]\n",
    "    else:\n",
    "        return chr(ord(first_letter[0]) + 1)\n",
    "\n",
    "sustantives_index_list = create_index_list(sustantives_forms)\n",
    "adjectives_index_list = create_index_list(adjectives_forms)\n",
    "verbs_index_list = create_index_list(verbs_forms)\n",
    "# Get the first two letters of the column FORMA on each DataFrame\n",
    "limit_letters = [verbs_df['FORMA'].str[0:index_chars].iloc[-1],\n",
    "                 sustantives_df['FORMA'].str[0:index_chars].iloc[-1],\n",
    "                 adjectives_df['FORMA'].str[0:index_chars].iloc[-1]]\n",
    "print(limit_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_word(word):\n",
    "    # Delete all numbers\n",
    "    word = re.sub(r\"\\d+\", \"\", word)\n",
    "    # Delete all accents\n",
    "    word = unidecode(word.lower())\n",
    "    # Remove simbols\n",
    "    word = re.sub(r\"[^a-z0-9ñ]\", \"\", word)\n",
    "    return word\n",
    "\n",
    "def get_reference(descripcion_oferta, df, index, column):\n",
    "    # Get the accuracy of the words in palabras_empleo_texto that are in descripcion_oferta\n",
    "    error = 0\n",
    "    accuracy = 0\n",
    "    if column == \"palabras_empleo_texto\":\n",
    "        list_words = df[column].iloc[index]\n",
    "    else:\n",
    "        list_words = df[column].iloc[index].lower().split(\" \")\n",
    "    \n",
    "    for word in descripcion_oferta.split(\" \"):\n",
    "        if unidecode(word) not in list_words:\n",
    "            error += 1\n",
    "        else:\n",
    "            accuracy += 1\n",
    "    return error, accuracy\n",
    "\n",
    "def add_words_to_vocabulary(palabras_list, vocabulary):\n",
    "    # Add to vocabulary all different words\n",
    "    for palabra in palabras_list:\n",
    "        if palabra not in vocabulary.keys():\n",
    "            vocabulary[palabra] = 1\n",
    "        else:\n",
    "            vocabulary[palabra] += 1\n",
    "    # Return the vocabulary\n",
    "    return vocabulary\n",
    "\n",
    "def show_process_stats(end_time_process, times, palabras, metrics, vocabulary):\n",
    "    # Print total of offers\n",
    "    print(\"Total of offers: {:.0f}\".format(len(times)))\n",
    "    # Print the time process\n",
    "    print(\"Time process: {:.2f} seg\".format(end_time_process))\n",
    "    # Get mean of times\n",
    "    mean_time = sum(times) / len(times)\n",
    "    print(\"Mean time: {:.2f} seg\".format(mean_time))\n",
    "    # Sum all the words is a list of lists\n",
    "    total_words = sum(palabras)\n",
    "    print(\"Total words: {:.0f}\".format(total_words))\n",
    "    # Get words per time\n",
    "    words_per_time = total_words / end_time_process\n",
    "    print(\"Words per time: {:.2f}\".format(words_per_time))\n",
    "    # Total number of different words\n",
    "    total_different_words = len(vocabulary.keys())\n",
    "    print(\"Total different words: {:.0f}\".format(total_different_words))\n",
    "    # Get the mean of er_nuevas, acc_nuevas, er_legacy, acc_legacy\n",
    "    er_nuevas = sum([metric[\"er_nuevas\"] for metric in metrics]) / len(metrics)\n",
    "    acc_nuevas = sum([metric[\"acc_nuevas\"] for metric in metrics]) / len(metrics)\n",
    "    er_legacy = sum([metric[\"er_legacy\"] for metric in metrics]) / len(metrics)\n",
    "    acc_legacy = sum([metric[\"acc_legacy\"] for metric in metrics]) / len(metrics)\n",
    "    # Print the metrics\n",
    "    print(\"Error medio producido en palabras nuevas: {:.2f}\".format(er_nuevas))\n",
    "    print(\"Precisión media obtenida en palabras nuevas: {:.2f}\".format(acc_nuevas))\n",
    "    print(\"Error medio anterio: {:.2f}\".format(er_legacy))\n",
    "    print(\"Precisión media anterior: {:.2f}\".format(acc_legacy))\n",
    "\n",
    "def create_excel_file(filename, end_time_process, times, n_palabras_total, n_palabras_encontradas, metrics, vocabulary):\n",
    "    # Create a dictionary with the data\n",
    "    data = {\n",
    "        'NOMBRE_TEST': [filename],\n",
    "        'INDEXACIÓN [n_letras]': index_chars,\n",
    "        'N_OFERTAS': [len(times)],\n",
    "        'WORDS_DESCRIPCION [n_palabras]': [sum(n_palabras_total)],\n",
    "        'WORDS_ENCONTRADAS [n_palabras]': [sum(n_palabras_encontradas)],\n",
    "        'TIME_PROCESS [seg]': [end_time_process],\n",
    "        'MEAN_TIME [seg]': [sum(times) / len(times)],\n",
    "        'WORDS_PER_TIME_DESCRIPTION [n_palabras/seg]': [sum(n_palabras_total) / end_time_process],\n",
    "        'MEAN_PRECISION': [sum([metric[\"acc_nuevas\"] for metric in metrics]) / len(metrics)],\n",
    "        'MEAN_ERRORES': [sum([metric[\"er_nuevas\"] for metric in metrics]) / len(metrics)],\n",
    "        'TOTAL_TIME_PALABRAS [horas]': [sum(times) / len(times) * 50000 / 36000],  # Convert seconds to hours\n",
    "        'VOCABULARIO [n_palabras_distintas]': [len(vocabulary.keys())]\n",
    "    }\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    # Save the DataFrame to an Excel file\n",
    "    df.to_excel('../test/' + filename + '.xlsx', index=False)\n",
    "    \n",
    "def update_excel_file(filename, end_time_process, times, n_palabras_total, n_palabras_encontradas, metrics, vocabulary):\n",
    "    try:\n",
    "        # Load the existing Excel file if it exists\n",
    "        df = pd.read_excel('../test/' + filename + '.xlsx')\n",
    "    except FileNotFoundError:\n",
    "        # Create a new DataFrame if the file doesn't exist\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "    # Create a dictionary with the new data\n",
    "    new_data = {\n",
    "        'NOMBRE_TEST': [filename],\n",
    "        'INDEXACIÓN [n_letras]': index_chars,  # Replace with your actual data\n",
    "        'N_OFERTAS': [len(times)],\n",
    "        'WORDS_DESCRIPCION [n_palabras]': [sum(n_palabras_total)],\n",
    "        'WORDS_ENCONTRADAS [n_palabras]': [sum(n_palabras_encontradas)],\n",
    "        'TIME_PROCESS [seg]': [end_time_process],\n",
    "        'MEAN_TIME [seg]': [sum(times) / len(times)],\n",
    "        'WORDS_PER_TIME_DESCRIPTION [n_palabras/seg]': [sum(n_palabras_total) / end_time_process],\n",
    "        'MEAN_PRECISION': [sum([metric[\"acc_nuevas\"] for metric in metrics]) / len(metrics)],\n",
    "        'MEAN_ERRORES': [sum([metric[\"er_nuevas\"] for metric in metrics]) / len(metrics)],\n",
    "        'TOTAL_TIME_PALABRAS [horas]': [sum(times) / len(times) * 50000 / 36000],  # Convert seconds to hours\n",
    "        'VOCABULARIO [n_palabras_distintas]': [len(vocabulary.keys())]\n",
    "    }\n",
    "\n",
    "    # Convert the new data to a DataFrame\n",
    "    new_df = pd.DataFrame(new_data)\n",
    "\n",
    "    # Concatenate the existing DataFrame with the new DataFrame\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame back to the Excel file\n",
    "    df.to_excel('../test/' + filename + '.xlsx', index=False)\n",
    "\n",
    "def get_lemma_df(word, df, unstructured_forms, index_list):\n",
    "    if index_chars == 0:\n",
    "        start, end = (0, len(unstructured_forms))\n",
    "    else:\n",
    "        start, end = find_indices(word, index_list, unstructured_forms)\n",
    "    # Is faster to handler the exception than to check if the word is in the list\n",
    "    try:\n",
    "        index = unstructured_forms.index(word, start, end)\n",
    "        if \"LEMA\" in df.columns:\n",
    "            return df.iloc[index][\"LEMA\"]\n",
    "        else:\n",
    "            return df.iloc[index][\"INF\"]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def conditional_inference(word, df_nouns, unstructured_forms_nouns, df_adj, unstructured_forms_adj, df_verbs, unstructured_forms_verb):\n",
    "    verb = get_lemma_df(word, df_verbs, unstructured_forms_verb, verbs_index_list)\n",
    "    if verb == None:\n",
    "        noun = get_lemma_df(word, df_nouns, unstructured_forms_nouns, sustantives_index_list)\n",
    "        if noun == None:\n",
    "            adjective = get_lemma_df(word, df_adj, unstructured_forms_adj, adjectives_index_list)\n",
    "            if adjective == None:\n",
    "                return None\n",
    "            else:\n",
    "                return adjective\n",
    "        else:\n",
    "            return noun\n",
    "    else:\n",
    "        return verb\n",
    "\n",
    "def get_syntax(words, df_nouns, unstructured_forms_nouns, df_adj, unstructured_forms_adj, unstructured_forms_adv, df_verbs, unstructured_forms_verb):\n",
    "    # Object palabras_list\n",
    "    palabras_list = []\n",
    "    # Split by \" \"\n",
    "    for word in words.split(\" \"):\n",
    "        word = clean_word(word)\n",
    "        if word in stop_words or word in unstructured_forms_adv:\n",
    "            continue\n",
    "        # Verify if is a noun\n",
    "        solution = conditional_inference(word, df_nouns, unstructured_forms_nouns, df_adj, unstructured_forms_adj, df_verbs, unstructured_forms_verb)\n",
    "        if solution != None:\n",
    "            palabras_list.append(solution)\n",
    "    return palabras_list\n",
    "\n",
    "def process_and_update_df(filename, df, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms, adverbs_forms ,verbs_df, verbs_forms):\n",
    "    import time\n",
    "    # Create a new column in the DataFrame to store the result\n",
    "    df[\"palabras_empleo_texto_nuevas\"] = \"\"\n",
    "    times = []\n",
    "    n_palabras_total = []\n",
    "    n_palabras_encontradas = []\n",
    "    metrics = []\n",
    "    vocabulary = {}\n",
    "    start_time_process = time.time()\n",
    "    # Iterate over the DataFrame and apply the word extraction function\n",
    "    for index, description in df[\"descripcion_oferta\"].items():\n",
    "        start_time = time.time()\n",
    "        # Get the list of words\n",
    "        palabras_list = get_syntax(description, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms, adverbs_forms ,verbs_df, verbs_forms)\n",
    "        # Add the words to the vocabulary\n",
    "        vocabulary = add_words_to_vocabulary(palabras_list, vocabulary)\n",
    "        # Save palabras_list in a new column in the DataFrame, insert the full list\n",
    "        try:\n",
    "            df.at[index, \"palabras_empleo_texto_nuevas\"] = ' '.join(palabras_list).upper()\n",
    "        except:\n",
    "            df.at[index, \"palabras_empleo_texto_nuevas\"] = ''\n",
    "        # Calculate partial time and save to times list\n",
    "        times.append(time.time() - start_time)\n",
    "        # Save the number of words in the list\n",
    "        n_palabras_total.append(len(description.split(\" \")))\n",
    "        n_palabras_encontradas.append(len(palabras_list))\n",
    "        # Get the metrics of the calculated words\n",
    "        er_nuevas, acc_nuevas = get_reference(description, df, index, \"palabras_empleo_texto_nuevas\")\n",
    "        # Get the metrics of the legacy words\n",
    "        er_legacy, acc_legacy = get_reference(description, df, index, \"palabras_empleo_texto\")\n",
    "        # Add to metrics list\n",
    "        metrics.append({\"er_nuevas\": er_nuevas, \"acc_nuevas\": acc_nuevas, \"er_legacy\": er_legacy, \"acc_legacy\": acc_legacy})\n",
    "    # Calculate and add the column with words that appear in palabras legacy but not in palabras nuevas\n",
    "    df[\"palabras_legacy_minus_nuevas\"] = df.apply(lambda row: list(set(row[\"palabras_empleo_texto\"]) - set(row[\"palabras_empleo_texto_nuevas\"])), axis=1)\n",
    "    end_time_process = time.time() - start_time_process\n",
    "    # show_process_stats(end_time_process, times, n_palabras, metrics, vocabulary)\n",
    "    # File in ../test/test.xlsx exists?\n",
    "    if not os.path.isfile('../test/' + filename + '.xlsx'):\n",
    "        # Create the Excel file\n",
    "        create_excel_file(filename, end_time_process, times, n_palabras_total, n_palabras_encontradas, metrics, vocabulary)\n",
    "    else:\n",
    "        # Update the Excel file\n",
    "        update_excel_file(filename, end_time_process, times, n_palabras_total, n_palabras_encontradas, metrics, vocabulary)\n",
    "    return df, times, n_palabras_encontradas, vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_oferta</th>\n",
       "      <th>id_puesto_esco_ull</th>\n",
       "      <th>categoria</th>\n",
       "      <th>subcategoria</th>\n",
       "      <th>asunto</th>\n",
       "      <th>requisitos_minimos</th>\n",
       "      <th>descripcion_oferta</th>\n",
       "      <th>skills</th>\n",
       "      <th>palabras_empleo_texto</th>\n",
       "      <th>requisitos_deseados</th>\n",
       "      <th>palabras_descripcion_oferta</th>\n",
       "      <th>palabras_empleo_texto_nuevas</th>\n",
       "      <th>palabras_legacy_minus_nuevas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ef5a8ae0a743018628df9bd53893bb</td>\n",
       "      <td>1634</td>\n",
       "      <td>Administracion de empresas</td>\n",
       "      <td>Administracion</td>\n",
       "      <td>administrativo con ingles y navision turno tarde</td>\n",
       "      <td>conocimientos de ingles avanzado hablado y es...</td>\n",
       "      <td>administrativo con ingles y navision turno tar...</td>\n",
       "      <td>microsoft dynamics nav navision ingles logist...</td>\n",
       "      <td>[administrativo, ingles, navision, empresas, c...</td>\n",
       "      <td></td>\n",
       "      <td>[administrativo, con, ingles, navision, turno,...</td>\n",
       "      <td>ADMINISTRATIVO INGLES NAVISION TURNAR EMPRESA ...</td>\n",
       "      <td>[navision, empresas, excel, internacional, off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47137c06a640348ca4cb7dcbf938b1</td>\n",
       "      <td>611</td>\n",
       "      <td>Sanidad y salud</td>\n",
       "      <td>Medicina general</td>\n",
       "      <td>medico a</td>\n",
       "      <td>ser licenciado a o tener el grado en medicina...</td>\n",
       "      <td>medico a las funciones a desempenar son las pr...</td>\n",
       "      <td></td>\n",
       "      <td>[medico, medicina, diagnostico, tratamiento, l...</td>\n",
       "      <td></td>\n",
       "      <td>[medico, las, funciones, desempenar, son, las,...</td>\n",
       "      <td>MEDICAR FUNCIONAR DESEMPENAR PROPIO PONER MEDI...</td>\n",
       "      <td>[licenciado, tratamiento, carne, colegiado, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cdfb72672340819a6721db72eee187</td>\n",
       "      <td>2825</td>\n",
       "      <td>Comercial y ventas</td>\n",
       "      <td>Comercial</td>\n",
       "      <td>repartidor autoventas</td>\n",
       "      <td></td>\n",
       "      <td>repartidor autoventas buscamos persona para pu...</td>\n",
       "      <td>ventas reparto almacen</td>\n",
       "      <td>[repartidor, persona, chofer, ventas, clientes...</td>\n",
       "      <td></td>\n",
       "      <td>[repartidor, autoventas, buscamos, persona, pa...</td>\n",
       "      <td>REPARTIDOR BUSCAR PERSONA PONER CHOFER REPARTI...</td>\n",
       "      <td>[reparto, seguimientos, almacenes, ventas, rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5746210e854264aaca9452f4d377a4</td>\n",
       "      <td>1984</td>\n",
       "      <td>Ventas al detalle</td>\n",
       "      <td>Venta al detalle</td>\n",
       "      <td>dependiente a</td>\n",
       "      <td>no se requiere experiencia previa</td>\n",
       "      <td>dependiente a abrimos proceso de seleccion par...</td>\n",
       "      <td></td>\n",
       "      <td>[dependiente, procesos, seleccion, comercial, ...</td>\n",
       "      <td></td>\n",
       "      <td>[dependiente, abrimos, proceso, de, seleccion,...</td>\n",
       "      <td>DEPENDIENTE ABRIR PROCESAR SELECCION DEPENDIEN...</td>\n",
       "      <td>[tiendas, experiencia, procesos, seleccion, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8a1bda0c91438bb4133f32e392a1ce</td>\n",
       "      <td>1984</td>\n",
       "      <td>Ventas al detalle</td>\n",
       "      <td>Venta al detalle</td>\n",
       "      <td>dependiente a stradivarius cc palmeras fuertev...</td>\n",
       "      <td>queremos incorporar personas con pasion por la...</td>\n",
       "      <td>dependiente a stradivarius cc palmeras fuertev...</td>\n",
       "      <td></td>\n",
       "      <td>[dependiente, palmeras, semanales, atenciones,...</td>\n",
       "      <td></td>\n",
       "      <td>[dependiente, stradivarius, cc, palmeras, fuer...</td>\n",
       "      <td>DEPENDIENTE STRADIVARIUS CC PALMERO FUERTEVENT...</td>\n",
       "      <td>[tiendas, atenciones, capacidad, dinamica, equ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id_oferta  id_puesto_esco_ull  \\\n",
       "0  ef5a8ae0a743018628df9bd53893bb                1634   \n",
       "1  47137c06a640348ca4cb7dcbf938b1                 611   \n",
       "2  cdfb72672340819a6721db72eee187                2825   \n",
       "3  5746210e854264aaca9452f4d377a4                1984   \n",
       "4  8a1bda0c91438bb4133f32e392a1ce                1984   \n",
       "\n",
       "                    categoria      subcategoria  \\\n",
       "0  Administracion de empresas    Administracion   \n",
       "1             Sanidad y salud  Medicina general   \n",
       "2          Comercial y ventas         Comercial   \n",
       "3           Ventas al detalle  Venta al detalle   \n",
       "4           Ventas al detalle  Venta al detalle   \n",
       "\n",
       "                                              asunto  \\\n",
       "0   administrativo con ingles y navision turno tarde   \n",
       "1                                           medico a   \n",
       "2                              repartidor autoventas   \n",
       "3                                      dependiente a   \n",
       "4  dependiente a stradivarius cc palmeras fuertev...   \n",
       "\n",
       "                                  requisitos_minimos  \\\n",
       "0   conocimientos de ingles avanzado hablado y es...   \n",
       "1   ser licenciado a o tener el grado en medicina...   \n",
       "2                                                      \n",
       "3                 no se requiere experiencia previa    \n",
       "4  queremos incorporar personas con pasion por la...   \n",
       "\n",
       "                                  descripcion_oferta  \\\n",
       "0  administrativo con ingles y navision turno tar...   \n",
       "1  medico a las funciones a desempenar son las pr...   \n",
       "2  repartidor autoventas buscamos persona para pu...   \n",
       "3  dependiente a abrimos proceso de seleccion par...   \n",
       "4  dependiente a stradivarius cc palmeras fuertev...   \n",
       "\n",
       "                                              skills  \\\n",
       "0   microsoft dynamics nav navision ingles logist...   \n",
       "1                                                      \n",
       "2                             ventas reparto almacen   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                               palabras_empleo_texto requisitos_deseados  \\\n",
       "0  [administrativo, ingles, navision, empresas, c...                       \n",
       "1  [medico, medicina, diagnostico, tratamiento, l...                       \n",
       "2  [repartidor, persona, chofer, ventas, clientes...                       \n",
       "3  [dependiente, procesos, seleccion, comercial, ...                       \n",
       "4  [dependiente, palmeras, semanales, atenciones,...                       \n",
       "\n",
       "                         palabras_descripcion_oferta  \\\n",
       "0  [administrativo, con, ingles, navision, turno,...   \n",
       "1  [medico, las, funciones, desempenar, son, las,...   \n",
       "2  [repartidor, autoventas, buscamos, persona, pa...   \n",
       "3  [dependiente, abrimos, proceso, de, seleccion,...   \n",
       "4  [dependiente, stradivarius, cc, palmeras, fuer...   \n",
       "\n",
       "                        palabras_empleo_texto_nuevas  \\\n",
       "0  ADMINISTRATIVO INGLES NAVISION TURNAR EMPRESA ...   \n",
       "1  MEDICAR FUNCIONAR DESEMPENAR PROPIO PONER MEDI...   \n",
       "2  REPARTIDOR BUSCAR PERSONA PONER CHOFER REPARTI...   \n",
       "3  DEPENDIENTE ABRIR PROCESAR SELECCION DEPENDIEN...   \n",
       "4  DEPENDIENTE STRADIVARIUS CC PALMERO FUERTEVENT...   \n",
       "\n",
       "                        palabras_legacy_minus_nuevas  \n",
       "0  [navision, empresas, excel, internacional, off...  \n",
       "1  [licenciado, tratamiento, carne, colegiado, gr...  \n",
       "2  [reparto, seguimientos, almacenes, ventas, rep...  \n",
       "3  [tiendas, experiencia, procesos, seleccion, de...  \n",
       "4  [tiendas, atenciones, capacidad, dinamica, equ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first 5 rows of the DataFrame and save into a new DataFrame\n",
    "partial_df = test_df.iloc[0:n_ofertas].copy()\n",
    "# Call the processing function with your DataFrame\n",
    "partial_df, time_list, n_palabras, vocabulary = process_and_update_df(filename, partial_df, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms, adverbs_forms ,verbs_df, verbs_forms)\n",
    "# Save vocabulary to a json file\n",
    "with open('../test/' + filename + '_vocabulary.json', 'w') as fp:\n",
    "    json.dump(vocabulary, fp)\n",
    "partial_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all the column names to upper\n",
    "partial_df.columns = [column.upper() for column in partial_df.columns]\n",
    "partial_df[['ID_OFERTA','ID_PUESTO_ESCO_ULL','CATEGORIA','SUBCATEGORIA','PALABRAS_EMPLEO_TEXTO_NUEVAS']].to_json(\"../../data/test/test_palabras_nuevas.csv\", orient=\"records\")\n",
    "\n",
    "\n",
    "def export_results_to_markdown(index, test_df, output_file, time):\n",
    "    # Get list of words in descripcion_oferta\n",
    "    descripcion_oferta = test_df[\"descripcion_oferta\"].iloc[index]\n",
    "    error, accuracy = get_reference(descripcion_oferta, test_df, index, \"palabras_empleo_texto_nuevas\")\n",
    "    \n",
    "    with open(\"../test/\" + str(index) + \"_\" + output_file, \"w\") as md_file:\n",
    "        # Write header for the section\n",
    "        md_file.write(f\"## Descripcion oferta: \\n{test_df['descripcion_oferta'].iloc[index]}\\n\")\n",
    "        md_file.write(f\"### Total de palabras en descripción: \\n{len(descripcion_oferta)}\\n\")\n",
    "        md_file.write(f\"\\n\")\n",
    "        md_file.write(f\"## Palabras nuevas: \\n{test_df['palabras_empleo_texto_nuevas'].iloc[index]}\\n\")\n",
    "        md_file.write(f\"### Accuracy - palabras nuevas: \\n{accuracy}\\n\")\n",
    "        md_file.write(f\"### Error - palabras nuevas: \\n{error}\\n\")\n",
    "        palabras_not_found = list(set(test_df['palabras_empleo_texto_nuevas'].iloc[index].lower().split(\" \")) - set(descripcion_oferta.split(\" \")))\n",
    "        md_file.write(f\"## Palabras nuevas no encontradas en descripción: \\n{', '.join(palabras_not_found)}\\n\")\n",
    "        md_file.write(f\"\\n\")\n",
    "        error, accuracy = get_reference(descripcion_oferta, test_df, index, \"palabras_empleo_texto\")\n",
    "        md_file.write(f\"## Palabras legacy: \\n{', '.join(test_df['palabras_empleo_texto'].iloc[index])}\\n\")\n",
    "        md_file.write(f\"### Accuracy - palabras legacy: \\n{accuracy}\\n\")\n",
    "        md_file.write(f\"### Error - palabras legacy: \\n{error}\\n\")\n",
    "        palabras_not_found = list(set(test_df['palabras_empleo_texto'].iloc[index]) - set(descripcion_oferta))\n",
    "        md_file.write(f\"## Palabras legacy no encontradas en descripción: \\n{', '.join(palabras_not_found)}\\n\")\n",
    "        md_file.write(f\"\\n\")\n",
    "        md_file.write(f\"## Tiempo de ejecución: \\n{time} segundos\\n\")\n",
    "        md_file.write(f\"## Relación palabras/tiempo: \\n{len(descripcion_oferta)/time} palabras/segundo\\n\")\n",
    "\n",
    "# Define the Markdown output file\n",
    "output_file = \"test.md\"\n",
    "\n",
    "# Call the function to export the results to Markdown\n",
    "# for index in range(0, 5):\n",
    "#     time = time_list[index]\n",
    "#     export_results_to_markdown(index, partial_df, output_file, time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
