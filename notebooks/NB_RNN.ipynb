{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 19:03:31.671982: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-17 19:03:31.723315: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-17 19:03:31.723364: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-17 19:03:31.723429: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-17 19:03:31.734800: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-17 19:03:31.736668: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-17 19:03:32.667763: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37575, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_OFERTA</th>\n",
       "      <th>ID_PUESTO_ESCO_ULL</th>\n",
       "      <th>CATEGORIA</th>\n",
       "      <th>SUBCATEGORIA</th>\n",
       "      <th>PALABRAS_EMPLEO_TEXTO_NUEVAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cdfb72672340819a6721db72eee187</td>\n",
       "      <td>2825</td>\n",
       "      <td>Comercial y ventas</td>\n",
       "      <td>Comercial</td>\n",
       "      <td>REPARTIDOR REPARTIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8a1bda0c91438bb4133f32e392a1ce</td>\n",
       "      <td>1984</td>\n",
       "      <td>Ventas al detalle</td>\n",
       "      <td>Venta al detalle</td>\n",
       "      <td>DOBLAR LOOK PERCHAR STRADIVARIUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5070f6b07f43d0ac234ceefa6b8595</td>\n",
       "      <td>76</td>\n",
       "      <td>Informatica y telecomunicaciones</td>\n",
       "      <td>Telecomunicaciones</td>\n",
       "      <td>TABLET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fe9c5f661a45819a97d8ca343f337c</td>\n",
       "      <td>1508</td>\n",
       "      <td>Informatica y telecomunicaciones</td>\n",
       "      <td>Telecomunicaciones</td>\n",
       "      <td>CONSORCIO MARKETING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>449a1e78944c59bb38263ab3e37d3f</td>\n",
       "      <td>127</td>\n",
       "      <td>Ingenieros y tecnicos</td>\n",
       "      <td>Otras ingenierias</td>\n",
       "      <td>PRIVILEGIAR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID_OFERTA  ID_PUESTO_ESCO_ULL  \\\n",
       "2  cdfb72672340819a6721db72eee187                2825   \n",
       "4  8a1bda0c91438bb4133f32e392a1ce                1984   \n",
       "7  5070f6b07f43d0ac234ceefa6b8595                  76   \n",
       "8  fe9c5f661a45819a97d8ca343f337c                1508   \n",
       "9  449a1e78944c59bb38263ab3e37d3f                 127   \n",
       "\n",
       "                          CATEGORIA        SUBCATEGORIA  \\\n",
       "2                Comercial y ventas           Comercial   \n",
       "4                 Ventas al detalle    Venta al detalle   \n",
       "7  Informatica y telecomunicaciones  Telecomunicaciones   \n",
       "8  Informatica y telecomunicaciones  Telecomunicaciones   \n",
       "9             Ingenieros y tecnicos   Otras ingenierias   \n",
       "\n",
       "       PALABRAS_EMPLEO_TEXTO_NUEVAS  \n",
       "2               REPARTIDOR REPARTIR  \n",
       "4  DOBLAR LOOK PERCHAR STRADIVARIUS  \n",
       "7                            TABLET  \n",
       "8               CONSORCIO MARKETING  \n",
       "9                       PRIVILEGIAR  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('../data/test/test_palabras_nuevas.json')\n",
    "# Delete rows with empty text\n",
    "df = df[df['PALABRAS_EMPLEO_TEXTO_NUEVAS'] != '']\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete all single occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(660, 4)\n"
     ]
    }
   ],
   "source": [
    "# Delete all rows with unique 'id_puesto_esco_ull'\n",
    "df = df[df.duplicated(subset='ID_PUESTO_ESCO_ULL', keep=False)]\n",
    "# Get the count of each 'id_puesto_esco_ull'\n",
    "count_df = df.groupby('ID_PUESTO_ESCO_ULL').count()\n",
    "print(count_df.shape)\n",
    "num_classes = count_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10458\n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(df['PALABRAS_EMPLEO_TEXTO_NUEVAS'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show vocab aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'marketing', 'competencia', 'inmobiliario', 'inicial',\n",
       "       'emprendedor', 'propiedad', 'acceso', 'inmueble', 'prospeccion',\n",
       "       'valoracion', 'vender', 'portal', 'espiritu', 'crm', 'comprador',\n",
       "       'unico', 'propietario', 'publicacion'], dtype='<U22')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  35,   30,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [  96,  152,   82,  171,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [  71,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [1862,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [1160,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [   3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [ 416,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [  23,    8,   33,    3,   16,   25,   15,    6,   14,   28,   21,\n",
       "           5,    4,    9,   27,    2,   13,    7,   18,   10,   19,   20,\n",
       "          24,   17,   11,   12],\n",
       "       [ 453,   66,    6,  391,  281,  428,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [  32,  399,  429,   70,   35,   30,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [2088,    5, 1162,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [  23,    8,   33,    3,   16,   25,   15,    6,   14,   28,   21,\n",
       "           5,    4,    9,   27,    2,   13,    7,   18,   10,   19,   20,\n",
       "          24,   17,   11,   12],\n",
       "       [  23,    8,   33,    3,   16,   25,   15,    6,   14,   28,   21,\n",
       "           5,    4,    9,   27,    2,   13,    7,   18,   10,   19,   20,\n",
       "          24,   17,   11,   12],\n",
       "       [ 278,   40,  389,    6,  209,   91,   22,    4,   27,  365,   76,\n",
       "         320,   29,  138,   53,   88,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [ 126,  444,   97,    6,   54,   22,    4,    9,  635,   27,   26,\n",
       "           2,   76,   39,   53,  120,   11,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [  23,    8,   33,    3,   16,   25,   15,    6,   14,   28,   21,\n",
       "           5,    4,    9,   27,    2,   13,    7,   18,   10,   19,   20,\n",
       "          24,   17,   11,   12],\n",
       "       [  23,    8,   33,    3,   16,   25,   15,    6,   14,   28,   21,\n",
       "           5,    4,    9,   27,    2,   13,    7,   18,   10,   19,   20,\n",
       "          24,   17,   11,   12],\n",
       "       [ 652,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [  23,    8,   33,    3,   16,   25,   15,    6,   14,   28,   21,\n",
       "           5,    4,    9,   27,    2,   13,    7,   18,   10,   19,   20,\n",
       "          24,   17,   11,   12],\n",
       "       [ 188,  194,  140,   50,  132, 1172,  179,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show an example of the encoding\n",
    "encoded_example = encoder(df['PALABRAS_EMPLEO_TEXTO_NUEVAS'].values[:20]).numpy()\n",
    "encoded_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVe  (None, None)              0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 3000)        31374000  \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 64)          192064    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, 660)         42900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31608964 (120.58 MB)\n",
      "Trainable params: 31608964 (120.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Modify the model architecture to return (None, 766) without time steps\n",
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=VOCAB_SIZE,\n",
    "        output_dim=3000),\n",
    "    # Add relu activation function\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model using appropriate loss and metrics for multi-class classification\n",
    "model.compile(loss='categorical_crossentropy',  # Use categorical crossentropy as your loss function\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary to review the architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/engine/training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/backend.py\", line 5575, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 660) and (None, None, 660) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/notebooks/NB_RNN.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.70.205/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/notebooks/NB_RNN.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m y_train_one_hot \u001b[39m=\u001b[39m to_categorical(y_train_mapped, num_classes\u001b[39m=\u001b[39mnum_classes)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.70.205/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/notebooks/NB_RNN.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Fit the model with one-hot encoded labels (y_train_one_hot)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.70.205/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/notebooks/NB_RNN.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train_one_hot, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.70.205/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/notebooks/NB_RNN.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Plot the accuracy and loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.70.205/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/notebooks/NB_RNN.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filebpa15ebp.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/engine/training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/keras/src/backend.py\", line 5575, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 660) and (None, None, 660) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "# Get the training data from 'descripcion_oferta' and the target from 'id_puesto_esco_ull'\n",
    "X_train = df['PALABRAS_EMPLEO_TEXTO_NUEVAS'].values\n",
    "y_train = df['ID_PUESTO_ESCO_ULL'].values\n",
    "\n",
    "# Step 1: Sort the class labels and assign consecutive integer IDs\n",
    "sorted_labels = sorted(np.unique(y_train))\n",
    "class_id_mapping = {class_label: class_id for class_id, class_label in enumerate(sorted_labels)}\n",
    "\n",
    "# Step 2: Create a dictionary to map class IDs to class labels\n",
    "class_label_mapping = {class_id: class_label for class_id, class_label in class_id_mapping.items()}\n",
    "\n",
    "# Step 3: Create functions for conversion\n",
    "def class_label_to_id(class_label):\n",
    "    return class_id_mapping.get(class_label)\n",
    "\n",
    "def class_id_to_label(class_id):\n",
    "    return class_label_mapping.get(class_id)\n",
    "\n",
    "# Map class labels to class IDs for y_train\n",
    "y_train_mapped = np.array([class_label_to_id(label) for label in y_train])\n",
    "\n",
    "# Step 4: Cast to categorical one-hot encoded variables\n",
    "# Set num_classes to the number of unique classes\n",
    "y_train_one_hot = to_categorical(y_train_mapped, num_classes=num_classes)\n",
    "\n",
    "# Fit the model with one-hot encoded labels (y_train_one_hot)\n",
    "history = model.fit(X_train, y_train_one_hot, epochs=10)\n",
    "\n",
    "# Plot the accuracy and loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
