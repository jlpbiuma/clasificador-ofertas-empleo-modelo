{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 17:16:20.767967: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-24 17:16:20.818540: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-24 17:16:20.818610: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-24 17:16:20.818678: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-24 17:16:20.829584: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-24 17:16:20.830232: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-24 17:16:21.938579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from functions.vectorization import *\n",
    "from functions.labelization import *\n",
    "from functions.vocabulary import *\n",
    "from functions.model import *\n",
    "from functions.predict import *\n",
    "from functions.tools import count_words\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PALABRAS_EMPLEO_TEXTO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PALABRAS_EMPLEO_TEXTO'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/notebooks/jobmarket/NB_test_01_predict.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.70.205/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/notebooks/jobmarket/NB_test_01_predict.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m df_test\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mupper() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m df_test\u001b[39m.\u001b[39mcolumns]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.70.205/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/notebooks/jobmarket/NB_test_01_predict.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# df_test['ID_PUESTO_ESCO_ULL'] = df_test['ID_PUESTO_ESCO_ULL'].apply(lambda x: str(int(x)))\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.70.205/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/notebooks/jobmarket/NB_test_01_predict.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m df_test[\u001b[39m'\u001b[39m\u001b[39mNUM_WORDS\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m count_words(df_test)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.70.205/home/fulp/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/notebooks/jobmarket/NB_test_01_predict.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m df_test\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/notebooks/jobmarket/functions/tools.py:28\u001b[0m, in \u001b[0;36mcount_words\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcount_words\u001b[39m(df):\n\u001b[1;32m     27\u001b[0m     \u001b[39m# Count the number of words in the column PALABRAS_EMPLEO_TEXTO\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mNUM_WORDS\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mPALABRAS_EMPLEO_TEXTO\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m df[\u001b[39m'\u001b[39m\u001b[39mNUM_WORDS\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/clasificador_ofertas_empleo/clasificador-ofertas-empleo-modelo/.venv/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PALABRAS_EMPLEO_TEXTO'"
     ]
    }
   ],
   "source": [
    "path_test = './test/offers_nacional_enero_2023.json'\n",
    "df_test = pd.read_json(path_test, orient='records', lines=True)\n",
    "# Set to upper the column names\n",
    "df_test.columns = [x.upper() for x in df_test.columns]\n",
    "# df_test['ID_PUESTO_ESCO_ULL'] = df_test['ID_PUESTO_ESCO_ULL'].apply(lambda x: str(int(x)))\n",
    "df_test['NUM_WORDS'] = count_words(df_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize test offers and id to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_vocabulary = '../data/train/vocabulary.json'\n",
    "vocabulary = load_vocabulary(path_vocabulary)\n",
    "test_vectors = np.vstack(create_vectorize_dataframe(df_test, vocabulary))\n",
    "path_ids_labels = '../data/train/ids_labels.json'\n",
    "dict_label_ids = load_dict_label_ids(path_ids_labels)\n",
    "# real_ids = list(df_test['ID_PUESTO_ESCO_ULL'])\n",
    "# test_labels = cast_id_to_labels(real_ids, dict_label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model= '../model/my_model_V15.h5'\n",
    "model = load_model(path_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get accuracy and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 12:37:37.976744: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 740138880 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1268/1268 [==============================] - 3s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Get the accuracy for this TEST\n",
    "# accuracy = get_accuracy(model, test_vectors, dict_label_ids, real_ids)\n",
    "# Print the value of accuracy in percentage with 2 decimals\n",
    "# print('Accuracy: {:.2%}'.format(accuracy))\n",
    "# Get predictions for this TEST\n",
    "predictions_id, probability = get_predictions(model, test_vectors, dict_label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = pd.DataFrame({'ID_OFERTA': df_test['ID_OFERTA'],\n",
    "                            'PREDICTED_ID': predictions_id,\n",
    "                            'PROBABILITY': probability,\n",
    "                            'NUM_OF_WORDS': df_test['NUM_WORDS']})\n",
    "df_report.head()\n",
    "df_report.to_csv('../reports/test_estudio_consejo_social_enero_agosto.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
