{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import ngrams\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "dictionary_path = './static/'\n",
    "stopwords = stopwords.words('spanish')\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "df_empleo = pd.read_csv(dictionary_path + 'diccionario_empleo.csv')\n",
    "df_equivalencias = pd.read_csv(dictionary_path + 'diccionario_equivalencias.csv')\n",
    "df_collocations = pd.read_csv(dictionary_path + 'diccionario_collocation.csv')\n",
    "list_collocations = df_collocations['FORMAS'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_vector_palabras_json(texto, palabra_generica=\"T\"):\n",
    "    # importamos las librerías necesarias\n",
    "    #Obtenemos las stopwords del idioma del módulo nltk\n",
    "    #adverbios\n",
    "    adverbios = ['ahora', 'antes', 'despues', 'tarde', 'luego', 'ayer', 'temprano', 'ya',\n",
    "             'todavia', 'anteayer', 'aun', 'pronto', 'hoy', 'aqui', 'ahi', 'alli',\n",
    "             'cerca', 'lejos', 'fuera', 'dentro', 'alrededor', 'aparte', 'encima',\n",
    "             'debajo', 'delante', 'detras', 'asi', 'bien', 'mal', 'despacio',\n",
    "             'deprisa', 'como', 'mucho', 'poco', 'muy', 'casi', 'todo', 'nada', 'algo',\n",
    "             'medio', 'demasiado', 'bastante', 'mas', 'menos', 'ademas', 'incluso',\n",
    "             'tambien', 'si', 'asimismo', 'no', 'tampoco', 'jamas', 'nunca', 'acaso',\n",
    "             'quiza', 'quizas', 'tal', 'vez', 'mejor']\n",
    "    stopwords.extend(adverbios)\n",
    "\n",
    "    # Obtengo en un dataframe el diccionario de empleo\n",
    "    with open(dictionary_path + 'diccionario_empleo.json', encoding=\"latin-1\") as f:\n",
    "        aux_emp = f.read()\n",
    "    diccionario_empleo = json.loads(aux_emp)\n",
    "\n",
    "    diccionario_palabra = {}\n",
    "    diccionario_masc = {}\n",
    "    diccionario_fem = {}\n",
    "    diccionario_masc_p = {}\n",
    "    diccionario_fem_p = {}\n",
    "    for i in range(len(diccionario_empleo)):\n",
    "        if not (isinstance(diccionario_empleo[i]['PALABRA'], float)):\n",
    "            # quitar caracteres a la izquierda y la derecha (se ha omitido los símbolos + y @)\n",
    "            tratar = diccionario_empleo[i]['PALABRA'].strip(r\"!#$%^&*()[]{};:,./<>?\\|`~-'=_·\")\n",
    "            tratar = tratar.strip('\"')\n",
    "\n",
    "            # quitamos el símbolo español ¡¿ºª y corregimos los acentos y letra ñ\n",
    "            sin_simbolo = tratar.replace(\"¡\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"»\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"«\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"¿\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"°\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"º\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ª\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"á\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"à\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"À\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Á\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"é\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"è\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"È\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"É\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"í\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ì\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ì\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Í\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ó\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ò\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ò\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ó\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ú\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ù\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ù\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ú\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ñ\", \"Ñ\")\n",
    "\n",
    "            # corrección de tildes\n",
    "            sin_simbolo = sin_simbolo.replace(\"?\", \"\")\n",
    "\n",
    "            # comprobamos que no sea un número\n",
    "            es_numero = sin_simbolo.isdigit()\n",
    "\n",
    "            # guardamos la palabra si no es número y no vacío\n",
    "            if ((es_numero == False) and (sin_simbolo != '')):\n",
    "                # sustituimos en el diccionario la palabra tratada\n",
    "                palabra_final = sin_simbolo\n",
    "\n",
    "            diccionario_palabra[palabra_final] = i\n",
    "\n",
    "        # MASCULINO\n",
    "        if ((not (isinstance(diccionario_empleo[i]['MASCULINO'], float))) & (\n",
    "                str(diccionario_empleo[i]['MASCULINO']).isdigit() == False)):\n",
    "            # quitamos el símbolo español ¡¿ºª y corregimos los acentos y letra ñ\n",
    "            sin_simbolo = str(diccionario_empleo[i]['MASCULINO']).replace(\"¡\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"»\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"«\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"¿\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"°\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"º\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ª\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"á\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"à\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"À\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Á\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"é\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"è\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"È\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"É\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"í\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ì\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ì\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Í\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ó\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ò\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ò\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ó\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ú\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ù\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ù\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ú\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ñ\", \"Ñ\")\n",
    "\n",
    "            # comprobamos que no sea un número\n",
    "            es_numero = sin_simbolo.isdigit()\n",
    "\n",
    "            # guardamos la palabra si no es número y no vacío\n",
    "            if ((es_numero == False) and (sin_simbolo != '')):\n",
    "                # sustituimos en el diccionario la palabra tratada\n",
    "                masculino_final = sin_simbolo\n",
    "                diccionario_masc[masculino_final] = i\n",
    "\n",
    "        # FEMENINO\n",
    "        if ((not (isinstance(diccionario_empleo[i]['FEMENINO'], float))) & (\n",
    "                str(diccionario_empleo[i]['FEMENINO']).isdigit() == False)):\n",
    "\n",
    "            sin_simbolo = str(diccionario_empleo[i]['FEMENINO']).replace(\"á\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"á\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"à\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"À\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Á\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"é\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"è\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"È\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"É\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"í\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ì\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ì\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Í\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ó\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ò\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ò\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ó\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ú\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ù\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ù\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ú\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ñ\", \"Ñ\")\n",
    "\n",
    "            # comprobamos que no sea un número\n",
    "            es_numero = sin_simbolo.isdigit()\n",
    "\n",
    "            # guardamos la palabra si no es número y no vacío\n",
    "            if ((es_numero == False) and (sin_simbolo != '')):\n",
    "                # sustituimos en el diccionario la palabra tratada\n",
    "                femenino_final = sin_simbolo\n",
    "                diccionario_fem[femenino_final] = i\n",
    "\n",
    "        # MASC_PLURAL\n",
    "        if ((not (isinstance(diccionario_empleo[i]['MASC_PLURAL'], float))) & (\n",
    "                str(diccionario_empleo[i]['MASC_PLURAL']).isdigit() == False)):\n",
    "\n",
    "            sin_simbolo = str(diccionario_empleo[i]['MASC_PLURAL']).replace(\"á\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"à\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"À\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Á\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"é\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"è\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"È\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"É\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"í\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ì\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ì\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Í\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ó\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ò\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ò\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ó\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ú\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ù\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ù\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ú\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ñ\", \"Ñ\")\n",
    "\n",
    "            # comprobamos que no sea un número\n",
    "            es_numero = sin_simbolo.isdigit()\n",
    "\n",
    "            # guardamos la palabra si no es número y no vacío\n",
    "            if ((es_numero == False) and (sin_simbolo != '')):\n",
    "                # sustituimos en el diccionario la palabra tratada\n",
    "                masc_plural_final = sin_simbolo\n",
    "                diccionario_masc_p[masc_plural_final] = i\n",
    "\n",
    "        # FEM_PLURAL\n",
    "        if ((not (isinstance(diccionario_empleo[i]['FEM_PLURAL'], float))) & (\n",
    "                str(diccionario_empleo[i]['FEM_PLURAL']).isdigit() == False)):\n",
    "\n",
    "            sin_simbolo = str(diccionario_empleo[i]['FEM_PLURAL']).replace(\"á\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"à\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"À\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Á\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"é\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"è\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"È\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"É\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"í\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ì\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ì\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Í\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ó\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ò\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ò\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ó\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ú\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ù\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ù\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ú\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ñ\", \"Ñ\")\n",
    "\n",
    "            # comprobamos que no sea un número\n",
    "            es_numero = sin_simbolo.isdigit()\n",
    "\n",
    "            # guardamos la palabra si no es número y no vacío\n",
    "            if ((es_numero == False) and (sin_simbolo != '')):\n",
    "                # sustituimos en el diccionario la palabra tratada\n",
    "                fem_plural_final = sin_simbolo\n",
    "                diccionario_fem_p[fem_plural_final] = i\n",
    "\n",
    "\n",
    "    # Obtengo en un dataframe el diccionario de equivalencias\n",
    "    with open(dictionary_path + 'diccionario_equivalencias.json',\n",
    "              encoding=\"latin-1\") as f:\n",
    "        aux_equiv = f.read()\n",
    "    diccionario_equiv = json.loads(aux_equiv)\n",
    "    \n",
    "    diccionario_equiv_p = {}\n",
    "    for i in range(len(diccionario_equiv)):\n",
    "        if ((not (isinstance(diccionario_equiv[i]['PALABRA'], float))) & (str(diccionario_equiv[i]['PALABRA']).isdigit() == False)):\n",
    "            # quitar caracteres a la izquierda y la derecha (se ha omitido los símbolos + y @)\n",
    "            tratar = diccionario_equiv[i]['PALABRA'].strip(r\"!#$%^&*()[]{};:,./<>?\\|`~-'=_·\")\n",
    "            tratar = tratar.strip('\"')\n",
    "\n",
    "            # quitamos el símbolo español ¡¿ºª y corregimos los acentos y letra ñ\n",
    "            sin_simbolo = tratar.replace(\"¡\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"»\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"«\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"¿\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"°\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"º\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ª\", \"\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"á\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"à\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"À\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Á\", \"A\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"é\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"è\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"È\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"É\", \"E\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"í\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ì\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ì\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Í\", \"I\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ó\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ò\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ò\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ó\", \"O\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ú\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ù\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ù\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"Ú\", \"U\")\n",
    "            sin_simbolo = sin_simbolo.replace(\"ñ\", \"Ñ\")\n",
    "\n",
    "            # corrección de tildes\n",
    "            sin_simbolo = sin_simbolo.replace(\"?\", \"\")\n",
    "\n",
    "            # comprobamos que no sea un número\n",
    "            es_numero = sin_simbolo.isdigit()\n",
    "\n",
    "            # guardamos la palabra si no es número y no vacío\n",
    "            if ((es_numero == False) and (sin_simbolo != '')):\n",
    "                # sustituimos en el diccionario la palabra tratada\n",
    "                equivalencia_palabra = sin_simbolo\n",
    "                diccionario_equiv_p[equivalencia_palabra] = i\n",
    "\n",
    "    vector_palabras = list()\n",
    "\n",
    "    lista_palabras = str(texto).lower()\n",
    "    palabras = lista_palabras.split()\n",
    "    filtered_words = [word for word in palabras if word not in stopwords]\n",
    "\n",
    "    table = {33: 32, 35: 32, 36: 32, 37: 32, 94: 32, 38: 32, 42: 32, 40: 32, 41: 32, 91: 32, 93: 32,\n",
    "             123: 32, 125: 32, 58: 32, 59: 32, 44: 32, 47: 32, 60: 32, 62: 32, 92: 32, 124: 32, 96: 32,\n",
    "             126: 32, 45: 32, 34: 32, 39: 32, 61: 32, 95: 32, 43: 32}\n",
    "\n",
    "    palabras_encontradas = []\n",
    "\n",
    "    for j in range(len(filtered_words)):\n",
    "        sin_simbolo = filtered_words[j].replace(\"¡\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"»\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"«\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"¿\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"°\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"º\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ª\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"_x000d_\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"@\", \"o\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"á\", \"a\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"à\", \"a\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"À\", \"a\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Á\", \"a\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"é\", \"e\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"è\", \"e\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"È\", \"e\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"É\", \"e\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"í\", \"i\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ì\", \"i\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Ì\", \"i\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Í\", \"i\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ó\", \"o\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ò\", \"o\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Ò\", \"o\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Ó\", \"o\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ú\", \"u\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ù\", \"u\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Ù\", \"u\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Ú\", \"u\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ñ\", \"ñ\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"?\", \"\")\n",
    "        tratar = sin_simbolo.strip(r\"!#$%^&*()[]{};:,./<>?\\|`~-'=_·\")\n",
    "        tratar2 = tratar.translate(table)\n",
    "        palabras = tratar2.split()\n",
    "        tokens = []\n",
    "        for palabra in palabras:\n",
    "            if palabra not in stopwords:\n",
    "                tokens.append(palabra.upper())\n",
    "        for w in tokens:\n",
    "            es_numero = w.isdigit()\n",
    "            if len(w) > 2 and not es_numero:\n",
    "                palabras_encontradas.append(w)\n",
    "\n",
    "    for i in range(len(palabras_encontradas)):\n",
    "        # Se comprueba PALABRA de DICCIONARIO_EMPLEO\n",
    "        if palabras_encontradas[i] in diccionario_palabra and diccionario_empleo[diccionario_palabra[palabras_encontradas[i]]]['PALABRA'] not in vector_palabras and (diccionario_empleo[diccionario_palabra[palabras_encontradas[i]]]['PALABRA_GENERICA'] == str(palabra_generica) or str(palabra_generica) == \"T\"):\n",
    "            vector_palabras.append(diccionario_empleo[diccionario_palabra[palabras_encontradas[i]]]['PALABRA'])\n",
    "        # Se comprueba MASCULINO de DICCIONARIO_EMPLEO\n",
    "        elif palabras_encontradas[i] in diccionario_masc and diccionario_empleo[diccionario_masc[palabras_encontradas[i]]]['PALABRA'] not in vector_palabras and (diccionario_empleo[diccionario_masc[palabras_encontradas[i]]]['PALABRA_GENERICA'] == str(palabra_generica) or str(palabra_generica) == \"T\"):\n",
    "            vector_palabras.append(diccionario_empleo[diccionario_masc[palabras_encontradas[i]]]['PALABRA'])\n",
    "        # Se comprueba FEMENINO de DICCIONARIO_EMPLEO\n",
    "        elif palabras_encontradas[i] in diccionario_fem and diccionario_empleo[diccionario_fem[palabras_encontradas[i]]]['PALABRA'] not in vector_palabras and (diccionario_empleo[diccionario_fem[palabras_encontradas[i]]]['PALABRA_GENERICA'] == str(palabra_generica) or str(palabra_generica) == \"T\"):\n",
    "            vector_palabras.append(diccionario_empleo[diccionario_fem[palabras_encontradas[i]]]['PALABRA'])\n",
    "        # Se comprueba MASC_PLURAL de DICCIONARIO_EMPLEO\n",
    "        elif palabras_encontradas[i] in diccionario_masc_p and diccionario_empleo[diccionario_masc_p[palabras_encontradas[i]]]['PALABRA'] not in vector_palabras and (diccionario_empleo[diccionario_masc_p[palabras_encontradas[i]]]['PALABRA_GENERICA'] == str(palabra_generica) or str(palabra_generica) == \"T\"):\n",
    "            vector_palabras.append(diccionario_empleo[diccionario_masc_p[palabras_encontradas[i]]]['PALABRA'])\n",
    "        # Se comprueba FEM_PLURAL de DICCIONARIO_EMPLEO\n",
    "        elif palabras_encontradas[i] in diccionario_fem_p and diccionario_empleo[diccionario_fem_p[palabras_encontradas[i]]]['PALABRA'] not in vector_palabras and (diccionario_empleo[diccionario_fem_p[palabras_encontradas[i]]]['PALABRA_GENERICA'] == str(palabra_generica) or str(palabra_generica) == \"T\"):\n",
    "            vector_palabras.append(diccionario_empleo[diccionario_fem_p[palabras_encontradas[i]]]['PALABRA'])\n",
    "        # Se comprueba DICCIONARIO_EQUIVALENCIAS\n",
    "        elif palabras_encontradas[i] in diccionario_equiv_p and diccionario_equiv[diccionario_equiv_p[palabras_encontradas[i]]]['PALABRA_CORRECTA'] not in vector_palabras and (diccionario_empleo[diccionario_equiv_p[palabras_encontradas[i]]]['PALABRA_GENERICA'] == str(palabra_generica) or str(palabra_generica) == \"T\"):\n",
    "            vector_palabras.append(diccionario_equiv[diccionario_equiv_p[palabras_encontradas[i]]]['PALABRA_CORRECTA'])\n",
    "    return vector_palabras\n",
    "\n",
    "\n",
    "def f_vector_collocation_json(texto):\n",
    "\n",
    "    # adverbios\n",
    "    adverbios = ['ahora', 'antes', 'despues', 'tarde', 'luego', 'ayer', 'temprano', 'ya',\n",
    "                 'todavia', 'anteayer', 'aun', 'pronto', 'hoy', 'aqui', 'ahi', 'alli',\n",
    "                 'cerca', 'lejos', 'fuera', 'dentro', 'alrededor', 'aparte', 'encima',\n",
    "                 'debajo', 'delante', 'detras', 'asi', 'bien', 'mal', 'despacio',\n",
    "                 'deprisa', 'como', 'mucho', 'poco', 'muy', 'casi', 'todo', 'nada', 'algo',\n",
    "                 'medio', 'demasiado', 'bastante', 'mas', 'menos', 'ademas', 'incluso',\n",
    "                 'tambien', 'si', 'asimismo', 'no', 'tampoco', 'jamas', 'nunca', 'acaso',\n",
    "                 'quiza', 'quizas', 'tal', 'vez', 'mejor']\n",
    "    stopwords.extend(adverbios)\n",
    "\n",
    "    # obtengo en un dataframe el diccionario de collocation\n",
    "    with open(dictionary_path + 'diccionario_collocation.json',\n",
    "              encoding=\"latin-1\") as f:\n",
    "        aux_collocations = f.read()\n",
    "    diccionario_collocations = json.loads(aux_collocations)\n",
    "\n",
    "    # obtengo en un dataframe el diccionario de equivalencias de collocation\n",
    "    with open(dictionary_path + 'diccionario_equivalencias_collocation.json',\n",
    "              encoding=\"latin-1\") as f:\n",
    "        aux_equiv = f.read()\n",
    "    dic_equiv_collocations = json.loads(aux_equiv)\n",
    "\n",
    "    vector_collocation = list()\n",
    "    collocations_dic = list()\n",
    "    collocations_equiv = list()\n",
    "\n",
    "    for i in range(len(diccionario_collocations)):\n",
    "        collocations_dic.append(diccionario_collocations[i]['RAIZ_COLLOCATION'])\n",
    "\n",
    "    for i in range(len(dic_equiv_collocations)):\n",
    "        collocations_equiv.append(dic_equiv_collocations[i]['RAIZ_COLLOCATION'])\n",
    "\n",
    "    stemmer = SnowballStemmer(\"spanish\")\n",
    "\n",
    "    lista_palabras = str(texto).lower()\n",
    "    palabras = lista_palabras.split()\n",
    "    filtered_words = [word for word in palabras if word not in stopwords]\n",
    "\n",
    "    table = {33: 32, 35: 32, 36: 32, 37: 32, 94: 32, 38: 32, 42: 32, 40: 32, 41: 32, 91: 32, 93: 32,\n",
    "             123: 32, 125: 32, 58: 32, 59: 32, 44: 32, 47: 32, 60: 32, 62: 32, 92: 32, 124: 32, 96: 32,\n",
    "             126: 32, 45: 32, 34: 32, 39: 32, 61: 32, 95: 32, 43: 32}\n",
    "\n",
    "    palabras_encontradas = []\n",
    "\n",
    "    for j in range(len(filtered_words)):\n",
    "        sin_simbolo = filtered_words[j].replace(\"¡\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"»\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"«\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"¿\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"°\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"º\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ª\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"_x000d_\", \"\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"@\", \"o\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"á\", \"a\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"à\", \"a\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"À\", \"a\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Á\", \"a\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"é\", \"e\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"è\", \"e\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"È\", \"e\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"É\", \"e\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"í\", \"i\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ì\", \"i\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Ì\", \"i\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Í\", \"i\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ó\", \"o\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ò\", \"o\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Ò\", \"o\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Ó\", \"o\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ú\", \"u\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ù\", \"u\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Ù\", \"u\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"Ú\", \"u\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"ñ\", \"ñ\")\n",
    "        sin_simbolo = sin_simbolo.replace(\"?\", \"\")\n",
    "        tratar = sin_simbolo.strip(r\"!#$%^&*()[]{};:,./<>?\\|`~-'=_·\")\n",
    "        tratar2 = tratar.translate(table)\n",
    "        palabras = tratar2.split()\n",
    "        tokens = []\n",
    "        for palabra in palabras:\n",
    "            if palabra not in stopwords:\n",
    "                tokens.append(palabra.upper())\n",
    "        for w in tokens:\n",
    "            es_numero = w.isdigit()\n",
    "            if len(w) > 2 and not es_numero:\n",
    "                palabras_encontradas.append(w)\n",
    "    collocations = []\n",
    "    for n in [2, 3]:\n",
    "        collocations.extend(nltk.ngrams(palabras_encontradas, n))\n",
    "\n",
    "    for coll in collocations:\n",
    "        if len(coll) == 2:\n",
    "            coll_final = coll[0] + \" \" + coll[1]\n",
    "        if len(coll) == 3:\n",
    "            coll_final = coll[0] + \" \" + coll[1] + \" \" + coll[2]\n",
    "        coll_sep = coll_final.split(sep=' ')\n",
    "        coll_def = \"\"\n",
    "        for k in range(len(coll_sep)):\n",
    "            coll_def = coll_def + stemmer.stem(coll_sep[k]).upper() + \" \"\n",
    "        coll_def = coll_def[:-1]\n",
    "        if coll_def in collocations_dic and coll_final not in vector_collocation:\n",
    "            vector_collocation.append(coll_final)\n",
    "        elif coll_def in collocations_equiv and coll_final not in vector_collocation:\n",
    "            vector_collocation.append(coll_final)\n",
    "\n",
    "    value = {\n",
    "        \"vector_collocation\": vector_collocation\n",
    "    }\n",
    "\n",
    "    return json.dumps(value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "expections = [\"@\", r\"\\.\"]\n",
    "\n",
    "def clean_text(text):\n",
    "    # ! EXCEPCIONES MANUALES!!!\n",
    "    # Cast exceptions to \"a\"\n",
    "    text = re.sub(r'@', 'a', text)\n",
    "    # Cast from \".\" to \"\"\n",
    "    text = re.sub(r'\\.', '', text)\n",
    "    \n",
    "    # Trim the text\n",
    "    text = text.strip()\n",
    "    # Remove accents using unidecode, excluding 'ñ' and 'Ñ'\n",
    "    text = ''.join(char if char in ('ñ', 'Ñ') else unidecode(char) for char in text)\n",
    "    # Delete non-alphanumeric characters\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # Delete additional spaces with regex\n",
    "    text = re.sub(r'\\s+', ' ', text).upper()\n",
    "    return text\n",
    "\n",
    "def get_words_by_text(text):\n",
    "    # Clean the text\n",
    "    text = clean_text(text)\n",
    "    # Split the text by \" \"\n",
    "    list_words = text.split(\" \")\n",
    "    # Delete empty strings\n",
    "    list_words = list(filter(None, list_words))\n",
    "    # Delete stopwords\n",
    "    list_words = [word for word in list_words if word not in stopwords]\n",
    "    final_words = []\n",
    "    for word in list_words:\n",
    "        # Find the word in the dataframe FORMA column and return the LEMA column the first match\n",
    "        lema_empleo = df_empleo[df_empleo['FORMA'] == word]['LEMA'].values\n",
    "        if len(lema_empleo) > 0:\n",
    "            final_words.append(lema_empleo[0])\n",
    "        lema_equivalencias = df_equivalencias[df_equivalencias['FORMA'] == word]['LEMA'].values\n",
    "        if len(lema_equivalencias) > 0:\n",
    "            final_words.append(lema_equivalencias[0])\n",
    "    # Delete duplicates\n",
    "    final_words = list(set(final_words))\n",
    "    return final_words\n",
    "\n",
    "# Change to upper case all stopwords\n",
    "stopwords = [word.upper() for word in stopwords]\n",
    "\n",
    "def clean_text(text):\n",
    "    # ! EXCEPCIONES MANUALES!!!\n",
    "    # Cast exceptions to \"a\"\n",
    "    text = re.sub(r'@', 'a', text)\n",
    "    # Cast from \".\" to \"\"\n",
    "    text = re.sub(r'\\.', '', text)\n",
    "    # Trim the text\n",
    "    text = text.strip()\n",
    "    # Remove accents using unidecode, excluding 'ñ' and 'Ñ'\n",
    "    text = ''.join(char if char in ('ñ', 'Ñ') else unidecode(char) for char in text)\n",
    "    # Delete non-alphanumeric characters\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # Delete additional spaces with regex\n",
    "    text = re.sub(r'\\s+', ' ', text).upper()\n",
    "    return text\n",
    "\n",
    "def filter_words(text):\n",
    "    # Split the text by \" \"\n",
    "    list_words = text.split(\" \")\n",
    "    # Delete empty strings\n",
    "    list_words = list(filter(None, list_words))\n",
    "    # Filter all stopwords\n",
    "    return [word for word in list_words if word not in stopwords]\n",
    "\n",
    "def get_list_stems(list_words):\n",
    "    # Get stems\n",
    "    return [stemmer.stem(word).upper() for word in list_words]\n",
    "\n",
    "def get_n_gramas(list_stems, min_n_gramas, max_n_gramas):\n",
    "    list_n_gramas = [\" \".join(n_grama) for n in range(min_n_gramas, max_n_gramas + 1)\n",
    "                     for n_grama in ngrams(list_stems, n)]\n",
    "    return list_n_gramas\n",
    "\n",
    "def calculate_forms(text, min_n_gramas=2, max_n_gramas=4):\n",
    "    # First clean text\n",
    "    text = clean_text(text)\n",
    "    # Filter words\n",
    "    list_words = filter_words(text)\n",
    "    # Get list of stems\n",
    "    list_stems = get_list_stems(list_words)\n",
    "    # Get the n gramas\n",
    "    list_n_gramas = get_n_gramas(list_stems, min_n_gramas, max_n_gramas)\n",
    "    if list_n_gramas != []:\n",
    "        return list_n_gramas\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def find_collocations(list_forms):\n",
    "    collocations = []\n",
    "    for form in list_forms:\n",
    "        if form in list_collocations:\n",
    "            collocations.append(form)\n",
    "    return collocations\n",
    "\n",
    "def find_lema(list_collocations):\n",
    "    lemas = []\n",
    "    for collaction in list_collocations:\n",
    "        lema = df_collocations[df_collocations[\"FORMAS\"] == collaction][\"LEMA\"].iloc[0]\n",
    "        lemas.append(lema)\n",
    "    return lemas\n",
    "        \n",
    "\n",
    "def get_collocations(descripcion_oferta):\n",
    "    # Get all forms from the description\n",
    "    list_forms = calculate_forms(descripcion_oferta)\n",
    "    # Find in the list of collocations\n",
    "    list_collocations = find_collocations(list_forms)\n",
    "    # Get the LEMA from the collocations\n",
    "    list_lema_found = find_lema(list_collocations)\n",
    "    # Delete duplicates\n",
    "    list_lema_non_duplicated = list(set(list_lema_found))\n",
    "    return list_lema_non_duplicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descripcion_oferta</th>\n",
       "      <th>COLLOCATIONS_LEGACY</th>\n",
       "      <th>COLLOCATIONS_MISSING</th>\n",
       "      <th>COLLOCATIONS_NEW</th>\n",
       "      <th>COLLOCATIONS_GAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38495</th>\n",
       "      <td>El Grupo DinoSol, empresa líder en distribució...</td>\n",
       "      <td>[TRABAJO EQUIPO]</td>\n",
       "      <td>[TRABAJO EQUIPO]</td>\n",
       "      <td>[TRABAJAR EQUIPOS, ORIENTACION CLIENTE]</td>\n",
       "      <td>[TRABAJAR EQUIPOS, ORIENTACION CLIENTE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49219</th>\n",
       "      <td>SANJOSE CONSTRUCTORA, precisa encontrar al men...</td>\n",
       "      <td>[EQUIPO TRABAJARAS, SECTOR CONSTRUCCION, ESTRA...</td>\n",
       "      <td>[SECTOR CONSTRUCCION, EQUIPO TRABAJARAS]</td>\n",
       "      <td>[ESTRATEGIA EMPRESARIAL, EQUIPOS TRABAJO]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4189</th>\n",
       "      <td>Inerza, empresa líder en el sector TIC en Cana...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44509</th>\n",
       "      <td>Grupo CTC, empresa de externalización de servi...</td>\n",
       "      <td>[SERVICIOS LOGISTICOS, PREPARACION MANUAL]</td>\n",
       "      <td>[PREPARACION MANUAL]</td>\n",
       "      <td>[SERVICIOS LOGISTICOS]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45248</th>\n",
       "      <td>En Princess Hotels &amp; Resorts buscamos camarero...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      descripcion_oferta  \\\n",
       "38495  El Grupo DinoSol, empresa líder en distribució...   \n",
       "49219  SANJOSE CONSTRUCTORA, precisa encontrar al men...   \n",
       "4189   Inerza, empresa líder en el sector TIC en Cana...   \n",
       "44509  Grupo CTC, empresa de externalización de servi...   \n",
       "45248  En Princess Hotels & Resorts buscamos camarero...   \n",
       "\n",
       "                                     COLLOCATIONS_LEGACY  \\\n",
       "38495                                   [TRABAJO EQUIPO]   \n",
       "49219  [EQUIPO TRABAJARAS, SECTOR CONSTRUCCION, ESTRA...   \n",
       "4189                                                  []   \n",
       "44509         [SERVICIOS LOGISTICOS, PREPARACION MANUAL]   \n",
       "45248                                                 []   \n",
       "\n",
       "                           COLLOCATIONS_MISSING  \\\n",
       "38495                          [TRABAJO EQUIPO]   \n",
       "49219  [SECTOR CONSTRUCCION, EQUIPO TRABAJARAS]   \n",
       "4189                                         []   \n",
       "44509                      [PREPARACION MANUAL]   \n",
       "45248                                        []   \n",
       "\n",
       "                                COLLOCATIONS_NEW  \\\n",
       "38495    [TRABAJAR EQUIPOS, ORIENTACION CLIENTE]   \n",
       "49219  [ESTRATEGIA EMPRESARIAL, EQUIPOS TRABAJO]   \n",
       "4189                                          []   \n",
       "44509                     [SERVICIOS LOGISTICOS]   \n",
       "45248                                         []   \n",
       "\n",
       "                             COLLOCATIONS_GAIN  \n",
       "38495  [TRABAJAR EQUIPOS, ORIENTACION CLIENTE]  \n",
       "49219                                       []  \n",
       "4189                                        []  \n",
       "44509                                       []  \n",
       "45248                                       []  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_offers = pd.read_json(data_path + \"descripcion_ofertas_infojobs_21_23.json\")\n",
    "# Get 100 random samples from the dataset\n",
    "df_test = df_offers.sample(100)\n",
    "\n",
    "# df_test[\"PALABRAS_LEGACY\"] = df_test[\"descripcion_oferta\"].apply(lambda x: f_vector_palabras_json(x))\n",
    "# df_test[\"PALABRAS_NEW\"] = df_test[\"descripcion_oferta\"].apply(get_words_by_text)\n",
    "df_test[\"COLLOCATIONS_LEGACY\"] = df_test[\"descripcion_oferta\"].apply(lambda x: json.loads(f_vector_collocation_json(x))[\"vector_collocation\"])\n",
    "# Enumerate the number of finded collocations\n",
    "df_test[\"COLLOCATIONS_NEW\"] = df_test[\"descripcion_oferta\"].apply(get_collocations)\n",
    "\n",
    "# Get the collocations in legacy that not appear in new\n",
    "df_test[\"COLLOCATIONS_MISSING\"] = df_test.apply(lambda x: list(set(x[\"COLLOCATIONS_LEGACY\"]) - set(x[\"COLLOCATIONS_NEW\"])), axis=1)\n",
    "# Get the collocations in new that not appear in legacy\n",
    "df_test[\"COLLOCATIONS_GAIN\"] = df_test.apply(lambda x: list(set(x[\"COLLOCATIONS_NEW\"]) - set(x[\"COLLOCATIONS_LEGACY\"])), axis=1)\n",
    "\n",
    "# Move the columns\n",
    "df_test = df_test[[\"descripcion_oferta\", \"COLLOCATIONS_LEGACY\", \"COLLOCATIONS_MISSING\", \"COLLOCATIONS_NEW\", \"COLLOCATIONS_GAIN\"]]\n",
    "\n",
    "df_test.to_csv(data_path + \"descripcion_ofertas_infojobs_21_23_test.csv\", index=True, sep=\";\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate words and collocations by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'descripcion_oferta': 'Si te apasiona el diseño y la creación de productos, eres capaz de hacer que la experiencia del cliente sea única y estás buscando un nuevo reto profesional ¡esta vacante es para ti! \\r\\n\\r\\nEn The Client Group, formado por SmartCEX, CCI y CLICC, nos especializamos en construir relaciones duraderas entre organizaciones y clientes, mediante una combinación de Customer y Employee Experience.\\r\\n\\r\\nActualmente, estamos en búsqueda de un/a Product Manager para proyecto estable, que, reportando directamente a la Dirección de Marketing, se responsabilizará de desarrollar e implementar productos y soluciones de las diferentes líneas de negocio.\\r\\n\\r\\n¿Qué requisitos deberías aportar?\\r\\n·\\tExperiencia mínima de 2 años como Product Manager o puesto similar de desarrollo de servicios de alto valor.\\r\\n·\\tExperiencia en el desarrollo de la estrategia online y offline de producto en el territorio nacional.\\r\\n·\\tCapacidad para analizar e identificar oportunidades de mercado y tendencias de las necesidades de los clientes.\\r\\n·\\tExperiencia en la generación del material para el equipo de ventas (briefings, presentaciones, etc.).\\r\\n·\\tExperiencia en la gestión del lanzamiento y testeo de piezas iniciales de producto.\\r\\n·\\tExperiencia en el apoyo y activa participación en Workshops, Eventos y Paid media.\\r\\n·\\tExperiencia en el seguimiento del tráfico Web y optimización de las conversiones.\\r\\n·\\tExperiencia en la creación de estrategia y seguimiento del canal e-commerce (creación de campañas, organizar el portfolio, rastrear precios y velar por la convivencia con el canal de ventas tradicional).\\r\\n·\\tDisponibilidad para viajar a nivel nacional.\\r\\n·\\tCarnet de conducir y vehículo propio.\\r\\n·\\tDominio paquete office.\\r\\n·\\tCastellano, catalán e inglés.\\r\\n\\r\\n¿Qué ofrecemos? \\r\\n·\\tFormar parte de una organización que promueve el desarrollo profesional y personal del equipo, con un claro enfoque a la experiencia de cliente.\\r\\n·\\tIncorporación inmediata.\\r\\n·\\tContrato temporal + Indefinido.\\r\\n·\\tJornada laboral de 39 horas semanales, en horario de lunes a jueves de 9:00 a 18:00 y los viernes de 8:00 a 15:00.\\r\\n·\\tSalario fijo + retribución variable en función de resultados.\\r\\n·\\tTeletrabajo.', 'PALABRAS_LEGACY': ['DISEÑO', 'PRODUCTOS', 'EXPERIENCIA', 'CLIENTES', 'UNICA', 'CLIENTE', 'RELACIONES', 'ORGANIZACIONES', 'COMBINACIONES', 'EMPLEADO', 'PRODUCTO', 'MANAGERS', 'PROYECTO', 'DIRECCION', 'MARKETING', 'IMPLEMENTAR', 'SOLUCIONES', 'DESARROLLO', 'SERVICIOS', 'ESTRATEGIA', 'OFFLINE', 'TERRITORIO', 'CAPACIDAD', 'TENDENCIAS', 'MATERIAL', 'EQUIPOS', 'VENTAS', 'PRESENTACIONES', 'GESTION', 'LANZAMIENTO', 'TESTEO', 'APOYO', 'ACTIVOS', 'EVENTOS', 'SEGUIMIENTOS', 'TRAFICO', 'WEB', 'OPTIMIZACION', 'COMMERCE', 'CAMPAÑA', 'PORTFOLIO', 'VEHICULO', 'DOMINIO', 'OFFICE', 'CASTELLANA', 'CATALAN', 'INGLES', 'PERSONAL', 'CONTRATOS', 'LABORAL', 'SEMANALES', 'SALARIOS', 'RETRIBUCION', 'RESULTADOS', 'TELETRABAJO'], 'COLLOCATIONS_LEGACY': ['DIRECCION MARKETING', 'DESARROLLO SERVICIOS', 'EQUIPO VENTAS', 'CONDUCIR VEHICULO', 'EXPERIENCIA CLIENTE'], 'PALABRAS_NEW': ['DISEÑO', 'PRESENTACIONES', 'APOYO', 'MATERIAL', 'EMPLEADO', 'INGLES', 'VENTAS', 'GESTION', 'CATALAN', 'TELETRABAJO', 'COMBINACIONES', 'EQUIPOS', 'ORGANIZACIONES', 'COMMERCE', 'PORTFOLIO', 'DOMINIO', 'SEMANALES', 'RESULTADOS', 'IMPLEMENTAR', 'PERSONAL', 'CAMPAÑA', 'RELACIONES', 'MANAGERS', 'DIRECCION', 'SOLUCIONES', 'DESARROLLO', 'TESTEO', 'EXPERIENCIA', 'CONTRATOS', 'OPTIMIZACION', 'CLIENTES', 'PRECIOS', 'SEGUIMIENTOS', 'OFFLINE', 'OFFICE', 'PRODUCTO', 'CLIENTE', 'VEHICULO', 'CASTELLANA', 'TRAFICO', 'LABORAL', 'EVENTOS', 'TENDENCIAS', 'SERVICIOS', 'PROYECTO', 'RETRIBUCION', 'WEB', 'SIMILAR', 'UNICA', 'CAPACIDAD', 'TERRITORIO', 'MARKETING', 'ESTRATEGIA', 'ACTIVOS', 'PRODUCTOS', 'SALARIOS', 'LANZAMIENTO'], 'COLLOCATIONS_NEW': ['EXPERIENCIA CLIENTES', 'DIRECCION MARKETING', 'CONDUCIR VEHICULO', 'NECESIDADES CLIENTES', 'EQUIPOS VENTAS']}\n"
     ]
    }
   ],
   "source": [
    "def get_characteristics(df_offers, index):\n",
    "    offer = df_offers.iloc[index]\n",
    "    # Get the words from the description\n",
    "    offer[\"PALABRAS_LEGACY\"] = f_vector_palabras_json(offer[\"descripcion_oferta\"])\n",
    "    offer[\"COLLOCATIONS_LEGACY\"] = json.loads(f_vector_collocation_json(offer[\"descripcion_oferta\"]))[\"vector_collocation\"]\n",
    "    offer[\"PALABRAS_NEW\"] = get_words_by_text(offer[\"descripcion_oferta\"])\n",
    "    offer[\"COLLOCATIONS_NEW\"] = get_collocations(offer[\"descripcion_oferta\"])\n",
    "    return offer.to_dict()\n",
    "\n",
    "offer = get_characteristics(df_offers, 977)\n",
    "print(offer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
