{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.functions.tools import load_json\n",
    "import pandas as pd\n",
    "import time\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import test set and dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11123, 5)\n"
     ]
    }
   ],
   "source": [
    "data = load_json('./data/test/test_palabras.json')\n",
    "# Now cast data to a DataFrame\n",
    "test_df = pd.DataFrame(data)\n",
    "print(test_df.shape)\n",
    "test_df.head()\n",
    "sustantives_df = pd.read_csv('./data/diccionario/df_structured_sustantivos.csv')\n",
    "adjectives_df = pd.read_csv('./data/diccionario/df_structured_adjetivos.csv')\n",
    "# Read the txt files sustantives and adjectives\n",
    "with open('./data/diccionario/list_unstructured_sustantivos.txt', 'r') as f:\n",
    "    sustantives_forms = f.read().splitlines()\n",
    "with open('./data/diccionario/list_unstructured_adjetivos.txt', 'r') as f:\n",
    "    adjectives_forms = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "list_remove = [\"www\", \"com\",\"http\", \"https\"]\n",
    "\n",
    "def tokenize_descripcion(text):\n",
    "    # Remove links (URLs) from the text using regular expressions\n",
    "    text = re.sub(r'http(s)?:\\s+\\S+', '', text, flags=re.IGNORECASE)\n",
    "    # Remove all occurrences of \".es\" (case-insensitive)\n",
    "    text = re.sub(r'\\.es', '', text, flags=re.IGNORECASE)\n",
    "    # Remove all non alpha characters from the text using regular expressions\n",
    "    text = re.sub(r'[^a-zA-Z ]+', ' ', text, flags=re.IGNORECASE)\n",
    "    # Remove unnecessary spaces from the text using regular expressions\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.IGNORECASE)\n",
    "    # Cast all words to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def create_palabras_column(text):\n",
    "    # Split the text into a list of words and filter simultaneously\n",
    "    palabras = [palabra for palabra in text.split(\" \") if len(palabra) > 1 and palabra not in list_remove]\n",
    "    return palabras\n",
    "\n",
    "def list_words(palabras_empleo_texto):\n",
    "    # print(palabras_empleo_texto)\n",
    "    return palabras_empleo_texto.lower().split(\" \")[:-1]\n",
    "\n",
    "def clean_descripcion(df):\n",
    "    # tokenize the descripcion\n",
    "    df['descripcion_oferta'] = df['descripcion_oferta'].apply(tokenize_descripcion)\n",
    "    # Split the text into a list of words\n",
    "    df['palabras_descripcion_oferta'] = df['descripcion_oferta'].apply(create_palabras_column)\n",
    "    # Convert the string into a list\n",
    "    df['palabras_empleo_texto'] = df['palabras_empleo_texto'].apply(lambda x: list_words(x))\n",
    "    return df\n",
    "\n",
    "test_df = clean_descripcion(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_word(word):\n",
    "    # Delete all numbers\n",
    "    word = re.sub(r\"\\d+\", \"\", word)\n",
    "    # Delete all accents\n",
    "    word = unidecode(word.lower())\n",
    "    # Remove simbols\n",
    "    word = re.sub(r\"[^a-z0-9Ã±]\", \"\", word)\n",
    "    return word\n",
    "\n",
    "def get_reference(descripcion_oferta, df, index, column):\n",
    "    # Get the accuracy of the words in palabras_empleo_texto that are in descripcion_oferta\n",
    "    error = 0\n",
    "    accuracy = 0\n",
    "    for word in descripcion_oferta:\n",
    "        if unidecode(word) not in df[column].iloc[index]:\n",
    "            error += 1\n",
    "        else:\n",
    "            accuracy += 1\n",
    "    return error, accuracy\n",
    "\n",
    "def get_syntax(words, df_nouns, unstructured_forms_nouns, df_adj, unstructured_forms_adj, estricto=False):\n",
    "    # Object palabras_dict\n",
    "    palabras_dict = {}\n",
    "    # Object palabras_list\n",
    "    palabras_list = []\n",
    "    # Initialize nouns array\n",
    "    nouns = []\n",
    "    adjectives = []\n",
    "    # Split by \" \"\n",
    "    for word in words.split(\" \"):\n",
    "        word = clean_word(word)\n",
    "        # Verify if is a noun\n",
    "        noun = get_lemma_df(word, df_nouns, unstructured_forms_nouns)\n",
    "        adjective = get_lemma_df(word, df_adj, unstructured_forms_adj)\n",
    "        adjectives, nouns = inference(adjective, noun, estricto, adjectives, nouns)\n",
    "    palabras_dict[\"Sustantivos\"] = nouns\n",
    "    palabras_dict[\"Adjetivos\"] = adjectives\n",
    "    palabras_list = nouns + adjectives\n",
    "    return palabras_dict, palabras_list\n",
    "\n",
    "def clasify_estric_mode(adjective, noun, adjective_list, noun_list):\n",
    "    if adjective is not None:\n",
    "        adjective_list.append(adjective)\n",
    "    elif noun is not None:\n",
    "        noun_list.append(noun)\n",
    "    return adjective_list, noun_list\n",
    "\n",
    "def clasify_non_estric_mode(adjective, noun, adjective_list, noun_list):\n",
    "    if noun is not None:\n",
    "        noun_list.append(noun)\n",
    "    if adjective is not None:\n",
    "        adjective_list.append(adjective)\n",
    "    return adjective_list, noun_list\n",
    "\n",
    "def inference(adjective, noun, estricto, adjective_list, noun_list):\n",
    "    if estricto:\n",
    "        adjective_list, noun_list = clasify_estric_mode(adjective, noun, adjective_list, noun_list)\n",
    "    else:\n",
    "        adjective_list, noun_list = clasify_non_estric_mode(adjective, noun, adjective_list, noun_list)\n",
    "    return adjective_list, noun_list\n",
    "\n",
    "def get_lemma_df(word, df, unstructured_forms):\n",
    "    try:\n",
    "        word_index = unstructured_forms.index(word)\n",
    "        return df.iloc[word_index][\"LEMA\"]\n",
    "    except ValueError:\n",
    "        return None  # Handle the case when the word is not found\n",
    "\n",
    "def process_and_update_df(df, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms):\n",
    "    # Create a new column in the DataFrame to store the result\n",
    "    df[\"palabras_list_all\"] = \"\"\n",
    "    df[\"palabras_dict\"] = \"\"\n",
    "    # Iterate over the DataFrame and apply the word extraction function\n",
    "    for index, description in df[\"descripcion_oferta\"].items():\n",
    "        palabras_dict, palabras_list = get_syntax(description, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms)\n",
    "        # Save palabras_list in a new column in the DataFrame, insert the full list\n",
    "        df.at[index, \"palabras_list_all\"] = palabras_list\n",
    "        # Save palabras_dict in a new column in the DataFrame\n",
    "        df.at[index, \"palabras_dict\"] = palabras_dict\n",
    "    # Calculate and add the column with words that appear in palabras legacy but not in palabras nuevas\n",
    "    df[\"palabras_legacy_minus_nuevas\"] = df.apply(lambda row: list(set(row[\"palabras_empleo_texto\"]) - set(row[\"palabras_list_all\"])), axis=1)\n",
    "    return df\n",
    "\n",
    "# Function to measure time and apply the processing function\n",
    "def process_and_measure_time(df, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms):\n",
    "    start_time = time.time()\n",
    "    df = process_and_update_df(df, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms)\n",
    "    print(\"Time: \", time.time() - start_time)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  8.377092361450195\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_puesto_esco_ull</th>\n",
       "      <th>categoria</th>\n",
       "      <th>subcategoria</th>\n",
       "      <th>palabras_empleo_texto</th>\n",
       "      <th>descripcion_oferta</th>\n",
       "      <th>palabras_descripcion_oferta</th>\n",
       "      <th>palabras_list_all</th>\n",
       "      <th>palabras_dict</th>\n",
       "      <th>palabras_legacy_minus_nuevas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1634</td>\n",
       "      <td>Atencion a clientes</td>\n",
       "      <td>Atencion al cliente</td>\n",
       "      <td>[administrativo, persona, reservas, buceo, ges...</td>\n",
       "      <td>buscamos una persona encargada de gestionar la...</td>\n",
       "      <td>[buscamos, una, persona, encargada, de, gestio...</td>\n",
       "      <td>[una, persona, buceo, horario, mismas, gestion...</td>\n",
       "      <td>{'Sustantivos': ['una', 'persona', 'buceo', 'h...</td>\n",
       "      <td>[facturaciones, correspondencia, fisica, trami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984</td>\n",
       "      <td>Ventas al detalle</td>\n",
       "      <td>Venta al detalle</td>\n",
       "      <td>[dependiente, tiendas, centro, comercial, expe...</td>\n",
       "      <td>se busca dependiente para la tienda tezenis en...</td>\n",
       "      <td>[se, busca, dependiente, para, la, tienda, tez...</td>\n",
       "      <td>[busca, dependiente, para, tienda, centro, com...</td>\n",
       "      <td>{'Sustantivos': ['busca', 'dependiente', 'para...</td>\n",
       "      <td>[idiomas, tiendas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>719</td>\n",
       "      <td>Recursos humanos</td>\n",
       "      <td>Prevencion de riesgos</td>\n",
       "      <td>[puentes, grua, normas, sector, metales, homol...</td>\n",
       "      <td>grupo loxamhune empresa lider en el alquiler d...</td>\n",
       "      <td>[grupo, loxamhune, empresa, lider, en, el, alq...</td>\n",
       "      <td>[grupo, empresa, lider, alquiler, maquinaria, ...</td>\n",
       "      <td>{'Sustantivos': ['grupo', 'empresa', 'lider', ...</td>\n",
       "      <td>[formaciones, vehiculo, homologado, prl, certi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1508</td>\n",
       "      <td>Comercial y ventas</td>\n",
       "      <td>Comercial</td>\n",
       "      <td>[asesores, comercial, prevencion, riesgos, lab...</td>\n",
       "      <td>antea prevencion es una compania dedicada a la...</td>\n",
       "      <td>[antea, prevencion, es, una, compania, dedicad...</td>\n",
       "      <td>[antea, prevencion, una, compania, prevencion,...</td>\n",
       "      <td>{'Sustantivos': ['antea', 'prevencion', 'una',...</td>\n",
       "      <td>[formaciones, contacto, asesorias, activos, ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2280</td>\n",
       "      <td>Ingenieros y tecnicos</td>\n",
       "      <td>Electronica y automatica industrial</td>\n",
       "      <td>[oficial, mantenimiento, electromecanico, agua...</td>\n",
       "      <td>mantenimiento preventivo y correctivo de sist...</td>\n",
       "      <td>[mantenimiento, preventivo, correctivo, de, si...</td>\n",
       "      <td>[mantenimiento, preventivo, y, correctivo, y, ...</td>\n",
       "      <td>{'Sustantivos': ['mantenimiento', 'preventivo'...</td>\n",
       "      <td>[repuestos, correctivos, equipos, plantas, tra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_puesto_esco_ull              categoria  \\\n",
       "0                1634    Atencion a clientes   \n",
       "1                1984      Ventas al detalle   \n",
       "2                 719       Recursos humanos   \n",
       "3                1508     Comercial y ventas   \n",
       "4                2280  Ingenieros y tecnicos   \n",
       "\n",
       "                          subcategoria  \\\n",
       "0                  Atencion al cliente   \n",
       "1                     Venta al detalle   \n",
       "2                Prevencion de riesgos   \n",
       "3                            Comercial   \n",
       "4  Electronica y automatica industrial   \n",
       "\n",
       "                               palabras_empleo_texto  \\\n",
       "0  [administrativo, persona, reservas, buceo, ges...   \n",
       "1  [dependiente, tiendas, centro, comercial, expe...   \n",
       "2  [puentes, grua, normas, sector, metales, homol...   \n",
       "3  [asesores, comercial, prevencion, riesgos, lab...   \n",
       "4  [oficial, mantenimiento, electromecanico, agua...   \n",
       "\n",
       "                                  descripcion_oferta  \\\n",
       "0  buscamos una persona encargada de gestionar la...   \n",
       "1  se busca dependiente para la tienda tezenis en...   \n",
       "2  grupo loxamhune empresa lider en el alquiler d...   \n",
       "3  antea prevencion es una compania dedicada a la...   \n",
       "4   mantenimiento preventivo y correctivo de sist...   \n",
       "\n",
       "                         palabras_descripcion_oferta  \\\n",
       "0  [buscamos, una, persona, encargada, de, gestio...   \n",
       "1  [se, busca, dependiente, para, la, tienda, tez...   \n",
       "2  [grupo, loxamhune, empresa, lider, en, el, alq...   \n",
       "3  [antea, prevencion, es, una, compania, dedicad...   \n",
       "4  [mantenimiento, preventivo, correctivo, de, si...   \n",
       "\n",
       "                                   palabras_list_all  \\\n",
       "0  [una, persona, buceo, horario, mismas, gestion...   \n",
       "1  [busca, dependiente, para, tienda, centro, com...   \n",
       "2  [grupo, empresa, lider, alquiler, maquinaria, ...   \n",
       "3  [antea, prevencion, una, compania, prevencion,...   \n",
       "4  [mantenimiento, preventivo, y, correctivo, y, ...   \n",
       "\n",
       "                                       palabras_dict  \\\n",
       "0  {'Sustantivos': ['una', 'persona', 'buceo', 'h...   \n",
       "1  {'Sustantivos': ['busca', 'dependiente', 'para...   \n",
       "2  {'Sustantivos': ['grupo', 'empresa', 'lider', ...   \n",
       "3  {'Sustantivos': ['antea', 'prevencion', 'una',...   \n",
       "4  {'Sustantivos': ['mantenimiento', 'preventivo'...   \n",
       "\n",
       "                        palabras_legacy_minus_nuevas  \n",
       "0  [facturaciones, correspondencia, fisica, trami...  \n",
       "1                                 [idiomas, tiendas]  \n",
       "2  [formaciones, vehiculo, homologado, prl, certi...  \n",
       "3  [formaciones, contacto, asesorias, activos, ve...  \n",
       "4  [repuestos, correctivos, equipos, plantas, tra...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first 5 rows of the DataFrame and save into a new DataFrame\n",
    "test_df = test_df.iloc[0:5].copy()\n",
    "# Call the processing function with your DataFrame\n",
    "test_df = process_and_measure_time(test_df, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms)\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_results_to_markdown(index, test_df, output_file):\n",
    "    # Get list of words in descripcion_oferta\n",
    "    descripcion_oferta = test_df[\"descripcion_oferta\"].iloc[index].split(\" \")\n",
    "    error, accuracy = get_reference(descripcion_oferta, test_df, index, \"palabras_list_all\")\n",
    "    \n",
    "    with open(output_file, \"w\") as md_file:\n",
    "        # Write header for the section\n",
    "        md_file.write(f\"**Descripcion oferta:** {test_df['descripcion_oferta'].iloc[index]}\\n\")\n",
    "        md_file.write(f\"**Total de palabras en descripciÃ³n:** {len(descripcion_oferta)}\\n\")\n",
    "        md_file.write(f\"**Accuracy - palabras nuevas:** {accuracy}\\n\")\n",
    "        md_file.write(f\"**Error - palabras nuevas:** {error}\\n\")\n",
    "        md_file.write(f\"**Palabras nuevas:** {', '.join(test_df['palabras_list_all'].iloc[index])}\\n\")\n",
    "        palabras_not_found = list(set(test_df['palabras_list_all'].iloc[index]) - set(descripcion_oferta))\n",
    "        md_file.write(f\"**Palabras nuevas no encontradas en descripciÃ³n:** {', '.join(palabras_not_found)}\\n\")\n",
    "        \n",
    "        error, accuracy = get_reference(descripcion_oferta, test_df, index, \"palabras_empleo_texto\")\n",
    "        md_file.write(f\"**Accuracy - palabras legacy:** {accuracy}\\n\")\n",
    "        md_file.write(f\"**Error - palabras legacy:** {error}\\n\")\n",
    "        md_file.write(f\"**Palabras legacy:** {', '.join(test_df['palabras_empleo_texto'].iloc[index])}\\n\")\n",
    "        \n",
    "        palabras_not_found = list(set(test_df['palabras_empleo_texto'].iloc[index]) - set(descripcion_oferta))\n",
    "        md_file.write(f\"**Palabras legacy no encontradas en descripciÃ³n:** {', '.join(palabras_not_found)}\\n\")\n",
    "\n",
    "# Define the Markdown output file\n",
    "output_file = \"results.md\"\n",
    "\n",
    "# Call the function to export the results to Markdown\n",
    "export_results_to_markdown(1, test_df, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
