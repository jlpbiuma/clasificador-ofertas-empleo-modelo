{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.functions.tools import load_json\n",
    "import pandas as pd\n",
    "import time\n",
    "from unidecode import unidecode\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import test set and dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11123, 5)\n"
     ]
    }
   ],
   "source": [
    "data = load_json('./data/test/test_palabras.json')\n",
    "# Now cast data to a DataFrame\n",
    "test_df = pd.DataFrame(data)\n",
    "print(test_df.shape)\n",
    "test_df.head()\n",
    "sustantives_df = pd.read_csv('./data/diccionario/df_structured_sustantivos.csv')\n",
    "adjectives_df = pd.read_csv('./data/diccionario/df_structured_adjetivos.csv')\n",
    "adverbs_df = pd.read_csv('./data/diccionario/df_structured_adverbios.csv')\n",
    "verbs_df = pd.read_csv('./data/diccionario/df_structured_verbos.csv').sort_values(by=['FORMA']).reset_index(drop=True)\n",
    "# Read the txt files sustantives and adjectives\n",
    "with open('./data/diccionario/list_unstructured_sustantivos.txt', 'r') as f:\n",
    "    sustantives_forms = f.read().splitlines()\n",
    "with open('./data/diccionario/list_unstructured_adjetivos.txt', 'r') as f:\n",
    "    adjectives_forms = f.read().splitlines()\n",
    "verbs_forms = verbs_df['FORMA'].tolist()\n",
    "# with open('./data/diccionario/list_unstructured_verbs.txt', 'r') as f:\n",
    "#     verbs_forms = f.read().splitlines()\n",
    "with open('./data/diccionario/list_unstructured_adverbios.txt', 'r') as f:\n",
    "    adverbs_forms = f.read().splitlines()\n",
    "# Get the spanish stopwords with nltk\n",
    "stop_words = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  (1021406, 2)\n",
      "After:  (1020203, 2)\n"
     ]
    }
   ],
   "source": [
    "# Delete all samples that a one of the columns is null in verbs_df\n",
    "print(\"Before: \", verbs_df.shape)\n",
    "verbs_df = verbs_df.dropna()\n",
    "print(\"After: \", verbs_df.shape)\n",
    "# Get the list of verbs in the column \"FORMA\"\n",
    "verbs_forms = verbs_df['FORMA'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexialice unstructured lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_list(unstructured_forms):\n",
    "    index_list = {}\n",
    "    for index, string in enumerate(unstructured_forms):\n",
    "        first_letter = string[0]\n",
    "        if first_letter not in index_list:\n",
    "            index_list[first_letter] = index\n",
    "    return index_list\n",
    "\n",
    "sustantives_index_list = create_index_list(sustantives_forms)\n",
    "adjectives_index_list = create_index_list(adjectives_forms)\n",
    "verbs_index_list = create_index_list(verbs_forms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "list_remove = [\"www\", \"com\",\"http\", \"https\"]\n",
    "\n",
    "def tokenize_descripcion(text):\n",
    "    # Remove links (URLs) from the text using regular expressions\n",
    "    text = re.sub(r'http(s)?:\\s+\\S+', '', text, flags=re.IGNORECASE)\n",
    "    # Remove all occurrences of \".es\" (case-insensitive)\n",
    "    text = re.sub(r'\\.es', '', text, flags=re.IGNORECASE)\n",
    "    # Remove all non alpha characters from the text using regular expressions\n",
    "    text = re.sub(r'[^a-zA-Z ]+', ' ', text, flags=re.IGNORECASE)\n",
    "    # Remove unnecessary spaces from the text using regular expressions\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.IGNORECASE)\n",
    "    # Cast all words to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def create_palabras_column(text):\n",
    "    # Split the text into a list of words and filter simultaneously\n",
    "    palabras = [palabra for palabra in text.split(\" \") if len(palabra) > 1 and palabra not in list_remove]\n",
    "    return palabras\n",
    "\n",
    "def list_words(palabras_empleo_texto):\n",
    "    # print(palabras_empleo_texto)\n",
    "    return palabras_empleo_texto.lower().split(\" \")[:-1]\n",
    "\n",
    "def clean_descripcion(df):\n",
    "    # tokenize the descripcion\n",
    "    df['descripcion_oferta'] = df['descripcion_oferta'].apply(tokenize_descripcion)\n",
    "    # Split the text into a list of words\n",
    "    df['palabras_descripcion_oferta'] = df['descripcion_oferta'].apply(create_palabras_column)\n",
    "    # Convert the string into a list\n",
    "    df['palabras_empleo_texto'] = df['palabras_empleo_texto'].apply(lambda x: list_words(x))\n",
    "    return df\n",
    "\n",
    "test_df = clean_descripcion(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_word(word):\n",
    "    # Delete all numbers\n",
    "    word = re.sub(r\"\\d+\", \"\", word)\n",
    "    # Delete all accents\n",
    "    word = unidecode(word.lower())\n",
    "    # Remove simbols\n",
    "    word = re.sub(r\"[^a-z0-9Ã±]\", \"\", word)\n",
    "    return word\n",
    "\n",
    "def find_indices(string, index_list, unstructured_forms):\n",
    "    if not string:  # Check if the string is empty\n",
    "        return 0, len(unstructured_forms)\n",
    "    first_letter = string[0]\n",
    "    start_index = index_list.get(first_letter, 0)\n",
    "    if first_letter == \"z\":\n",
    "        end_index = len(unstructured_forms)\n",
    "    else:\n",
    "        next_letter = chr(ord(first_letter) + 1)\n",
    "        end_index = index_list.get(next_letter, len(unstructured_forms))\n",
    "    return start_index, end_index\n",
    "\n",
    "def get_lemma_df(word, df, unstructured_forms, index_list):\n",
    "    start, end = find_indices(word, index_list, unstructured_forms)\n",
    "    # Is faster to handler the exception than to check if the word is in the list\n",
    "    try:\n",
    "        index = unstructured_forms.index(word, start, end)\n",
    "        if \"LEMA\" in df.columns:\n",
    "            return df.iloc[index][\"LEMA\"]\n",
    "        else:\n",
    "            return df.iloc[index][\"INF\"]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def conditional_inference(word, df_nouns, unstructured_forms_nouns, df_adj, unstructured_forms_adj, df_verbs, unstructured_forms_verb):\n",
    "    verb = get_lemma_df(word, df_verbs, unstructured_forms_verb, verbs_index_list)\n",
    "    if verb == None:\n",
    "        noun = get_lemma_df(word, df_nouns, unstructured_forms_nouns, sustantives_index_list)\n",
    "        if noun == None:\n",
    "            adjective = get_lemma_df(word, df_adj, unstructured_forms_adj, adjectives_index_list)\n",
    "            if adjective == None:\n",
    "                return None\n",
    "            else:\n",
    "                return adjective\n",
    "        else:\n",
    "            return noun\n",
    "    else:\n",
    "        return verb\n",
    "\n",
    "def get_syntax(words, df_nouns, unstructured_forms_nouns, df_adj, unstructured_forms_adj, unstructured_forms_adv, df_verbs, unstructured_forms_verb):\n",
    "    # Object palabras_list\n",
    "    palabras_list = []\n",
    "    # Split by \" \"\n",
    "    for word in words.split(\" \"):\n",
    "        word = clean_word(word)\n",
    "        if word in stop_words or word in unstructured_forms_adv:\n",
    "            continue\n",
    "        # Verify if is a noun\n",
    "        solution = conditional_inference(word, df_nouns, unstructured_forms_nouns, df_adj, unstructured_forms_adj, df_verbs, unstructured_forms_verb)\n",
    "        if solution != None:\n",
    "            palabras_list.append(solution)\n",
    "    return palabras_list\n",
    "\n",
    "def process_and_update_df(df, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms, adverbs_forms ,verbs_df, verbs_forms):\n",
    "    # Create a new column in the DataFrame to store the result\n",
    "    df[\"palabras_list_all\"] = \"\"\n",
    "    times = []\n",
    "    start_time_process = time.time()\n",
    "    # Iterate over the DataFrame and apply the word extraction function\n",
    "    for index, description in df[\"descripcion_oferta\"].items():\n",
    "        start_time = time.time()\n",
    "        # Get the list of words\n",
    "        palabras_list = get_syntax(description, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms, adverbs_forms ,verbs_df, verbs_forms)\n",
    "        # Save palabras_list in a new column in the DataFrame, insert the full list\n",
    "        df.at[index, \"palabras_list_all\"] = palabras_list\n",
    "        remain_time = time.time() - start_time\n",
    "        times.append(remain_time)\n",
    "    # Calculate and add the column with words that appear in palabras legacy but not in palabras nuevas\n",
    "    df[\"palabras_legacy_minus_nuevas\"] = df.apply(lambda row: list(set(row[\"palabras_empleo_texto\"]) - set(row[\"palabras_list_all\"])), axis=1)\n",
    "    end_time_process = time.time() - start_time_process\n",
    "    print(\"Time process: \", end_time_process)\n",
    "    return df, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time process:  0.9065427780151367\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_puesto_esco_ull</th>\n",
       "      <th>categoria</th>\n",
       "      <th>subcategoria</th>\n",
       "      <th>palabras_empleo_texto</th>\n",
       "      <th>descripcion_oferta</th>\n",
       "      <th>palabras_descripcion_oferta</th>\n",
       "      <th>palabras_list_all</th>\n",
       "      <th>palabras_legacy_minus_nuevas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1634</td>\n",
       "      <td>Atencion a clientes</td>\n",
       "      <td>Atencion al cliente</td>\n",
       "      <td>[administrativo, persona, reservas, buceo, ges...</td>\n",
       "      <td>buscamos una persona encargada de gestionar la...</td>\n",
       "      <td>[buscamos, una, persona, encargada, de, gestio...</td>\n",
       "      <td>[buscar, persona, encargado, gestionar, reserv...</td>\n",
       "      <td>[centro, atenciones, ventas, correspondencia, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984</td>\n",
       "      <td>Ventas al detalle</td>\n",
       "      <td>Venta al detalle</td>\n",
       "      <td>[dependiente, tiendas, centro, comercial, expe...</td>\n",
       "      <td>se busca dependiente para la tienda tezenis en...</td>\n",
       "      <td>[se, busca, dependiente, para, la, tienda, tez...</td>\n",
       "      <td>[buscar, dependiente, tender, centrar, comerci...</td>\n",
       "      <td>[centro, tiendas, idiomas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>719</td>\n",
       "      <td>Recursos humanos</td>\n",
       "      <td>Prevencion de riesgos</td>\n",
       "      <td>[puentes, grua, normas, sector, metales, homol...</td>\n",
       "      <td>grupo loxamhune empresa lider en el alquiler d...</td>\n",
       "      <td>[grupo, loxamhune, empresa, lider, en, el, alq...</td>\n",
       "      <td>[grupo, empresa, lider, alquiler, maquinar, pl...</td>\n",
       "      <td>[prl, riesgos, formaciones, alquileres, contra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1508</td>\n",
       "      <td>Comercial y ventas</td>\n",
       "      <td>Comercial</td>\n",
       "      <td>[asesores, comercial, prevencion, riesgos, lab...</td>\n",
       "      <td>antea prevencion es una compania dedicada a la...</td>\n",
       "      <td>[antea, prevencion, es, una, compania, dedicad...</td>\n",
       "      <td>[antea, prevencion, compania, dedicado, preven...</td>\n",
       "      <td>[ambiente, ventas, clientes, acuerdos, prospec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2280</td>\n",
       "      <td>Ingenieros y tecnicos</td>\n",
       "      <td>Electronica y automatica industrial</td>\n",
       "      <td>[oficial, mantenimiento, electromecanico, agua...</td>\n",
       "      <td>mantenimiento preventivo y correctivo de sist...</td>\n",
       "      <td>[mantenimiento, preventivo, correctivo, de, si...</td>\n",
       "      <td>[mantenimiento, preventivo, correctivo, sistem...</td>\n",
       "      <td>[repuestos, electromecanico, equipos, mecanica...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_puesto_esco_ull              categoria  \\\n",
       "0                1634    Atencion a clientes   \n",
       "1                1984      Ventas al detalle   \n",
       "2                 719       Recursos humanos   \n",
       "3                1508     Comercial y ventas   \n",
       "4                2280  Ingenieros y tecnicos   \n",
       "\n",
       "                          subcategoria  \\\n",
       "0                  Atencion al cliente   \n",
       "1                     Venta al detalle   \n",
       "2                Prevencion de riesgos   \n",
       "3                            Comercial   \n",
       "4  Electronica y automatica industrial   \n",
       "\n",
       "                               palabras_empleo_texto  \\\n",
       "0  [administrativo, persona, reservas, buceo, ges...   \n",
       "1  [dependiente, tiendas, centro, comercial, expe...   \n",
       "2  [puentes, grua, normas, sector, metales, homol...   \n",
       "3  [asesores, comercial, prevencion, riesgos, lab...   \n",
       "4  [oficial, mantenimiento, electromecanico, agua...   \n",
       "\n",
       "                                  descripcion_oferta  \\\n",
       "0  buscamos una persona encargada de gestionar la...   \n",
       "1  se busca dependiente para la tienda tezenis en...   \n",
       "2  grupo loxamhune empresa lider en el alquiler d...   \n",
       "3  antea prevencion es una compania dedicada a la...   \n",
       "4   mantenimiento preventivo y correctivo de sist...   \n",
       "\n",
       "                         palabras_descripcion_oferta  \\\n",
       "0  [buscamos, una, persona, encargada, de, gestio...   \n",
       "1  [se, busca, dependiente, para, la, tienda, tez...   \n",
       "2  [grupo, loxamhune, empresa, lider, en, el, alq...   \n",
       "3  [antea, prevencion, es, una, compania, dedicad...   \n",
       "4  [mantenimiento, preventivo, correctivo, de, si...   \n",
       "\n",
       "                                   palabras_list_all  \\\n",
       "0  [buscar, persona, encargado, gestionar, reserv...   \n",
       "1  [buscar, dependiente, tender, centrar, comerci...   \n",
       "2  [grupo, empresa, lider, alquiler, maquinar, pl...   \n",
       "3  [antea, prevencion, compania, dedicado, preven...   \n",
       "4  [mantenimiento, preventivo, correctivo, sistem...   \n",
       "\n",
       "                        palabras_legacy_minus_nuevas  \n",
       "0  [centro, atenciones, ventas, correspondencia, ...  \n",
       "1                         [centro, tiendas, idiomas]  \n",
       "2  [prl, riesgos, formaciones, alquileres, contra...  \n",
       "3  [ambiente, ventas, clientes, acuerdos, prospec...  \n",
       "4  [repuestos, electromecanico, equipos, mecanica...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first 5 rows of the DataFrame and save into a new DataFrame\n",
    "test_df = test_df.iloc[0:5].copy()\n",
    "# Call the processing function with your DataFrame\n",
    "test_df, times = process_and_update_df(test_df, sustantives_df, sustantives_forms, adjectives_df, adjectives_forms, adverbs_forms ,verbs_df, verbs_forms)\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference(descripcion_oferta, df, index, column):\n",
    "    # Get the accuracy of the words in palabras_empleo_texto that are in descripcion_oferta\n",
    "    error = 0\n",
    "    accuracy = 0\n",
    "    for word in descripcion_oferta:\n",
    "        if unidecode(word) not in df[column].iloc[index]:\n",
    "            error += 1\n",
    "        else:\n",
    "            accuracy += 1\n",
    "    return error, accuracy\n",
    "\n",
    "def export_results_to_markdown(index, test_df, output_file, time):\n",
    "    # Get list of words in descripcion_oferta\n",
    "    descripcion_oferta = test_df[\"descripcion_oferta\"].iloc[index].split(\" \")\n",
    "    error, accuracy = get_reference(descripcion_oferta, test_df, index, \"palabras_list_all\")\n",
    "    \n",
    "    with open(\"./test/\" + str(index) + \"_\" + output_file, \"w\") as md_file:\n",
    "        # Write header for the section\n",
    "        md_file.write(f\"## Descripcion oferta: \\n{test_df['descripcion_oferta'].iloc[index]}\\n\")\n",
    "        md_file.write(f\"### Total de palabras en descripciÃ³n: \\n{len(descripcion_oferta)}\\n\")\n",
    "        md_file.write(f\"\\n\")\n",
    "        md_file.write(f\"## Palabras nuevas: \\n{', '.join(test_df['palabras_list_all'].iloc[index])}\\n\")\n",
    "        md_file.write(f\"### Accuracy - palabras nuevas: \\n{accuracy}\\n\")\n",
    "        md_file.write(f\"### Error - palabras nuevas: \\n{error}\\n\")\n",
    "        palabras_not_found = list(set(test_df['palabras_list_all'].iloc[index]) - set(descripcion_oferta))\n",
    "        md_file.write(f\"## Palabras nuevas no encontradas en descripciÃ³n: \\n{', '.join(palabras_not_found)}\\n\")\n",
    "        md_file.write(f\"\\n\")\n",
    "        error, accuracy = get_reference(descripcion_oferta, test_df, index, \"palabras_empleo_texto\")\n",
    "        md_file.write(f\"## Palabras legacy: \\n{', '.join(test_df['palabras_empleo_texto'].iloc[index])}\\n\")\n",
    "        md_file.write(f\"### Accuracy - palabras legacy: \\n{accuracy}\\n\")\n",
    "        md_file.write(f\"### Error - palabras legacy: \\n{error}\\n\")\n",
    "        palabras_not_found = list(set(test_df['palabras_empleo_texto'].iloc[index]) - set(descripcion_oferta))\n",
    "        md_file.write(f\"## Palabras legacy no encontradas en descripciÃ³n: \\n{', '.join(palabras_not_found)}\\n\")\n",
    "        md_file.write(f\"\\n\")\n",
    "        md_file.write(f\"## Tiempo de ejecuciÃ³n: \\n{time} segundos\\n\")\n",
    "        md_file.write(f\"## RelaciÃ³n palabras/tiempo: \\n{len(descripcion_oferta)/time} palabras/segundo\\n\")\n",
    "\n",
    "# Define the Markdown output file\n",
    "output_file = \"test.md\"\n",
    "\n",
    "# Call the function to export the results to Markdown\n",
    "for index in range(0, test_df.shape[0]):\n",
    "    time = times[index]\n",
    "    export_results_to_markdown(index, test_df, output_file, time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
